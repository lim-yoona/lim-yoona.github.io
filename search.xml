<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ymdb-一个分布式键值存储系统</title>
      <link href="/2024/05/02/2024-05-02-ymdb/"/>
      <url>/2024/05/02/2024-05-02-ymdb/</url>
      
        <content type="html"><![CDATA[<p><a href="https://github.com/lim-yoona/ymdb"><strong><em>ymdb</em></strong></a> 是我开源的一款简易的分布式键值存储系统，适用于分布式系统初学者练手或者应届生写上简历，这篇文章将对 <strong><em>ymdb</em></strong> 做一个全面的介绍（建议仅用作学习用途，应用于生产是危险的，因为 <strong><em>ymdb</em></strong> 尚不完善）。  </p><p><strong><em>ymdb</em></strong> 使用 <em>Go</em> 语言开发，从面试情况来看，面试官还是很喜欢问这个项目的，并且有几个面试官表示这样的项目比较抓眼球，因为它是一个偏底层的并且不是一个千篇一律（俗称“烂大街”）的项目，因此写在简历上不失为一个好的选择。  </p><h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><p>要做一个分布式存储系统，需要考虑以下三个点：  </p><ol><li>存储  </li><li>分区  </li><li>复制</li></ol><p>存储是设计一个存储系统必须要考虑的，而分区和复制则是设计一个分布式系统需要考虑的。  </p><p>在存储部分，当前的键值存储有三种技术方案，一种是 <a href="https://github.com/facebook/rocksdb"><em>RocksDB</em></a> 采用的 <em>LSMT(Log Structured Merge Tree)</em> 方案；一种是 <a href="https://github.com/rosedblabs/rosedb"><em>RoseDB</em></a> 采用的 <em>Bitcask</em> 方案；一种是 <a href="https://github.com/redis/redis"><em>Redis</em></a> 的方案。考虑到我想做一个持久的键值存储系统，所以 <em>Redis</em> 这种基于内存的方式首先排除，<em>Redis</em> 的持久化仅用作备份以及主从复制，并不会从磁盘去拿数据。<em>LSMT</em> 实现起来较为复杂，且其虽然写效率很高，但读效率却较差，主要由于 <em>LSMT</em> 是在磁盘上的多层结构，可能要查好几层才能查到数据。因此，我最终选择 <em>RoseDB</em> 的方案来实现键值存储，即将所有的 <em>key</em> 存储在内存中，并将 <em>key</em> 对应的值在磁盘中的位置与 <em>key</em> 一同存放，而将 <em>value</em> 都存储在磁盘上，读取数据只需要一次磁盘IO，写入数据由于是追加写，可以利用到 <em>page cache</em> ，这样读写效率都很高。  </p><p>在分区部分，我们要做的是对数据的分区，由于我们将所有的 <em>key</em> 都存放在内存中，所以内存的大小就是我们可以存储的数据量的瓶颈，所以我们需要进行数据分区，保证每个节点上只存储部分数据而不是全量数据，这样就使得存储系统中可以存储的数据总量不受单台计算机的内存和磁盘大小的约束。借鉴 <em>Redis</em> ,我采用<strong>一致性哈希</strong>来做数据分区，不过没有 <em>Redis</em> 那么复杂。  </p><p>在容错部分，做为一个分布式的系统，必须具有容错的能力，现有的知名的分布式系统例如 <em>hdfs</em> 、<em>gfs</em> 以及 <em>kafka</em> 等都是通过将一份数据存储多份副本来保证可靠性的，**<em>ymdb</em>** 亦是如此，我设计一个分区内的多个节点存储当前分区数据的多个副本来提供容错性。我采用 <em>Raft</em> 算法来实现分区内节点间的分布式共识，首先 <em>Raft</em> 易于理解，其次 <em>Raft</em> 被许多知名开源软件广泛使用，例如 <em>etcd</em> 、<em>tikv</em> 、<em>Consul</em> 等。</p><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p><a href="https://imgse.com/i/pFJnTYQ"><img src="https://s11.ax1x.com/2024/02/17/pFJnTYQ.jpg" alt="ymdb整体架构"></a></p><p><strong><em>ymdb</em></strong> 的整体架构如图所示，客户端通过一致性哈希去确定数据所在的分区，每个分区内包含多个节点，存储本分区内数据的多个副本，在某一个具体的节点上，内存中存储所有的 <em>key</em> ，并使用跳表(<em>skip-list</em>)来作为 <em>key</em> 的索引结构以加快查找，<em>value</em> 以追加写的方式存储在磁盘上。</p><h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2><h3 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h3><p><strong><em>ymdb</em></strong> 在内存中存储所有的 <em>key</em> ，并采用跳表作为 <em>key</em> 的索引。选择跳表的原因在于其易于实现、维护成本低且范围查询友好，由于是内存索引，所以没有必要选择平衡树徒增维护成本。</p><p>相关代码位于项目的 <strong>index</strong> 包下，我这里直接采用了对第三方跳表实现的封装，<code>put()</code> 方法将 <em>key</em> 以及对应 <em>value</em> 所在的位置写入跳表；<code>get()</code>方法通过 <em>key</em> 获得其对应 <em>value</em> 在磁盘上的位置；<code>delete()</code>方法仅在跳表中删除指定 <em>key</em> 。  </p><p>虽然我这里使用了第三方的跳表实现，但是跳表易于实现，也可以自己实现，我之前使用 <em>C++</em> 实现过一版，具体思路在于使用 <em>vector</em> 作为跳表的节点，设置 <em>vector</em> 长度为跳表的高度，<em>vector</em> 的元素以下标顺序 <code>0-i</code> 分别存储该节点在跳表中的 <code>0-i</code> 层的信息，以随机的方式选择每个节点的高度。  </p><h3 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h3><p>所有的 <em>value</em> 以追加写的方式存储在磁盘上的 <strong>WAL</strong> 文件中，这部分代码在项目的 <strong>db</strong> 包下，是 <strong><em>ymdb</em></strong> 存储引擎的实现，目前对数据的操作包含 <code>put</code>、<code>get</code> 以及 <code>delete</code>。  </p><h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><p>采用一致性哈希来实现数据的分区，一致性哈希的基本原理可以看 <a href="https://ymiir.asia/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/consistent-hashing">一致性哈希算法</a>，这里我也是采用了第三方实现，代码位于项目的 <strong>cluster-cli.go</strong> ，也就是说 <strong><em>ymdb</em></strong> 在客户端完成对于数据的定位，随后再向相应的分区发送数据的读写请求。  </p><p>虽然我这里使用了第三方的一致性哈希实现，但是自己实现起来应该也较为简单，由于需要在哈希环上顺时针去寻找数据所在的分区，所以首先我们需要一个有序的数据结构，比如红黑树，首先对分区做哈希得到32位哈希值，存到红黑树中，之后对数据做哈希得到32位哈希值，在红黑树中搜索第一个比自己大的节点就是这个数据对应的分区。如果需要增加虚拟节点，只需要给真实分区加上一些信息，依旧做哈希得到哈希值，如果有数据映射到该分区，则可以进一步映射到真实的分区上。  </p><h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h2><p>采用 <em>Raft</em> 算法来实现节点间的分布式共识，<em>Raft</em> 算法的基本原理可以看 <a href="https://ymiir.asia/%E5%88%86%E5%B8%83%E5%BC%8F/raft-algo-summary"><em>Raft</em> 共识算法总结</a>。当客户端给一个分区发出写数据指令，该分区的 <em>Leader</em> 会来处理这个指令，<em>Leader</em> 负责将这条指令复制给其余的节点，其余的节点执行指令实现数据存储，并返回给 <em>Leader</em> ，当 <em>Leader</em> 收到集群中半数以上节点的响应时，就认为这条指令可以提交了，于是执行指令并给客户端返回。  </p><p><strong><em>ymdb</em></strong> 基于 <em>Raft</em> 算法，因此 <strong><em>ymdb</em></strong> 整体上是一个 <code>CP</code> 型的分布式系统，也就是说，保证强一致性并且具有分区容错性。  </p><p>我采用了 <a href="https://github.com/hashicorp">HashiCorp</a> 的 <em>Raft</em> 实现，代码位于项目的 <strong>raft</strong> 包下，<code>application.go</code> 下定义了自己的 <em>FSM</em> ,即有限状态机，主要是需要实现 <code>Apply()</code> 方法来定义日志应用的逻辑。由于我们客户端使用 <code>grpc</code> 来与 <strong><em>ymdb</em></strong> 集群做交互，所以还需要编写 <code>proto</code> 文件来定义 <code>grpc</code> 通信所需要的消息和服务，同时还需要在 <code>application.go</code> 中实现一个 <code>rpc</code> 服务端，实现 <code>SendMsg()</code> 方法处理 <code>rpc</code> 请求。另外，<em>Raft</em> 集群节点间的通信是第三方库实现好的，无需考虑。  </p><h2 id="通信"><a href="#通信" class="headerlink" title="通信"></a>通信</h2><p>客户端采用 <code>grpc</code> 与多个 <em>Raft</em> 集群进行通信，客户端代码位于 <code>cluster-cli.go</code> 中，根据不同的指令和 <em>key</em> 向不同的数据分区发送不同的 <code>rpc</code> 请求，集群中任意一个节点收到 <code>rpc</code> 请求会把请求转发给 <em>Leader</em> 进行处理，<em>Leader</em> 处理消息的逻辑见 <code>application.go</code> 下的 <code>rpcInterface</code> 的 <code>SendMsg()</code> 方法，首先应用日志，之后从响应 <code>channel</code> 中取得结果；应用日志的具体逻辑在 <code>dataTracker</code> 的 <code>Apply()</code> 方法中，这里应用日志也就是交给存储引擎来执行数据读写命令，这里把消息放在了一个消息队列也就是 <code>MsQueue</code> 中，存储引擎会从中取命令然后执行，达到一个异步处理的效果。  </p><h2 id="崩溃恢复"><a href="#崩溃恢复" class="headerlink" title="崩溃恢复"></a>崩溃恢复</h2><p>为了实现崩溃一致性，节点应该具有崩溃恢复的能力，**<em>ymdb</em>** 在磁盘上额外存放了一个用于恢复的 <em>WAL</em> 文件，记录修改数据的指令，在每次执行修改类型的命令之前，首先将命令写入到日志中，类似于 <em>MySQL</em> 的 <em>redo log</em> ，这样即使节点崩溃。在节点恢复之后只需要执行日志中的指令即可恢复数据，实现崩溃一致性。  </p><p>写入日志的代码位于项目的 <strong>route</strong> 包下，在 <code>Handle()</code> 方法中，根据消息类型执行不同的操作，只有 <strong>PUT</strong> 和 <strong>DELETE</strong> 操作才会去调用 <code>writeWAL()</code> 方法写入恢复日志。  </p><p>崩溃恢复的代码位于项目的 <strong>db</strong> 包下的 <code>Restore()</code> 方法以及 <code>NewDB()</code> 方法，在创建 <code>DB</code> 对象时，如果发现指定目录下已经有日志文件，则置恢复状态位 <code>isRestore</code> 为真，执行恢复操作，否则创建新的日志文件。  </p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p><strong><em>ymdb</em></strong> 目前尚有大量优化空间，我能想到的如下：</p><ol><li>增加缓存系统。对于随机读取，无法利用到操作系统的 <em>page cache</em> ，导致每次查询稳定一次磁盘IO，是拖慢速度的，如果增加了缓存系统，便可以大大提升效率。然而引入缓存系统就必须要考虑其带来的数据不一致性，尚需要斟酌。  </li><li>服务发现。目前系统中的节点数量和地址信息在数据库启动时就已经确定了，无法动态扩展，可以增加服务注册与发现机制来实现节点的动态增删，具体可以使用 <a href="https://github.com/apache/zookeeper"><em>zookeeper</em></a> 来实现。  </li><li>节点间数据迁移。由于使用了一致性哈希作为数据分区算法，增加和删除分区必然导致分区数据的变化，所以需要实现分区间数据的迁移，可以使用子进程来实现。</li></ol><p>具体 <strong><em>ymdb</em></strong> 的使用可以参考 <a href="https://github.com/lim-yoona/ymdb/blob/main/README.md">README.md</a> 以及 <a href="https://github.com/lim-yoona/ymdb/tree/main/example">示例</a>。  </p><h2 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h2><p>面试中对这个项目的考察多从以下几点进行提问： </p><ol><li>为什么选择跳表作为内存索引，不选择别的</li><li>跳表的原理是什么，应该如何实现 </li><li>为什么选择一致性哈希，还了解别的数据分区算法吗 </li><li>一致性哈希知道怎么实现吗 </li><li>一致性哈希存在哪些问题，如何解决 </li><li>为什么选择 <em>Raft</em> 算法来做分布式共识，还了解别的分布式共识算法吗</li><li><em>Raft</em> 的领导选举介绍一下</li><li><em>Raft</em> 的 <em>Leader</em> 挂了会发生什么</li><li><em>Raft</em> 是强一致的吗，如何保证强一致的</li><li><em>Raft</em> 是如何解决脑裂问题的</li><li><em>CAP</em> 定理介绍一下</li><li><strong><em>ymdb</em></strong> 跟 <em>Redis</em> 集群有哪些不同之处</li><li>做过压测吗，性能如何</li></ol><p>这就是我对 <strong><em>ymdb</em></strong> 的整体介绍，包括之后的优化思路以及面试常见问题，有任何问题可在评论区交流。  </p><p><em>MIT6.824</em> 的实验最终也会实现一个分布式的键值存储系统，然如果时间不充裕，听完 <em>MIT</em> 的全英课再自己实现 <em>Raft</em> 也需要较长时间，出于练手的考虑，直接采用第三方 <em>Raft</em> 快速构建一个分布式系统也是可以的，并且面试官很少会关注到 <em>Raft</em> 算法的具体实现。  </p>]]></content>
      
      
      <categories>
          
          <category> 开源 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 开源 </tag>
            
            <tag> 分布式 </tag>
            
            <tag> 存储 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java ReentrantLock原理</title>
      <link href="/2024/04/28/2024-04-28-ReentrantLock/"/>
      <url>/2024/04/28/2024-04-28-ReentrantLock/</url>
      
        <content type="html"><![CDATA[<p><strong><em>ReentrantLock</em></strong> 是 <em>Java JUC(java.util.concurrent)</em> 包下的一个锁工具，它实现了 <em>Lock</em> 接口，与 <em>synchronized</em> 锁不同，**<em>ReentrantLock</em>** 除了用来做线程间互斥之外，还提供了很多高级的特性，例如<strong>公平锁 &amp; 非公平锁</strong>以及<strong>可中断</strong>。  </p><p>本文将从 <strong>JDK17</strong> 源码角度介绍一下 <strong><em>ReentrantLock</em></strong> 的底层实现原理，这部分是 <em>Java</em> 面试的常考知识点。（目前看到的博客都是基于 <strong>JDK8</strong> 源码分析的，而鲜有基于 <strong>JDK17</strong> 源码进行分析的）  </p><p><em>2024美团暑期实习后端开发一面：公平锁与非公平锁是如何实现的？</em> 看完这篇文章你就明白了！</p><h2 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h2><p><strong>AQS</strong> 的全称为 <em>AbstractQueueSynchronizer</em> ，即抽象队列同步器，通俗来讲，<strong>AQS</strong> 的作用就是来定义线程如何获得锁、线程未获得锁如何等待以及线程如何释放锁。**<em>ReentrantLock</em>** 的底层实现是高度依赖 <strong>AQS</strong> 的，这一点从源码中就可以看得出来：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ReentrantLock</span> <span class="keyword">implements</span> <span class="title class_">Lock</span>, java.io.Serializable &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">7373984872572414699L</span>;</span><br><span class="line">    <span class="comment">/** Synchronizer providing all implementation mechanics */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Sync sync;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Base of synchronization control for this lock. Subclassed</span></span><br><span class="line"><span class="comment">     * into fair and nonfair versions below. Uses AQS state to</span></span><br><span class="line"><span class="comment">     * represent the number of holds on the lock.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">abstract</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Sync</span> <span class="keyword">extends</span> <span class="title class_">AbstractQueuedSynchronizer</span> &#123;</span><br><span class="line">        ···</span><br><span class="line">    &#125;</span><br><span class="line">    ···</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong><em>ReentrantLock</em></strong> 内部有一个 <em>Sync</em> 类型的对象，<em>Sync</em> 这个类则是继承自 _AbstractQueuedSynchronizer_，也就是抽象队列同步器，这个锁的同步控制基础就是这个 <em>Sync</em> 提供的，可以注意到这里的 <em>Sync</em> 仍然是抽象类，其实它还有两个子类，分别是 <em>FairSync</em> 和 <em>NonFairSync</em> ，分别对应于公平锁的实现和非公平锁的实现。  </p><p><strong>AQS</strong> 底层是一个 <em>CLH</em> 队列，是一个双向队列，由 <em>Node</em> 节点连接而成，这部分代码位于 <em>AbstractQueuedSynchronizer</em> 抽象类中，</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** CLH Nodes */</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">    <span class="keyword">volatile</span> Node prev;       <span class="comment">// initially attached via casTail</span></span><br><span class="line">    <span class="keyword">volatile</span> Node next;       <span class="comment">// visibly nonnull when signallable</span></span><br><span class="line">    Thread waiter;            <span class="comment">// visibly nonnull when enqueued</span></span><br><span class="line">    <span class="keyword">volatile</span> <span class="type">int</span> status;      <span class="comment">// written by owner, atomic bit ops by others</span></span><br><span class="line">    </span><br><span class="line">    ···</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，一个 <em>Node</em> 包含指向前后 <em>Node</em> 的指针(prev 和 next)，一个在等待的线程对象(waiter)以及状态(status)。这里的状态指的是这个线程对象的状态，在 <strong>JDK17</strong> 中，这个状态只有三种，但在 <strong>JDK8</strong> 中这里的状态数量更多。  </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Node status bits, also used as argument and return values</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">WAITING</span>   <span class="operator">=</span> <span class="number">1</span>;          <span class="comment">// must be 1</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">CANCELLED</span> <span class="operator">=</span> <span class="number">0x80000000</span>; <span class="comment">// must be negative</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">COND</span>      <span class="operator">=</span> <span class="number">2</span>;          <span class="comment">// in a condition wait</span></span><br></pre></td></tr></table></figure><p>其中 <strong>WAITING</strong> 表示线程在等待，<strong>CANCELLED</strong> 表示线程已取消获取锁(用于实现锁的可中断)，<strong>COND</strong> 表示线程处于一个条件等待的状态。  </p><p>除了 <em>CLH</em> 队列外，<strong>AQS</strong> 中还有一个状态字段，即：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The synchronization state.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="type">int</span> state;</span><br></pre></td></tr></table></figure><p>用于标识锁目前是否被占用，等于 0 则锁空闲，大于 0 则锁被占用。  </p><p>一个获取锁失败的线程会被封装成为一个 <em>Node</em> 对象放入到队列中排队等待获取锁。  </p><p>知道了 <strong>AQS</strong> 的概念，现在我们可以通过 <strong><em>ReentrantLock</em></strong> 加锁的全流程来窥探到 <strong><em>ReentrantLock</em></strong> 的底层原理了。  </p><h2 id="ReentrantLock-加锁流程"><a href="#ReentrantLock-加锁流程" class="headerlink" title="ReentrantLock 加锁流程"></a>ReentrantLock 加锁流程</h2><p>首先是实例化一个 <strong><em>ReentrantLock</em></strong> 锁对象，这里构造函数可带参数，如果参数为 <em>True</em> ，则会实例化一个公平锁，默认为非公平锁，其实区别就在于是实例化了一个 <em>FairSync</em> 对象还是一个 <em>NonFairSync</em> 对象。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 实例化一个锁</span></span><br><span class="line"><span class="type">Lock</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantLock</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 构造函数的实现</span></span><br><span class="line"><span class="comment">// 非公平锁</span></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">ReentrantLock</span><span class="params">()</span> &#123;</span><br><span class="line">    sync = <span class="keyword">new</span> <span class="title class_">NonfairSync</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 公平锁</span></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">ReentrantLock</span><span class="params">(<span class="type">boolean</span> fair)</span> &#123;</span><br><span class="line">    sync = fair ? <span class="keyword">new</span> <span class="title class_">FairSync</span>() : <span class="keyword">new</span> <span class="title class_">NonfairSync</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之后调用 <code>lock()</code> 方法加锁，其实底层是调用了 <em>sync</em> 对象的 <code>lock()</code> 方法来加锁，看到这里，你可能更能理解为什么说 <strong><em>ReentrantLock</em></strong> 的底层实现是高度依赖 <strong>AQS</strong> 的。  </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">lock</span><span class="params">()</span> &#123;</span><br><span class="line">    sync.lock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>sync.lock()</code> 的实现如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title function_">lock</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (!initialTryLock())</span><br><span class="line">        acquire(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里 <code>initialTryLock()</code> 方法是一个抽象方法，实际上调用的是 <em>Sync</em> 这个类的两个子类 <em>FairSync</em> 和 <em>NonFairSync</em> 的重写的 <code>initialTryLock()</code> 方法。  </p><p>我们先看非公平锁 <em>FairSync</em> 的实现：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Sync object for non-fair locks</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">NonfairSync</span> <span class="keyword">extends</span> <span class="title class_">Sync</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">7316153563782823691L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">initialTryLock</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">current</span> <span class="operator">=</span> Thread.currentThread();</span><br><span class="line">        <span class="keyword">if</span> (compareAndSetState(<span class="number">0</span>, <span class="number">1</span>)) &#123; <span class="comment">// first attempt is unguarded</span></span><br><span class="line">            setExclusiveOwnerThread(current);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (getExclusiveOwnerThread() == current) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">c</span> <span class="operator">=</span> getState() + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (c &lt; <span class="number">0</span>) <span class="comment">// overflow</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Error</span>(<span class="string">&quot;Maximum lock count exceeded&quot;</span>);</span><br><span class="line">            setState(c);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Acquire for non-reentrant cases after initialTryLock prescreen</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">tryAcquire</span><span class="params">(<span class="type">int</span> acquires)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (getState() == <span class="number">0</span> &amp;&amp; compareAndSetState(<span class="number">0</span>, acquires)) &#123;</span><br><span class="line">            setExclusiveOwnerThread(Thread.currentThread());</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>非公平锁的 <code>initialTryLock()</code> 方法通过 <em>CAS</em> 尝试加锁(即 <code>compareAndSetState(0, 1)</code>)，如果 <strong>AQS</strong> 的 <em>state</em> 字段为 0 ，则把这个字段变为 1 ，并使用 <code>setExclusiveOwnerThread(current);</code> 将独占锁的线程设置为当前线程即自己，否则加锁失败，失败之后会判断当前独占锁的线程是不是当前线程。如果是的话将 <em>state</em> 加一，同样加锁成功，这里就体现了可重入锁的实现，即同一个线程可以多次获取锁而不阻塞，<em>state</em> 字段其实就是这个线程获取锁的次数。如果这两种情况都没有加锁成功，则认为锁被另一个线程独占，加锁失败，返回 <em>false</em> 。  </p><p>在第一次 <em>CAS</em> 加锁未成功时，会调用 <code>acquire(1)</code> 这个方法，这个方法是 <em>AbstractQueuedSynchronizer</em> 抽象类提供给我们的，接下来我们看看这个方法的实现。  </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title function_">acquire</span><span class="params">(<span class="type">int</span> arg)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (!tryAcquire(arg))</span><br><span class="line">        acquire(<span class="literal">null</span>, arg, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">0L</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先调用 <code>tryAcquire(arg)</code> 方法，这里会去调用具体实现类的 <code>tryAcquire()</code> 方法，同样，我们先看非公平锁的实现，实际上上面已经给出，这里只摘出 <code>tryAcquire()</code> 的实现：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">tryAcquire</span><span class="params">(<span class="type">int</span> acquires)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (getState() == <span class="number">0</span> &amp;&amp; compareAndSetState(<span class="number">0</span>, acquires)) &#123;</span><br><span class="line">        setExclusiveOwnerThread(Thread.currentThread());</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里是尝试了第二次 <em>CAS</em> 加锁，与 <code>initialTryLock()</code> 方法中的逻辑差不多，同样也是做 <em>CAS</em> 尝试，如果成功，将独占这个锁的线程设置为自己，如果不成功则返回 <em>false</em> 。  </p><p>如果第二次 <em>CAS</em> 加锁不成功，则调用 <code>acquire(null, arg, false, false, false, 0L)</code> 方法，这个方法极其重要，它的内部定义了线程如何排队来获取锁的逻辑。  </p><p>下面是这个方法的完整实现，我添加了较为详细的注释便于理解：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="type">int</span> <span class="title function_">acquire</span><span class="params">(Node node, <span class="type">int</span> arg, <span class="type">boolean</span> shared,</span></span><br><span class="line"><span class="params">                  <span class="type">boolean</span> interruptible, <span class="type">boolean</span> timed, <span class="type">long</span> time)</span> &#123;</span><br><span class="line">    <span class="comment">// node 是将要加入 DLH 队列的节点</span></span><br><span class="line">    <span class="comment">// spins 是队头节点在竞争锁时可以自旋的次数</span></span><br><span class="line">    <span class="comment">// interrupted 当前线程是否中断获取锁</span></span><br><span class="line">    <span class="comment">// first 当前线程是否位于队列第一个节点中</span></span><br><span class="line">    <span class="comment">// pred 当前节点的前一个节点</span></span><br><span class="line">    <span class="type">Thread</span> <span class="variable">current</span> <span class="operator">=</span> Thread.currentThread();</span><br><span class="line">    <span class="type">byte</span> <span class="variable">spins</span> <span class="operator">=</span> <span class="number">0</span>, postSpins = <span class="number">0</span>;   <span class="comment">// retries upon unpark of first thread</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">interrupted</span> <span class="operator">=</span> <span class="literal">false</span>, first = <span class="literal">false</span>;</span><br><span class="line">    <span class="type">Node</span> <span class="variable">pred</span> <span class="operator">=</span> <span class="literal">null</span>;                <span class="comment">// predecessor of node when enqueued</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Repeatedly:</span></span><br><span class="line"><span class="comment">     *  Check if node now first</span></span><br><span class="line"><span class="comment">     *    if so, ensure head stable, else ensure valid predecessor</span></span><br><span class="line"><span class="comment">     *  if node is first or not yet enqueued, try acquiring</span></span><br><span class="line"><span class="comment">     *  else if node not yet created, create it</span></span><br><span class="line"><span class="comment">     *  else if not yet enqueued, try once to enqueue</span></span><br><span class="line"><span class="comment">     *  else if woken from park, retry (up to postSpins times)</span></span><br><span class="line"><span class="comment">     *  else if WAITING status not set, set and retry</span></span><br><span class="line"><span class="comment">     *  else park and clear WAITING status, and check cancellation</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 一个大循环，来控制线程对锁的竞争</span></span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="comment">// 如果当前节点不为第一个节点、前一个节点也不为空、头结点也不等于前一个节点</span></span><br><span class="line">        <span class="keyword">if</span> (!first &amp;&amp; (pred = (node == <span class="literal">null</span>) ? <span class="literal">null</span> : node.prev) != <span class="literal">null</span> &amp;&amp;</span><br><span class="line">            !(first = (head == pred))) &#123;</span><br><span class="line">            <span class="comment">// 如果前一个节点状态小于 0，说明前驱是一个取消了获取锁请求的线程</span></span><br><span class="line">            <span class="comment">// 则清理队列，去除掉取消获取锁的节点</span></span><br><span class="line">            <span class="keyword">if</span> (pred.status &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                cleanQueue();           <span class="comment">// predecessor cancelled</span></span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            <span class="comment">// 如果前驱的前驱为空，</span></span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (pred.prev == <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="comment">// 这是一个自旋等待提示，告诉CPU当前线程正在自旋等待，</span></span><br><span class="line">                <span class="comment">// 处理器可以进行一些针对自旋的优化</span></span><br><span class="line">                Thread.onSpinWait();    <span class="comment">// ensure serialization</span></span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果当前节点是第一个节点或者前驱为空，则竞争锁</span></span><br><span class="line">        <span class="keyword">if</span> (first || pred == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="type">boolean</span> acquired;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (shared)</span><br><span class="line">                    acquired = (tryAcquireShared(arg) &gt;= <span class="number">0</span>);</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    <span class="comment">// CAS 获取锁</span></span><br><span class="line">                    acquired = tryAcquire(arg);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Throwable ex) &#123;</span><br><span class="line">                cancelAcquire(node, interrupted, <span class="literal">false</span>);</span><br><span class="line">                <span class="keyword">throw</span> ex;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 如果成功获取到了锁</span></span><br><span class="line">            <span class="keyword">if</span> (acquired) &#123;</span><br><span class="line">                <span class="comment">// 如果还是第一个，把这个节点从队列中拿下来，赋值给 head</span></span><br><span class="line">                <span class="keyword">if</span> (first) &#123;</span><br><span class="line">                    node.prev = <span class="literal">null</span>;</span><br><span class="line">                    head = node;</span><br><span class="line">                    pred.next = <span class="literal">null</span>;</span><br><span class="line">                    node.waiter = <span class="literal">null</span>;</span><br><span class="line">                    <span class="keyword">if</span> (shared)</span><br><span class="line">                        signalNextIfShared(node);</span><br><span class="line">                    <span class="keyword">if</span> (interrupted)</span><br><span class="line">                        current.interrupt();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果当前节点为空</span></span><br><span class="line">        <span class="keyword">if</span> (node == <span class="literal">null</span>) &#123;                 <span class="comment">// allocate; retry before enqueue</span></span><br><span class="line">            <span class="keyword">if</span> (shared)</span><br><span class="line">                node = <span class="keyword">new</span> <span class="title class_">SharedNode</span>();</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="comment">// 创建节点</span></span><br><span class="line">                node = <span class="keyword">new</span> <span class="title class_">ExclusiveNode</span>();</span><br><span class="line">        <span class="comment">// 如果前驱为空，入队</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (pred == <span class="literal">null</span>) &#123;          <span class="comment">// try to enqueue</span></span><br><span class="line">            node.waiter = current;</span><br><span class="line">            <span class="type">Node</span> <span class="variable">t</span> <span class="operator">=</span> tail;</span><br><span class="line">            node.setPrevRelaxed(t);         <span class="comment">// avoid unnecessary fence</span></span><br><span class="line">            <span class="keyword">if</span> (t == <span class="literal">null</span>)</span><br><span class="line">                tryInitializeHead();</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (!casTail(t, node))</span><br><span class="line">                node.setPrevRelaxed(<span class="literal">null</span>);  <span class="comment">// back out</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                t.next = node;</span><br><span class="line">        <span class="comment">// 如果是第一个节点且自旋次数不为 0 自旋次数减，且调用 onSpinWait()</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (first &amp;&amp; spins != <span class="number">0</span>) &#123;</span><br><span class="line">            --spins;                        <span class="comment">// reduce unfairness on rewaits</span></span><br><span class="line">            Thread.onSpinWait();</span><br><span class="line">        <span class="comment">// 如果当前节点状态为 0 ，说明是新节点，初始化状态为 WAITTING</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (node.status == <span class="number">0</span>) &#123;</span><br><span class="line">            node.status = WAITING;          <span class="comment">// enable signal and recheck</span></span><br><span class="line">        <span class="comment">// 重新计算自旋次数，并且由于当前线程自旋次数用完，被 park 住</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="type">long</span> nanos;</span><br><span class="line">            spins = postSpins = (<span class="type">byte</span>)((postSpins &lt;&lt; <span class="number">1</span>) | <span class="number">1</span>);</span><br><span class="line">            <span class="keyword">if</span> (!timed)</span><br><span class="line">                LockSupport.park(<span class="built_in">this</span>);</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((nanos = time - System.nanoTime()) &gt; <span class="number">0L</span>)</span><br><span class="line">                LockSupport.parkNanos(<span class="built_in">this</span>, nanos);</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            node.clearStatus();</span><br><span class="line">            <span class="keyword">if</span> ((interrupted |= Thread.interrupted()) &amp;&amp; interruptible)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> cancelAcquire(node, interrupted, interruptible);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段核心代码的作用在于控制未获得锁的线程入队，同时让队列头部的线程参与争夺锁。需要注意的是，这里的 <em>head</em> 指向抢到锁的线程对应的 _node_。  </p><p>首先第一个 <em>if</em> 中，</p><ol><li>如果发现有取消获取锁的线程，会执行队列清理，</li><li>如果自己是第二个节点，那么会一直自旋来判断前一个线程是否放弃了获取锁，防止队头线程已经放弃了获取锁，而在队列之后的线程还不知道，造成饥饿。</li></ol><p>第二个 <em>if</em> 中，</p><ol><li>如果当前节点是队列中的第一个节点或者前驱为空，则参与争夺锁，调用了 <code>tryAcquire()</code> 方法，也就是说争夺锁的线程只有队列中的第一个 <em>Node</em> 中的线程、刚释放了锁的那个线程以及还尚未进入这个函数的线程（在进入这个函数之前会尝试两次 <em>CAS</em> 来获取锁）。</li></ol><p>第三个 <em>if</em> 中，</p><ol><li>如果当前节点还为空，则实例化一个 _node_，</li><li>如果前驱为空，则入队，</li><li>如果当前节点为队列中第一个节点，且自旋次数(spins)未用尽，则 -1 ，之后接着做下一次自旋</li><li>如果当前节点状态为 0 ，说明是新节点，将状态设置为 WAITTING</li><li>最后 <em>else</em> 中会先计算当前线程的自旋次数 _spins_，并将当前线程 <strong>park</strong> 住</li></ol><p>按照源码中 <em>spins</em> 的计算方法，每当 <em>spins</em> 用尽，下一次的自旋次数为上一次的自旋次数的 2 倍 +1 。  </p><p>可以看到，队列中第一个 <em>node</em> 中的线程等待的时间越长，其可以自旋的次数就会越多，这样可以有效地避免队列中的线程饥饿，因为自旋次数越多，获取锁的概率越大，所以随着等待时间的增加，获取锁的概率其实也是增加的。<strong>JDK17</strong>中是这样的，而在 <strong>JDK8</strong> 中却有所不同，<strong>JDK8</strong> 中线程每次被唤醒只会自旋一次就迅速被 <em>park</em> 住，这样就比较容易造成饥饿。  </p><p>概括来讲整个加锁过程，一个线程首先会自旋两次尝试获取锁，如果这两次都没有获取到锁，则进入到 <code>acquire()</code> 方法的大循环中，队列中的所有在等待的线程都会被 <em>park</em> 住, 直到第一个线程被唤醒，然后开始自旋，直到自旋次数用尽，被再次 <em>park</em> 住……  </p><p>你可能会问，那么谁来唤醒队列中第一个等待的线程呢？当然是刚刚释放锁的那个线程啦~  </p><p>解锁也是调用了 <em>sync</em> 对象的 <code>release()</code> 方法，下面是解锁部分的源码：  </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">unlock</span><span class="params">()</span> &#123;</span><br><span class="line">    sync.release(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">release</span><span class="params">(<span class="type">int</span> arg)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (tryRelease(arg)) &#123;</span><br><span class="line">        signalNext(head);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">tryRelease</span><span class="params">(<span class="type">int</span> releases)</span> &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">c</span> <span class="operator">=</span> getState() - releases;</span><br><span class="line">    <span class="keyword">if</span> (getExclusiveOwnerThread() != Thread.currentThread())</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalMonitorStateException</span>();</span><br><span class="line">    <span class="type">boolean</span> <span class="variable">free</span> <span class="operator">=</span> (c == <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (free)</span><br><span class="line">        setExclusiveOwnerThread(<span class="literal">null</span>);</span><br><span class="line">    setState(c);</span><br><span class="line">    <span class="keyword">return</span> free;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">signalNext</span><span class="params">(Node h)</span> &#123;</span><br><span class="line">    Node s;</span><br><span class="line">    <span class="keyword">if</span> (h != <span class="literal">null</span> &amp;&amp; (s = h.next) != <span class="literal">null</span> &amp;&amp; s.status != <span class="number">0</span>) &#123;</span><br><span class="line">        s.getAndUnsetStatus(WAITING);</span><br><span class="line">        LockSupport.unpark(s.waiter);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>tryRelease()</code> 方法尝试解锁，如果成功解锁，则调用 <code>signalNext()</code> 方法，唤醒队列中的第一个线程，于是队列中的第一个线程就加入到了获取锁的行列中来。  </p><p>这就是 <strong><em>ReentrantLock</em></strong> 加锁过程及其底层原理，你可能会疑惑为什么前面都在讲非公平锁，那公平锁呢？  </p><h2 id="公平锁"><a href="#公平锁" class="headerlink" title="公平锁"></a>公平锁</h2><p>其实公平锁的实现与非公平锁及其类似，只有一处不同，具体可以看公平锁的源码：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Sync object for fair locks</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">FairSync</span> <span class="keyword">extends</span> <span class="title class_">Sync</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> -<span class="number">3000897897090466540L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Acquires only if reentrant or queue is empty.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">initialTryLock</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">current</span> <span class="operator">=</span> Thread.currentThread();</span><br><span class="line">        <span class="type">int</span> <span class="variable">c</span> <span class="operator">=</span> getState();</span><br><span class="line">        <span class="keyword">if</span> (c == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!hasQueuedThreads() &amp;&amp; compareAndSetState(<span class="number">0</span>, <span class="number">1</span>)) &#123;</span><br><span class="line">                setExclusiveOwnerThread(current);</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (getExclusiveOwnerThread() == current) &#123;</span><br><span class="line">            <span class="keyword">if</span> (++c &lt; <span class="number">0</span>) <span class="comment">// overflow</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Error</span>(<span class="string">&quot;Maximum lock count exceeded&quot;</span>);</span><br><span class="line">            setState(c);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Acquires only if thread is first waiter or empty</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">tryAcquire</span><span class="params">(<span class="type">int</span> acquires)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (getState() == <span class="number">0</span> &amp;&amp; !hasQueuedPredecessors() &amp;&amp;</span><br><span class="line">            compareAndSetState(<span class="number">0</span>, acquires)) &#123;</span><br><span class="line">            setExclusiveOwnerThread(Thread.currentThread());</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，与非公平锁不同的是，在公平锁在决定是否要去抢锁之前会有一个额外的判断，也就是会调用 <code>hasQueuedPredecessors()</code> 方法，这个方法的作用在于判断队列中是否有等待处理的线程，如果没有，当前线程才会去抢锁，如果队列中有线程则无法抢锁，这样就保证了，线程可以按照自己在队列中的顺序公平地获得锁。  </p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>拓扑排序</title>
      <link href="/2024/03/25/2024-03-25-Topological-Sorting/"/>
      <url>/2024/03/25/2024-03-25-Topological-Sorting/</url>
      
        <content type="html"><![CDATA[<p>拓扑排序（Topological Sorting）是一种针对有向无环图（DAG）的排序算法。在拓扑排序中，图中的顶点被安排成一个线性序列，使得如果图中存在一条从顶点 u 到顶点 v 的有向边，则在序列中顶点 u 出现在顶点 v 之前。  </p><p>拓扑排序通常用于描述一组任务或事件之间的依赖关系，其中每个任务都有一些前置任务，必须在它们完成后才能执行。通过拓扑排序，我们可以确定一种合理的执行顺序，以确保所有任务都按照其依赖关系得到正确执行。  </p><p>在实现上，拓扑排序可以根据下面的步骤实现：  </p><ol><li>找到入度为 0 的顶点，把这些节点加入到排序结果中，这些节点没有前置任务  </li><li>将已经加入到排序结果中的节点及其相连的边删去，更改图中其他节点的入度  </li><li>重复 1，2 步，直到图中没有入度为 0 的节点</li></ol><p>如果被拓扑排序的图是一个有向无环图，那么所有顶点都会被排序；而如果图中有环，则拓扑排序只会得到一部分的节点序列。  </p><p>因此，拓扑排序也常被用来检测一个图中是否有环。  </p><p>下面是拓扑排序入门的一个经典案例及其代码实现（_2024春招字节跳动暑期实习一面代码题_）：</p><blockquote><p><strong>题目描述</strong>: 一共有 n 门课你可以选，从课程0，1到课程 n-1 。 有一个数组 p ,  p[i] &#x3D; [a, b]  表示你必须要先修完课程 b 才可以修课程 a 。 请写一个方程返回 true &#x2F; false 表示你是否能修完所有的课程。  </p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ymiir;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">topologicalSorting</span><span class="params">(<span class="type">int</span> n, <span class="type">int</span>[][] graph)</span>&#123;</span><br><span class="line">        <span class="comment">// 创建入度数组，存储每个节点的入度</span></span><br><span class="line">        <span class="type">int</span>[] inDegree = <span class="keyword">new</span> <span class="title class_">int</span>[n];</span><br><span class="line">        <span class="comment">// 邻接矩阵</span></span><br><span class="line">        Map&lt;Integer, List&lt;Integer&gt;&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        <span class="comment">// 入度数组置 0</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            inDegree[i] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 初始化邻接矩阵和入度数组</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;graph.length;i++)&#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">node</span> <span class="operator">=</span> graph[i][<span class="number">0</span>];</span><br><span class="line">            <span class="type">int</span> <span class="variable">pre</span> <span class="operator">=</span> graph[i][<span class="number">1</span>];</span><br><span class="line">            inDegree[node]++;</span><br><span class="line">            map.computeIfAbsent(pre, k-&gt;<span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;()).add(node);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 创建队列并初始化队列，将入度为 0 的节点入队，用于拓扑排序</span></span><br><span class="line">        Queue&lt;Integer&gt; queue = <span class="keyword">new</span> <span class="title class_">ArrayDeque</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(inDegree[i]==<span class="number">0</span>)&#123;</span><br><span class="line">                queue.offer(i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 拓扑排序</span></span><br><span class="line">        <span class="comment">// count 用于记录拓扑排序遍历到的节点</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(!queue.isEmpty())&#123;</span><br><span class="line">            <span class="comment">// 一个元素出队</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">temp</span> <span class="operator">=</span> queue.poll();</span><br><span class="line">            count++;</span><br><span class="line">            <span class="comment">// 如果邻接矩阵中有</span></span><br><span class="line">            <span class="keyword">if</span>(map.containsKey(temp))&#123;</span><br><span class="line">                <span class="comment">// 删掉当前元素及与之相连的边，具体表现在子节点入度 -1</span></span><br><span class="line">                <span class="keyword">for</span>(<span class="type">int</span> v : map.get(temp))&#123;</span><br><span class="line">                    inDegree[v]--;</span><br><span class="line">                    <span class="comment">// 如果调整之后入度为 0 ，则可以放入拓扑排序序列，入队</span></span><br><span class="line">                    <span class="keyword">if</span>(inDegree[v]==<span class="number">0</span>)&#123;</span><br><span class="line">                        queue.add(v);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果拓扑排序遍历到了所有的节点，则说明可以修完所有的课</span></span><br><span class="line">        <span class="keyword">return</span> count==n;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">int</span>[][] graph = ;</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">flag</span> <span class="operator">=</span> topologicalSorting(<span class="number">4</span>,graph);</span><br><span class="line">        System.out.println(flag);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring框架的理解与总结</title>
      <link href="/2024/03/09/2024-03-10-Spring-understanding&amp;summary/"/>
      <url>/2024/03/09/2024-03-10-Spring-understanding&amp;summary/</url>
      
        <content type="html"><![CDATA[<p><strong>Spring</strong> 是 <code>Java</code> 生态中一个举足轻重的框架，大大简化了开发，它的主要核心特性包括两个，分别是 <strong>控制反转</strong> 以及 <strong>依赖注入</strong>。  </p><h3 id="控制反转"><a href="#控制反转" class="headerlink" title="控制反转"></a>控制反转</h3><p><strong><em>Inversion of control</em></strong> ，简写为 <strong><em>IoC</em></strong> ，译为 <strong>控制反转</strong>，是一种设计思想，它将对象的 <strong>创建</strong> 和 <strong>管理</strong> 交给了 <code>Spring</code> 来管理，更具体地说，是交给了 <strong><em>IoC</em></strong> 容器来管理。  </p><p><strong><em>IoC</em></strong> 容器是控制反转的一个实现，它存放着开发者交给 <code>Spring</code> 管理的对象，其底层是一个 <code>Map</code>。</p><p><strong><em>IoC</em></strong> 的好处是可以帮我们管理对象间的依赖关系，隐藏了对象的创建逻辑，当我们需要一个对象实例时直接去问 <code>Spring</code> 要就行了。这样降低了依赖，减小了耦合。比方说 <strong>A</strong> 类中依赖了 <strong>B</strong> 类，如果没有 **<em>控制反转</em>**， <strong>A</strong> 类需要自己去在代码中创建对象 <strong>B</strong> 的实例，倘若对象 <strong>B</strong> 的构造函数或者说具体实现在之后有改变，那么所有依赖了 <strong>B</strong> 类的地方代码都需要重新改，依赖关系比较简单还好，如果依赖关系错综复杂，那简直无处下手。  </p><p>常常与 <strong><em>控制反转</em></strong> 一起出现的一个概念叫做 <strong><em>依赖注入</em></strong> ，即 <strong><em>Dependency Injection</em></strong> ，简称 <strong><em>DI</em></strong> 。 <strong><em>依赖注入</em></strong> 指程序运行过程中，如果需要依赖另一个对象，那么无需创建这个对象，而是通过外部的注入。**<em>依赖注入</em>** 是 <strong><em>IoC</em></strong> 最常见的一种实现方式。  </p><h3 id="Spring-Bean"><a href="#Spring-Bean" class="headerlink" title="Spring Bean"></a>Spring Bean</h3><p>简单来讲，**<em>Spring Bean</em>** 指的就是那些被 <strong><em>IoC</em></strong> 容器管理的 <code>Java</code> 对象。  </p><p>如果我们想告诉 <code>Spring</code> 哪些对象想要交给它管理，就要进行配置，通常有三种方式，分别是 <strong>XML配置</strong>、<strong>注解</strong> 以及 <strong>Java配置类</strong> 。  </p><p><strong><em>XML配置</em></strong> 方式通过在项目的 <code>resources</code> 文件夹下编写 <code>Spring</code> 配置文件来实现配置以及依赖注入，分别通过 <code>bean</code> 标签和 <code>property</code> 标签来完成，基于 <strong><em>XML配置</em></strong> 的方式并不方便所以不常用，此处略去。  </p><p>基于 <strong><em>注解</em></strong> 来配置更加方便，是常用的方式。  </p><h4 id="基于注解配置"><a href="#基于注解配置" class="headerlink" title="基于注解配置"></a>基于注解配置</h4><p>首先需要在 <code>Spring</code> 配置文件中开启组件扫描，<code>Spring</code> 会自动扫描指定的包及其子包下的所有类，如果类上有相关注解，会执行相应的操作。  </p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">&quot;包路径&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">context:component-scan</span>&gt;</span></span><br></pre></td></tr></table></figure><p>使用注解定义对象，将注解标注在 <code>Java</code> 类上，将它们定义为 <code>Spring Baen</code> ，具体来说，有以下四个注解都可以用来创建类。  </p><p><strong>@Component</strong> 、 <strong>@Repository</strong> 、 <strong>@Service</strong> 以及 <strong>@Controller</strong>  </p><p>这四个注解的功能都是相同的，不同之处仅有含义的区分，其中 <strong>@Component</strong> 是通用的，**@Repository** 用在数据访问层（DAO层），**@Service** 用在业务层，而 <strong>@Controller</strong> 用在控制层。  </p><p>与这四个注解不同的是，还有一个同样可以实现将一个对象标注为 <code>SpringBean</code> 的注解是 <strong>@Bean</strong>  </p><p><strong>@Bean</strong> 与 <strong>@Component</strong> 有什么区别呢？具体表现在以下方面：  </p><ol><li>前者作用于方法，而后者作用于类</li><li>后者是通过开启组件扫描从而自动装配的，而前者标注在方法上，在方法中产生了 <em><strong>Bean</strong></em> ，告诉 <code>Spring</code> 你来帮我管理这个 <em><strong>Bean</strong></em></li><li>当我们想要将第三方包中的类装配到 <code>Spring</code> 中时，则只能通过 <strong>@Bean</strong> 来实现</li></ol><p><strong><em>属性注入</em></strong> 的实现依赖于两个注解，分别是 <strong>@Autowired</strong> 以及 <strong>@Resource</strong></p><p><strong>@Autowired</strong> 默认根据数据类型装配，也就是说在 <strong><em>IoC</em></strong> 容器中选择匹配的类型注入  </p><p>这个注解可以被用在 <strong>构造方法上</strong> 、 <strong>方法上</strong> 、 <strong>形参上</strong> 、 <strong>属性上</strong> 以及 <strong>注解上</strong>  </p><p>较为常用的方式是 <strong>在属性上</strong> 以及 在 <strong>属性的<code>set</code>方法</strong> 上写 <strong>@Autowired</strong> 注解来实现依赖注入  </p><p>默认来讲，**@Autowired** 是根据类型注入的，但是当一个接口拥有两个实现类时，就无法使用基于类型注入了，所以需要 <strong>@Autowired</strong> 配合 <strong>@Qualifier</strong> 注解实现基于名称的注入</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Qualifier(value = &quot;&quot;)</span></span><br></pre></td></tr></table></figure><p>另有一注解 <strong>@Resource</strong> 也可以实现属性注入，它不是 <code>Spring</code> 的注解，而是属于 <code>JDK</code> 扩展包，可以用在 <strong>属性上</strong> 以及 <strong>set方法上</strong> ，它默认根据名称进行装配（指定 <code>name</code> 属性），若未指定名称，则按照属性名进行装配，如果通过名称找不到，则会根据类型装配  </p><p>前面提到 <strong>基于注解配置</strong> 中要在 <code>Spring</code> 配置文件中配置开启组件扫描，如果想要实现全注解的开发，就要使用 <strong>Java配置类</strong> 来进行配置  </p><p>写一个配置类，上使用注解 <strong>@Configuration</strong> 标明这是一个配置类，再添加一个注解 <strong>@ComponentScan()</strong> 括号中填写想要扫描的包名 <strong>开启组件扫描</strong> ，这样就代替了 <code>Spring</code> 配置文件  </p><h4 id="Bean的作用域"><a href="#Bean的作用域" class="headerlink" title="Bean的作用域"></a>Bean的作用域</h4><p>这里只介绍常见的两种，分别是 <em><strong>singleton</strong></em> 以及 <em><strong>prototype</strong></em> </p><p><em><strong>singleton</strong></em> 是单例模式，这是 <code>Spring</code> 默认的 <strong>Bean</strong> 作用域，这样的 <strong>Bean</strong> 在整个 <em><strong>IoC</strong></em> 容器中只有一个实例  </p><p><em><strong>prototype</strong></em> 每次获取都会创建一个新的 <strong>Bean</strong> 实例，它不是单例的  </p><p>配置 <strong>Bean</strong> 作用域的方法在于使用 <strong>@Scope</strong> 注解，此注解的 <code>value</code> 属性标识这个 <strong>Bean</strong> 的作用于  </p><p>未完待续……</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Raft 共识算法总结</title>
      <link href="/2024/02/13/2024-02-13-Raft-Algo-Summary/"/>
      <url>/2024/02/13/2024-02-13-Raft-Algo-Summary/</url>
      
        <content type="html"><![CDATA[<p><em><strong>Raft</strong></em> 算法是目前应用广泛的分布式共识算法，在许多知名的开源项目比如 <em>etcd</em> 中，都有 <em><strong>Raft</strong></em> 的身影。同时，随着 <em>MIT6.824</em> 课程的普及，_<strong>Raft</strong>_ 俨然成为了最广为人知的分布式共识算法。  </p><p><em><strong>Raft</strong></em> 的设计动机之一就是为解决 <em>Paxos</em> 算法的难以理解性，因此 <em><strong>Raft</strong></em> 的一个大的特性就是易于理解。  </p><p>直接啃论文是困难的，本文旨在以简洁的文字总结 <em><strong>Raft</strong></em> 算法，让第一次认识 <em><strong>Raft</strong></em> 算法的同学也可以很快有一个整体上的理解。  </p><blockquote><p><em><strong>Raft is a consensus algorithm for managing a replicated log.</strong></em></p></blockquote><p>上面这句话引自 <em><strong>Raft</strong></em> 论文，即 <em><strong>Raft</strong></em> 是一个用于管理<strong>复制式日志</strong>的<strong>共识</strong>算法。  </p><p>这里有两个问题，什么是复制式日志？什么是共识？</p><hr><p><strong>复制式日志（ <em>replicated log</em> ）</strong>  </p><p>与复制式日志紧密相关的一个概念是 <strong>复制式状态机（ <em>Replicated state machines</em> ）</strong>  </p><p><strong>复制式状态机</strong> 用于解决分布式系统中的 <strong>容错（ <em>fault tolerance</em> ）</strong> 问题，通常采用 <strong>复制式日志</strong> 实现，这里的容错是如何解决的呢？<strong>复制</strong>！日志中包含了对系统或者数据的操作（类似于 <em>Mysql</em> 的 <em>undo log_、_redo log</em> 等等），当日志只应用于单个节点上时，会有单点故障问题，一旦这个节点挂了，那么我的数据或者服务也就挂掉了；但是如果在多个节点上复制同样的日志，做同样的操作，那么即使有节点挂掉了，别的节点还在，我的数据或者服务依然可以为客户端所用，这使得整个系统具备了一定的容错性（除非所有保存相同日志的节点同时都挂了，但概率微乎其微）。  </p><p><strong>共识（ <em>consensus</em> ）</strong>  </p><p>共识问题是分布式系统中的核心问题，通俗来讲，<strong>共识</strong> 指：</p><blockquote><p><em>Several computers (or nodes) achieve consensus if they all agree on some value.</em></p></blockquote><p><em><strong>许多计算机（或者节点）都认可同一个值，那么称他们达成了共识。</strong></em>  </p><p>那么如何让这么多的节点都认可同一个值呢？像 <em><strong>Raft</strong></em> 这样的共识算法就是为此而设计的。  </p><hr><p>如图所示，这是一个 <strong>复制式状态机</strong> 的示意图：  </p><p><a href="https://imgse.com/i/pF8NS7n"><img src="https://s11.ax1x.com/2024/02/13/pF8NS7n.md.png" alt="复制式状态机"></a>  </p><p>它包含 <strong>共识模块（Consensus Module）</strong> 、<strong>日志（Log）</strong> 以及 <strong>状态机（State Machine）</strong> 。它的具体工作流程如下，首先客户端与 <strong>共识模块</strong> 通信提交日志，随后 <strong>共识模块</strong> 将日志复制到其他节点的 <strong>复制式状态机</strong> 中，最后所有节点将日志提交给状态机执行。  </p><p>这里的 <strong>共识模块</strong> 采用的就是 <em><strong>Raft</strong></em> 这样的共识算法，它来保证各个节点上 <strong>日志</strong> 的一致性。一个共识算法应该做到可以 <strong>保证所有节点上的状态机以相同的顺序执行相同的日志，最后得到相同的状态，产生相同的结果，达成共识</strong> 。  </p><p>一个分布式共识算法，它应该具有以下 <strong>典型特征</strong> ：  </p><ol><li>在非拜占庭条件下保证安全（从不返回错误结果），非拜占庭条件指的是不考虑恶意节点的情况，但是包括网络延迟、分区、丢包、重复以及乱序等情况  </li><li>可以容忍小于集群中 <strong>1&#x2F;2</strong> 数量的节点挂掉，但系统整体功能完全正常  </li><li>节点崩溃后可恢复</li><li>不依赖时序来保证日志的一致性  </li><li>一条命令受到集群大多数节点的响应时，这条命令就算完成，少量响应慢的机器不影响整体系统的性能</li></ol><p>以上便是共识算法的作用、特征及其在分布式系统中的地位，下面探讨分布式共识算法 <em><strong>Raft</strong></em> 的实现。  </p><p>整体上来讲，_<strong>Raft</strong>_ 算法可以分为几个模块，分别是：<strong>领导选举（ <em>Leader election</em> ）</strong>，<strong>日志复制（ <em>Log replication</em> ）</strong> 以及 <strong>安全性（Safety）</strong> 。  </p><p>一个运行着 <em><strong>Raft</strong></em> 算法的集群，会选举出来一个 <em><strong>Leader</strong></em> ，这个 <em><strong>Leader</strong></em> 全权负责日志的复制并将日志应用于状态机，这样简化了 <strong>日志复制</strong> ，所有的日志流动是单向的，只会从 <strong>Leader</strong> 流向其他节点。  </p><p>在 <em><strong>Raft</strong></em> 集群中，任意时刻，每个节点都处于下述三种状态之一：_<strong>leader</strong><em>,</em><strong>follower</strong>_ 和 <em><strong>candidate</strong></em> 。</p><ol><li><em><strong>leader</strong></em> ：正常情况下，集群中同一时间只会有一个 <em><strong>leader</strong></em>  </li><li><em><strong>follower</strong></em> ：_<strong>follower</strong>_ 是被动的，只会响应 <em><strong>leader</strong></em> 和 <em><strong>candidate</strong></em> 的 <code>RPC</code> 消息  </li><li><em><strong>candidate</strong></em> ：在选举新的 <em><strong>leader</strong></em> 时会用到，是竞选 <em><strong>leader</strong></em> 的候选人</li></ol><p>在 <em><strong>Raft</strong></em> 集群的初始状态，所有的节点状态都是 <em><strong>follower</strong></em> ，如果直到 <strong>election timeout</strong> 都没有收到来自 <strong>leader</strong> 的 <code>AppendEntries RPC</code>，也没有投票给某个 <em><strong>candidate</strong></em> ， 则自动转入 <em><strong>candidate</strong></em> 状态。  </p><p><em>注：<strong>election timeout</strong> 是选举超时时间，如果超过了这个时间还没有产生 <strong>leader</strong>，则认为目前没有 <strong>leader</strong> ，那么他自己成为 <strong>candidate</strong> ，请求投票竞选 <strong>leader</strong>；<code>AppendEntries RPC</code>是 <strong>leader</strong> 请求其他节点增加日志条目的 <code>RPC</code>消息；<strong>election timeout</strong> 是从一个范围内随机选取的，目的是为了避免两个节点同时变成 <strong>candidate</strong> 选举失败或者形成集群的分裂</em>  </p><p>转为 <em><strong>candidate</strong></em> 之后，立即开始选举，首先增大 <em><strong>term</strong></em> ，然后投票给自己，设置选举定时器，最后发送 <code>RequestVote RPC</code> 给所有其他节点。如果收到大多数节点的赞成票，则成为 <em><strong>leader</strong></em> ，如果收到了新 <em><strong>leader</strong></em> 的 <code>AppendEntries RPC</code> ，则转为 <em><strong>follower</strong></em> ，如果 <strong>election timeout</strong> ，则再次开始选举。  </p><p><em>注：<strong>term</strong> 是 <strong>任期</strong> ，<strong>Raft</strong> 将时间分为长度不定的任期，任期使用连续的整数表示，每一次选举的时候任期都会增加。任期是一个逻辑时钟，用于让各节点检测过期信息。每个节点都会存放当前任期，节点之间通信会携带任期号，如果一个节点发现自己任期落后，就更新任期；如果一个 <em><strong>candidate</strong></em> 或者一个 <em><strong>leader</strong></em> 发现自己的任期过期，则自动切换为 <strong>follower</strong> ；如果节点收到了携带过期任期号的请求，会拒绝这个请求。<code>RequestVote RPC</code> 是 <strong>candidate</strong> 用来请求投票的 <code>RPC</code> 消息，一个节点在相同任期内只能投出一票</em>  </p><p>当一个 <em><strong>candidate</strong></em> 赢得选举后，它成为 <em><strong>leader</strong></em> ，同时向其他节点发送心跳消息，建立权威。之后 <em><strong>leader</strong></em> 开始服务客户端请求，每收到一条来自客户端的日志，_<strong>leader</strong>_ 首先首先把这条日志追加到自己的 <strong>log</strong> ，然后通过发送 <code>AppendEntries RPC</code> 消息将日志复制给其他节点。复制成功之后，_<strong>leader</strong>_ 才会将这个日志条目应用到自己的状态机，并给客户端响应。_<strong>leader</strong>_ 会对失联或者很慢的节点无限重试 <code>AppendEntries RPC</code>，直到所有的 <strong>follower</strong> 都复制了所有的日志.  </p><p><em><strong>Raft</strong></em> 的日志结构如下图所示：  </p><p><a href="https://imgse.com/i/pF8wk5R"><img src="https://s11.ax1x.com/2024/02/13/pF8wk5R.md.png" alt="raft 日志结构"></a>  </p><p>日志由日志条目组成，日志条目被顺序编号，标识其在日志中的索引（ <strong>log index</strong> ），每个日志条目也携带 <strong>term</strong> ，图中位于最上方整数的便为日志索引，每条日志中的整数则为 <strong>term</strong> ，而日志中类似于 <code>x&lt;-3</code> 的则为日志内容，日志内容会在日志复制成功后应用到状态机。  </p><p>什么是 <strong>committed entries</strong> ? 简单来说，就是已提交日志条目，那么什么是提交（ <strong>commit</strong> ）呢？  </p><p>只要这个日志条目已经在大多数节点上复制了，就认为这条日志已经提交了；<strong>这也暗含着，这个日志条目之前的所有日志条目都是已提交的</strong>。_<strong>follower</strong>_ 一旦确定某个日志条目被提交了，就将这个日志条目应用到自己的状态机。  </p><p>这样的设计可以保证不同节点的日志内容一致，称为 <strong>Log matching</strong> 。如果两份日志中有两个日志条目，他们的 <strong>log index</strong> 和 <strong>term</strong> 都相同，那么可以认为：  </p><ol><li>这两个日志条目一定包含了<strong>相同的命令</strong>。因为在给定 <strong>log index</strong> 和 <strong>term</strong> 的情况下，只可以定位到一个日志条目，所以如果存在，那么他们的内容一定相同。  </li><li>在这两份日志中，从该 <strong>log index</strong> <strong>往前的所有日志条目其内容都相同</strong>。这是通过 <code>AppendEntries RPC</code> 中简单的一致性检查来保证的，<code>AppendEntries RPC</code> 会携带上一条日志的 <strong>log index</strong> 和 <strong>term</strong> 信息，如果 <em><strong>flowwer</strong></em> 的日志的前一条日志并不与之相符，那么它会拒绝新的日志条目。</li></ol><p>所以，如果一个 <em><strong>follower</strong></em> 接受了某一条日志，这意味着这条日志与 <em><strong>leader</strong></em> 的是一致的，也意味着前一条日志与 <em><strong>leader</strong></em> 是一致的，以此类推，它的整个日志都与 <em><strong>leader</strong></em> 是一致的。  </p><p>在系统运行过程当中，由于 <em><strong>leader</strong></em> 挂掉等原因，会导致节点间的日志不一致，如何处理日志不一致呢？  </p><p><em><strong>Raft</strong></em> 的解决方式是使用 <em><strong>leader</strong></em> 的日志覆盖 <em><strong>follower</strong></em> 的日志，一旦发现 <em><strong>follower</strong></em> 中的日志与 <em><strong>leader</strong></em> 不一致，就会采取行动。  </p><ol><li>首先找到 <em><strong>leader</strong></em> 与 <em><strong>follower</strong></em> 最后一个共同认可的日志条目（ <strong>这暗示着这条日志以及之前的日志都一致，所以不用管</strong>）  </li><li>将 <em><strong>follower</strong></em> 中从这条日志之后的日志都删除  </li><li>将 <em><strong>leader</strong></em> 中从这条日志之后的日志都同步给 <em><strong>follower</strong></em></li></ol><p>这里有一个需要注意的特性是，**<em>leader</em> 永远不会覆盖或者删除自己日志中的记录**。  </p><p>这里，你可能会有疑问，如果 <em><strong>leader</strong></em> 自己的记录就并不完整呢（也就是说选举出来的 <em><strong>leader</strong></em> 并没有包含全部的之前已经提交过的日志条目）？  </p><p>幸运的是，_<strong>Raft</strong>_ 已经考虑到了这点，它要求一个 <strong>term</strong> 的 <em><strong>leader</strong></em> 必须包含之前所有 <em><strong>leader</strong></em> 已经提交的日志，也就是说，当选 <em><strong>leader</strong></em> 的节点，它的日志条目一定是系统中最新的。  </p><p>在请求投票时，<code>RequestVote RPC</code> 会包含发送方的日志信息，如果接收方发现自己的日志比发送方还要新，就会拒绝发送方成为 <em><strong>leader</strong></em> 的请求。  </p><p>为了解决集群节点数量变化可能导致的集群分裂问题， <em><strong>Raft</strong></em> 采用两阶段方式，集群首先切换到一个 <strong>联合共识（ <em>joint consensus</em> ）</strong> 的 <strong>事务型配置（ <em>transitional configuration</em> ）</strong> ，一旦联合共识提交，系统就切换到 <strong>新配置</strong> 。在这个过程中，集群不会丢失可用性，仍然能继续服务客户端请求。  </p><p>在 <em><strong>Raft</strong></em> 集群中，客户端会将所有的请求都发给 <em><strong>leader</strong></em> ，但是很多时候客户端并不知道 <em><strong>leader</strong></em> 是谁，那怎么办？ 实际上，客户端会随机选择一个 <em><strong>Raft</strong></em> 节点进行连接，如果连接的节点是 <em><strong>leader</strong></em> ，它会直接处理请求；如果连接的节点不是 <em><strong>leader</strong></em> ，则会拒绝这个请求，并把连接重定向到 <em><strong>leader</strong></em> 。  </p><p>至此，分布式共识算法 <em><strong>Raft</strong></em> 的核心机制已经在本文中探讨了，如果有问题，可在评论区讨论~  </p><p>下面我们讨论一下 <em><strong>Raft</strong></em> 算法的一致性保证，_<strong>Raft</strong>_ 号称是可以保证 <strong>强一致性</strong> 的算法，我们先来看看强&#x2F;弱一致性的定义：  </p><blockquote><p><em><strong>Strong consistency</strong> – ensures that only consistent state can be seen.</em></p><ul><li><em>All replicas return the same value when queried for the attribute of an object All replicas return the same value when queried for the attribute of an object. This may be achieved at a cost – high latency.</em></li></ul></blockquote><p><strong>强一致性</strong> 保证只有一致性的状态才能被客户端看到，也就是说，查询所有副本返回的数据应该是一致的，但是这也会带来代价——较高的延迟。  </p><blockquote><p><em><strong>Weak consistency – for when the “fast access” requirement dominates.</strong></em>  </p><ul><li><em>update some replica, e.g. the closest or some designated replica</em>  </li><li><em>the updated replica sends up date messages to all other replicas</em>  </li><li><em>different replicas can return different values for the queried attribute of the object the value should be returned, or “not known”, with a timestamp</em>  </li><li><em>in the long term all updates must propagate to all replicas …….</em>  <ul><li><em>consider failure and restart procedures,</em>  </li><li><em>consider order of arrival,</em>  </li><li><em>consider possible conflicting updates consider possible conflicting updates</em></li></ul></li></ul></blockquote><p><strong>弱一致性</strong> 适用于需要低延迟的场景，它首先更新一个副本，由这个副本去更新其他的副本，不同的副本会返回不一致的数据，<strong>GFS（ The Google File System ）</strong> 就采用了这样仅保证弱一致性的算法。  </p><p><em><strong>Raft</strong></em> 是保证强一致性的，也就是说，在日志 <strong>提交（ <em>commit</em> ）</strong> 之后，我们去访问 <em><strong>Raft</strong></em> 集群，得到的返回一定是最新的且一致的。  </p><p>实际上，_<strong>Raft</strong>_ 在大多数节点都成功复制了一条日志之后，就认为这条日志已经提交了，很显然，此时集群中的所有节点的日志并不止一致的，那么 <em><strong>Raft</strong></em> 的强一致性是如何保证的呢？  </p><p>我认为这是由客户端仅与 <em><strong>leader</strong></em> 通信保证的，虽然客户端可以连接集群中的任意一个节点，但是最后都会被转发给 <em><strong>leader</strong></em> ，_<strong>Raft</strong>_ 通过 <em><strong>leader</strong></em> 来保证 <strong>强一致性</strong> ，即实现访问的一定是最新的数据，且每次访问得到的结果都是一致的。  </p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>The Google File System</title>
      <link href="/2024/02/12/2024-02-12-GFS-/"/>
      <url>/2024/02/12/2024-02-12-GFS-/</url>
      
        <content type="html"><![CDATA[<p>今天看了<a href="https://pdos.csail.mit.edu/6.824/papers/gfs.pdf">The Google File System</a>的论文，我们简称其为GFS。GFS是谷歌的分布式文件存储系统，这篇论文是现代分布式软件系统入门的经典论文，并由此诞生了Hadoop生态中HDFS的开源实现。  </p><p>我不会一字一句地翻译这篇论文，因为我并不是想实现这样一个系统，我打算将一些关键点提炼出来以供学习。  </p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><blockquote><p>GFS shares many of the same goals  as previous distributed file systems such as performance,  scalability, reliability, and availability.</p></blockquote><p>GFS与之前的分布式文件系统有着许多共同的目标，比如性能、可扩展性、可靠性和可用性。  </p><p>但是，Google在实践中提出了与早期分布式文件系统不同的设计。  </p><p>首先，组件失效是常态而不是例外。因此，<strong>持续监控(constant monitoring)<strong>、</strong>错误检测(error detection)<strong>、</strong>容错( fault<br>tolerance)<strong>和</strong>自动恢复(automatic recovery)</strong> 必须是系统的组成部分。  </p><p>其次，文件很大，几个GB的文件是很常见的。但是把他们分成KB大小的文件(数量可以达到上亿个)来管理是难以处理的。因此需要重新设计IO操作和块大小。  </p><p>第三，大多数文件被修改的方式是追加新数据而不是重写已存在数据。文件中的随机写入实际上是不存在的。一旦写入，文件就只能被读取，而且通常只能按顺序读取。考虑到这种对大文件的访问模式，追加成为性能优化和原子性保证的重点。  </p><p>第四，共同设计应用程序和文件系统API可以增加我们的灵活性，从而使整个系统受益。例如，我们使用弱一致性模型，以简化文件系统。我们还引入了原子追加操作，以便多个客户机可以并发地追加到一个文件，而无需在它们之间进行额外的同步。  </p><h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><h3 id="假设"><a href="#假设" class="headerlink" title="假设"></a>假设</h3><p>以下假设来指导我们设计一个符合需求的文件系统：</p><ol><li><p>该系统由许多经常失效的组件构建而成。它必须不断地监控自身，并在常规基础上检测、容忍组件故障，并迅速从组件故障中恢复。  </p></li><li><p>系统存储适当数量的大文件。我们期望有几百万个文件，每个文件的大小通常为100mb或更大。几GB大小的文件是常见的情况，应该有效地管理。必须支持小文件，但我们不需要针对它们进行优化。  </p></li><li><p>工作负载主要由两种类型的读取（操作）组成：大规模流读取和小规模随机读取。在大规模流读取操作中，单次操作通常读取数百KB大小，更常见的是1M或者更多。来自同一客户端的连续操作经常读取某一文件的一个连续区域。小规模的随机读取通常在任意偏移位置读取若干KB大小。  </p></li><li><p>这些工作负载还有许多大的、顺序的写操作，将数据追加到文件中。文件一旦写入，就很少再被修改。支持在文件中的任意位置进行小的写操作，但不一定要高效。  </p></li><li><p>系统必须有效地为并发追加到同一文件的多个客户端实现定义良好的语义。  </p></li><li><p>高持续带宽比低延迟更重要。我们的大多数目标应用程序都重视以高速率批量处理数据，而很少有对单个读或写有严格的响应时间要求。</p></li></ol><h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p>GFS提供了熟悉的文件系统接口。文件在目录中按层次组织，并由路径名标识。GFS支持常见的操作来 <em><strong>create</strong></em>, <em><strong>delete</strong></em>,  <em><strong>open</strong></em>, <em><strong>close</strong></em>, <em><strong>read</strong></em>, 和 <em><strong>write</strong></em> 文件.  </p><p>GFS还有快照(<em><strong>snapshot</strong></em>)和记录追加(<em><strong>record append</strong></em>)操作。 <em><strong>snapshot</strong></em> 以低开销创建文件或者目录的副本。_<strong>record append</strong>_ 确保每个单独客户端 <code>append</code> 的原子性，允许多个客户端并发地向相同的文件追加数据。  </p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>GFS集群由单个 <em><strong>master</strong></em> 和多个 <em><strong>chunkservers</strong></em> 组成，并且可以被多个 <em><strong>clients</strong></em> 访问，如图1所示。  </p><p><a href="https://imgse.com/i/pPdLyfe"><img src="https://s1.ax1x.com/2023/08/30/pPdLyfe.png" alt="pPdLyfe.png"></a>  </p><p>这些机器都是运行用户层面服务进程的普通的Linux机器。</p><p>文件被划分成固定大小的 <em><strong>chunks</strong></em> 。每个 <strong>chunk</strong> 由一个不可变且全局唯一的 64 位 <strong>chunk handle</strong> 标识，是在 <strong>chunk</strong> 创建时由 <strong>master</strong> 分配的。</p><p><em><strong>Chunkservers</strong></em> 将 <strong>chunks</strong> 作为 <em>Linux</em> 文件存储在本地磁盘，通过指定的 <strong>chunk handle</strong> 和 <strong>byte range</strong> 读写 <strong>chunk</strong> 数据。为了提高可靠性，每个 <strong>chunk</strong> 被复制到多个 <strong>chunkservers</strong> 上。默认情况下，存储三个副本，不过用户可以为 <em><strong>file namespace</strong></em> 的不同区域指定不同的复制级别。  </p><p><em><strong>master</strong></em> 维护所有文件系统元数据(<em><strong>metadata</strong></em>)。包括 <strong>namespace</strong> 、访问控制信息、<strong>files</strong> 到 <strong>chunks</strong> 的映射以及 <strong>chunks</strong> 的当前位置。它还控制系统范围的活动，如 <strong>chunk lease management</strong> 、孤立 <strong>chunks</strong> 的垃圾回收和 <strong>chunkservers</strong> 之间的 <strong>chunks</strong> 迁移。_<strong>master</strong>_ 定期使用 <em>HeartBeat</em> 消息与每个 <strong>chunkserver</strong> 通信，给它指令并且收集它的状态。  </p><p>连接到每个应用程序中的 <em><strong>GFS client</strong></em> 代码实现文件系统 <strong>API</strong> ，并与 <em><strong>master</strong></em> 和 <em><strong>chunkserver</strong></em> 通信，以代表应用程序读取或写入数据。_<strong>Clients</strong>_ 与 <em><strong>master</strong></em> 交互以进行元数据操作，但是所有承载数据的通信都直接通过 <em><strong>chunkservers</strong></em> 。  </p><p><em><strong>client</strong></em> 和 <em><strong>chunkserver</strong></em> 都不缓存文件数据。客户端缓存提供的好处很少，因为文件很大，无法缓存。这样可以消除缓存一致性问题，简化系统，<strong>但是客户端会缓存 <em>metadata</em></strong> 。_<strong>chunkserver</strong>_ 不需要缓存文件数据，因为 <strong>chunks</strong> 被存储为本地文件，因此 <em>Linux</em> 的 <em>buffer cache</em> 已经将频繁访问的数据保存在内存中。  </p><p><em>博主注：这里的 <code>namespace</code> 可能让人一头雾水，我们见过了太多的 <code>&#39;namespace&#39;</code> ，在 Linux 系统中，在 C++ 中，不同的语境下其含义各不相同，但是其大体意思都是一致的，即 <strong>隔离</strong> 。借助 <strong>wikipedia</strong> 上的定义：</em></p><blockquote><p><em>A namespace in computer science (sometimes also called a name scope) is an abstract container or environment created to hold a logical grouping of unique identifiers or symbols (i.e. names).</em></p></blockquote><p><em><code>namespace</code> 是一个抽象容器或环境，被创建用于保存唯一标识符或者符号的逻辑分组。</em></p><h3 id="使用单个的master"><a href="#使用单个的master" class="headerlink" title="使用单个的master"></a>使用单个的master</h3><p>使用单个 <em><strong>master</strong></em> 极大简化了设计，并使得 <em><strong>master</strong></em> 可以借助全局知识做出复杂的 <strong>chunk placement</strong> 和 <strong>replication decisions</strong> 。</p><p><em><strong>master</strong></em> 不参与文件读写，_<strong>client</strong>_ 询问 <em><strong>master</strong></em> 自己应该联系哪些 _<strong>chunkservers</strong>_，并且会在一段时间内缓存这个信息， 在后续操作中直接与 <em><strong>chunkservers</strong></em> 交互。  </p><p>让我们模拟一下一次简单读取的流程:<br>首先，使用固定的 <strong>chunk</strong> 大小，<strong>client</strong> 将应用程序指定的 <strong>file name</strong> 和 <strong>byte offset</strong> 转换为文件中的 <strong>chunk</strong> 索引。<br>然后，它向 <em><strong>master</strong></em> 发送一个包含 <strong>file name</strong> 和 <strong>chunk索引</strong> 的请求。<br><em><strong>master</strong></em> 返回相应的 <strong>chunk handle</strong> 和副本的位置。_<strong>client</strong>_ 使用 <strong>file name</strong> 和 <strong>chunk索引</strong> 作为键来缓存这些信息。<br>然后，_<strong>client</strong>_ 向其中一个副本(很可能是最近的副本)发送请求。这个请求指定 <strong>chunk handle</strong> 和该 <strong>chunk</strong> 中的 <strong>byte range</strong> 。在缓存的信息过期或文件被重新打开之前，对同一 <strong>chunk</strong> 的进一步读取不需要更多的 <strong>client-master</strong> 交互。  </p><p>实际上，_<strong>client</strong>_ 通常会在同一个请求中请求多个 <em><strong>chunk</strong></em> ，而 <em><strong>master</strong></em> 也可以在请求后立即包含 <strong>chunk</strong> 的信息。这些额外的信息避免了未来的几个 <strong>client-master</strong> 交互，几乎没有额外的成本。  </p><h3 id="chunk-size"><a href="#chunk-size" class="headerlink" title="chunk size"></a>chunk size</h3><p>使用 <strong>64MB</strong> 作为 <strong>chunk size</strong> ，每个 <strong>chunk</strong> 副本以普通Linux文件的形式存储在 <em><strong>chunkservers</strong></em> 上，只根据需要进行扩展。  </p><p>大的 <strong>chunk size</strong> 带来了如下的优点：</p><ol><li>减少了 <em><strong>client</strong></em> 需要与 <em><strong>master</strong></em> 交互的次数</li><li>大的 <strong>chunk</strong> 使得 <em><strong>client</strong></em> 可以在其上做很多操作，减少了网络开销</li><li>减小了存放在 <em><strong>master</strong></em> 上的 <strong>metadata</strong> 的大小</li></ol><h3 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h3><p><em><strong>master</strong></em> 存储三种主要类型的 <strong>metadata</strong> : <em>the file and chunk namespaces</em> , <em>the mapping from files to chunks</em> 和 <em>the locations of each chunk’s replicas</em> .  </p><p>所有 <strong>metadata</strong> 都保存在 <em><strong>master</strong></em> 的内存中。前两种类型也通过将<strong>改变</strong>记录到存储在 <em><strong>master</strong></em> 本地磁盘中并复制到远程机器上的 <em>operation log</em> 中来保持持久化。使用日志允许我们简单、可靠地更新 <em><strong>master</strong></em> 的状态，并且在 <em><strong>master</strong></em> 崩溃时不会冒不一致的风险。_<strong>master</strong>_ 不持久化 <strong>chunk</strong> 的位置信息（也就是第三种类型的 <strong>metadata</strong> ）。相反，它会在 <em><strong>master</strong></em> 启动时以及每当有 <em><strong>chunkserver</strong></em> 加入集群时询问每个 <em><strong>chunkserver</strong></em> 关于它的 <strong>chunk</strong> 信息。  </p><h4 id="In-Memory-Data-Structures"><a href="#In-Memory-Data-Structures" class="headerlink" title="In-Memory Data Structures"></a>In-Memory Data Structures</h4><p>由于 <strong>metadata</strong> 存储在 <em><strong>master</strong></em> 的内存中，所以 <em><strong>master</strong></em> 的操作很快。而且，_<strong>master</strong>_ 可以在后台周期性地扫描其整个状态，这既简单又有效。这种周期性扫描用于实现 <strong>chunk</strong> 垃圾回收、出现 <em><strong>chunkserver</strong></em> 故障时的重新复制以及 <strong>chunk</strong> 迁移，以平衡 <em><strong>chunkserver</strong></em> 之间的负载和磁盘空间使用。  </p><p>这种只使用内存的方法的一个潜在问题是，<strong>chunk</strong> 的数量以及整个系统的容量受到 <em><strong>master</strong></em> 拥有多少内存的限制。这在实践中并不是一个严重的问题。  </p><p><em><strong>master</strong></em> 为每个 <strong>64mb</strong> 的 <strong>chunk</strong> 维护少于 64 字节的 <strong>metadata</strong> 。大多数 <strong>chunk</strong> 都是满的，因为大多数文件包含许多 <strong>chunk</strong> ，只有最后一个 <strong>chunk</strong> 可能被部分填充。  </p><p>同样的，每个文件的 <strong>file namespace</strong> 数据通常要求小于 64 字节，因为它使用前缀压缩紧凑地存储文件名。  </p><h4 id="Chunk-Locations"><a href="#Chunk-Locations" class="headerlink" title="Chunk Locations"></a>Chunk Locations</h4><p><em><strong>master</strong></em> 不会持久记录哪些 <em><strong>chunkservers</strong></em> 拥有给定 <strong>chunk</strong> 的副本。它只是在启动时轮询 <em><strong>chunkservers</strong></em> 以获取该信息。此后，_<strong>master</strong>_ 可以使自己保持最新状态，因为它控制所有 <strong>chunk</strong> 的放置，并使用常规的 <em>HeartBeat</em> 消息监视 <em><strong>chunkserver</strong></em> 状态。  </p><p>这样的做法更简单，因为 <em><strong>chunkserver</strong></em> 离开和加入集群是常有的事，如果持久地存储这部分信息会导致同步问题。  </p><h4 id="Operation-Log"><a href="#Operation-Log" class="headerlink" title="Operation Log"></a>Operation Log</h4><p>操作日志记录了 <strong>metadata</strong> 重大变更的历史记录。这是 <strong>GFS</strong> 的核心。它不仅是 <strong>metadata</strong> 的唯一持久记录，而且还用作定义并发操作顺序的逻辑时间线。<strong>file</strong> 和 <strong>chunk</strong> ，以及它们的版本，都是由它们被创建时的逻辑时间唯一且永久地标识的。  </p><p>由于操作日志是至关重要的，我们必须可靠地存储它，并且在 <strong>metadata</strong> 更改持久化之前，不能使更改对客户机可见。否则，即使 <strong>chunks</strong> 本身被保存下来，我们也会丢失整个文件系统或最近的客户端操作。因此，我们在多台远程机器上复制它，并且只有在本地和远程将相应的日志记录刷新到磁盘之后才响应客户机操作。_<strong>master</strong>_ 在刷新之前将多个日志记录 <em>batch</em> 在一起，从而减少刷新和复制对整个系统吞吐量的影响。  </p><p><em><strong>master</strong></em> 通过重放执行操作日志来恢复文件系统状态。为了最小化启动时间，我们必须保持日志较小。每当日志增长超过一定大小时，主服务器就会检查其状态，以便通过从本地磁盘加载最新的检查点( <strong>checkpoint</strong> )并在此之后仅重放有限数量的日志记录来进行恢复。检查点采用类似b树的紧凑形式，可以直接映射到内存中，并用于 <strong>namespace</strong> 查找，而无需额外解析。这进一步加快了恢复速度并提高了可用性。  </p><p>恢复只需要最新的完整 <strong>checkpoint</strong> 和后续的日志文件。  </p><h2 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h2><p><strong>GFS</strong> 采用弱一致性模型，足以满足需求， 实现起来简单且高效。    </p><h3 id="GFS的保证"><a href="#GFS的保证" class="headerlink" title="GFS的保证"></a>GFS的保证</h3><p>文件 <strong>namespace</strong> 的改变(例如，文件创建)是原子性的。<strong>namespace</strong> 锁保证原子性和正确性;<em><strong>master</strong></em> 的操作日志定义了这些操作的全局总顺序。  </p><p>数据改变之后的文件区域的状态取决于改变的类型、成功还是失败以及是否存在并发改变。表 1 总结了结果。  </p><p><a href="https://imgse.com/i/pPwTazn"><img src="https://s1.ax1x.com/2023/08/31/pPwTazn.png" alt="pPwTazn.png"></a>  </p><p>如果所有客户端总是看到相同的数据，无论他们从哪个副本读取，那么文件区域就是 <em><strong>consistent</strong></em> 。一个文件改变之后，如果它是 <em><strong>consistent</strong></em> 的，并且客户端可以看到整个改变写了什么，那么这个文件区域被称为 <em><strong>defined</strong></em> 。  </p><p>当一个改变成功而不受并发写入的干扰时，受影响的区域就被定义( <strong>defined</strong> )了(并且暗含一致性):所有客户端都将始终看到改变所写的内容。  </p><p>并发成功的改变使区域 <strong>undefined</strong> ，但保持一致:所有客户端都看到相同的数据，但它可能不反映任何一个改变所写的内容。  </p><p>失败的改变使区域不一致(因此也 <strong>undefined</strong> ):不同的客户端可能在不同的时间看到不同的数据。  </p><p>我们将在下面描述应用程序如何区分 <strong>defined</strong> 区域和 <strong>undefined</strong> 区域。应用程序不需要进一步区分不同类型的 <strong>undefined</strong> 区域。  </p><p>数据变化可能是写入或追加记录。写操作导致在应用程序指定的文件偏移量处写入数据。记录追加会导致数据(“记录”)至少原子性地自动追加一次，即使在存在并发改变的情况下也是如此，但是以 <strong>GFS</strong> 选择的偏移量进行追加。(相反，“常规”追加只是在客户端认为是文件当前结束的偏移量处进行写操作。) 偏移量返回给客户端，并标记包含该记录的 <strong>defined</strong> 区域的开始。  </p><p>在一系列成功的改变之后，保证被更改的文件区域defined，并包含由最后一个改变写入的数据。GFS通过(a)在其所有副本上以相同的顺序对 <strong>chunk</strong> 应用改变，以及(b)使用 <strong>chunk version numbers</strong> 来检测任何由于在其 <em><strong>chunkserver</strong></em> 关闭时错过改变而变得过时的副本来实现这一点。失效副本将永远不会涉及到改变，也不会给向 <em><strong>master</strong></em> 请求块位置的客户端。他们会被垃圾回收。  </p><p>在成功的改变之后很长一段时间，组件故障当然仍然会损坏或破坏数据。<strong>GFS</strong> 通过 <em><strong>master</strong></em> 和所有 <em><strong>chunkserver</strong></em> 之间的定期握手来识别故障的 <em><strong>chunkserver</strong></em> ，并通过校验和来检测数据损坏。一旦问题出现，数据会尽快从有效的副本中恢复。只有在 <strong>GFS</strong> 做出反应之前(通常在几分钟内)所有副本都丢失时，<strong>chunk</strong> 才会不可逆转地丢失。即使在这种情况下，它也变得不可用，而不是损坏:应用程序接收到明显的错误，而不是损坏的数据。  </p><h3 id="对于应用程序的影响"><a href="#对于应用程序的影响" class="headerlink" title="对于应用程序的影响"></a>对于应用程序的影响</h3><p><strong>GFS</strong> 应用程序可以通过一些简单的技术来适应宽松的一致性模型：依赖于<strong>追加</strong>而不是覆写，<em>checkpointing</em> ， 以及写自验证的，自识别的记录。  </p><h2 id="系统交互"><a href="#系统交互" class="headerlink" title="系统交互"></a>系统交互</h2><p>我们设计系统的目标是最小化 <em><strong>master</strong></em> 在所有操作中的参与。在这个背景下，我们现在描述 _<strong>client</strong>_， _<strong>master</strong>_， <em><strong>chunkservers</strong></em> 是怎样交互来实现 <em>data mutations</em>, <em>atomic record append</em>, 以及 <em>snapshot</em> 的。  </p><h3 id="Leases和Mutation顺序"><a href="#Leases和Mutation顺序" class="headerlink" title="Leases和Mutation顺序"></a>Leases和Mutation顺序</h3><p><strong>mutation</strong> 操作改变一个 <strong>chunk</strong> 的内容或者 <strong>metadata</strong> ，例如一个写或者一个 <strong>append</strong> 操作。<strong>mutation</strong> 作用于一个 <strong>chunk</strong> 的所有副本。我们使用 <strong>leases</strong> 来在副本间维持一致的 <strong>mutation</strong> 顺序。_<strong>master</strong>_ 为其中一个副本授予一个 <strong>chunk lease</strong> ， 我们称之为 <em><strong>primary</strong></em> 。_<strong>primary</strong>_ 为 <strong>chunk</strong> 上的所有 <strong>mutation</strong> 选择一个顺序。所有的副本在应用 <strong>mutations</strong> 时遵循这个顺序。于是，全局的 <strong>mutation</strong> 顺序首先被 <em><strong>master</strong></em> 选择的 <strong>lease</strong> 授予顺序定义，在 <strong>lease</strong> 内由 <em><strong>primary</strong></em> 分配的序列号定义。  </p><p><strong>lease</strong> 机制被设计来最小化 <em><strong>master</strong></em> 管理开销。一个 <strong>lease</strong> 的初始超时时间为 60 秒。然而，一旦 <strong>chunk</strong> 被 <strong>mutated</strong> ，_<strong>primary</strong>_ 可以请求并且通常无限期地从 <em><strong>master</strong></em> 接收扩展。这些扩展请求和 <strong>grants</strong> 承载在 <em><strong>master</strong></em> 和所有 <em><strong>chunkservers</strong></em> 之间定期交换的 <em>HeartBeat</em> 消息上。_<strong>master</strong>_ 有时尝试在 <strong>lease</strong> 到期前撤销它。即使 <em><strong>master</strong></em> 丢失了与一个 <em><strong>primary</strong></em> 的通信，在老 <strong>lease</strong> 期限后，它可以安全地授予一个新 <strong>lease</strong> 给别的副本。  </p><p>在图二中，我们经由这些步骤通过跟随写控制流来阐述这个过程：  </p><p><a href="https://imgse.com/i/pF8uKYj"><img src="https://s11.ax1x.com/2024/02/12/pF8uKYj.md.png" alt="图二"></a></p><ol><li>客户端询问 <em><strong>master</strong></em> 哪一个 <em><strong>chunkserver</strong></em> 保存了 <strong>chunk</strong> 的当前 <strong>lease</strong> 以及其他副本的位置。如果没有人有 <strong>lease</strong> ，_<strong>master</strong>_ 选择一个副本授予它 <strong>lease</strong>。  </li><li><em><strong>master</strong></em> 返回 <em><strong>primary</strong></em> 的身份以及其他副本（ <em><strong>secondary</strong></em> ）的位置。客户端缓存这些数据用于未来的 <strong>mutatios</strong> 。只有当 <strong>primary</strong> 不可达或者副本不再保存一个 <strong>lease</strong> 时，客户端才需要再次联系 <em><strong>master</strong></em> 。  </li><li>客户端把数据推给所有的副本。客户端可以按照任何顺序这样做。每个 <em><strong>chunkserver</strong></em> 将数据存储在内部的 <strong>LRU buffer</strong> 缓存中，直到数据被使用或者老化。通过解耦数据流和控制流，我们可以基于网络拓扑来调度昂贵的数据流，而不用去管哪个 <em><strong>chunkserver</strong></em> 是 <strong>primary</strong> 。  </li><li>一旦所有的副本确认了接收数据，客户端给 <strong>primary</strong> 发送一个写请求。该请求将标识之前推送到所有副本的数据。<strong>primary</strong> 为它收到的所有 <strong>mutation</strong> 分配连续的序列号，可能来自多个客户端，它提供必要的序列化。它按照序列号的顺序把 <strong>mutation</strong> 应用到自己的本地。  </li><li><strong>primary</strong> 将写请求转发给所有的次级副本。每个次级副本采用与 <strong>primary</strong> 相同的序列号顺序应用 <strong>mutations</strong> 。</li><li>次级副本都回复 <strong>primary</strong> 表示他们已完成操作。  </li><li><strong>primary</strong> 回复客户端。在任何副本中遇到的任何错误都将报告给客户端。如果出现错误，写入操作可能在 <strong>primary</strong> 成功，在次级副本上成功了任意子集。（如果它在 <strong>primary</strong> 失败，它将不会分配一个序列号并且转发。）客户端请求被认为失败，修改的区域处于不一致状态。我们的客户端代码通过重试出错的 <strong>mutation</strong> 来处理这样的错误。它会在步骤 3 到 7 之间进行几次尝试。</li></ol><p>如果应用程序的写入值很大或者跨越块边界， <strong>GFS</strong> 客户端将他拆成多个写操作。他们都遵循上面描述的控制流，但是可能会与来自其他客户端的操作交织和覆盖。因此，共享的文件区域最终可能包含来自不同客户端的片段，尽管副本是相同的，因为所有副本在各个操作上都以相同的顺序成功完成。这使得文件区域处于一致但是未定义的状态。</p><h3 id="数据流（Data-Flow）"><a href="#数据流（Data-Flow）" class="headerlink" title="数据流（Data Flow）"></a>数据流（Data Flow）</h3><p>我们使用网络有效地解耦了数据流和控制流。当控制流从客户端流向 <strong>primary</strong> ，然后流向所有次级副本时，数据以流水线的方式沿着精心挑选的 <em><strong>chunkservers</strong></em> 链线性推送。我们的目标是充分利用每台机器的网络带宽，避免网络瓶颈和高延迟连接，最小化推送所有数据的延迟。  </p><p>为了充分地利用每台机器的网络带宽，数据被沿着 <em><strong>chunkservers</strong></em> 链线性推送，而不是分布在别的拓扑结构中（例如，树）。因此，每台机器的全部出站带宽用于尽可能快地传输数据，而不是在多个接收者之间分配。  </p><p>为了尽可能避免网络瓶颈和高延迟连接，每台机器将数据转发给网络拓扑中没有收到数据的最近的机器。假定客户端正在将数据推送到 <em><strong>chunkservers</strong></em> <strong>S1</strong> 到 <strong>S4</strong> 。它将数据发送到最近的 <em><strong>chunkserver</strong></em> ，称为 <strong>S1</strong> 。<strong>S1</strong> 将数据转发给 <strong>S2</strong> 到 <strong>S4</strong> 中离他最近的 <em><strong>chunkserver</strong></em> ，称为 <strong>S2</strong> 。同样地，<strong>S2</strong> 转发数据到 <strong>S3</strong> 和 <strong>S4</strong> 中离自己更近的机器。我们的网络拓扑足够简单，以至于可以从 IP 地址准确地估计出距离。  </p><p>最后，我们流水线化 TCP 连接上的数据来最小化延迟。一旦一个 <em><strong>chunkserver</strong></em> 接收到了一些数据，它立即开始转发。流水线对我们特别有帮助，因为我们使用全双工链路的交换网络。立即转发数据不会降低接收速率。  </p><h3 id="原子记录追加"><a href="#原子记录追加" class="headerlink" title="原子记录追加"></a>原子记录追加</h3><p>未完待续…</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Adusumilli P .THE GOOGLE FILE SYSTEM[J].[2023-08-30].<br>[2] Hades. 【译文】The Google File System 经典的分布式文件存储系统[EB&#x2F;OL]. [2023-08-31]. <a href="https://zhuanlan.zhihu.com/p/522459187">https://zhuanlan.zhihu.com/p/522459187</a>.  </p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IO及IO模型</title>
      <link href="/2023/12/07/2023-12-07-IO%E5%8E%9F%E7%90%86/"/>
      <url>/2023/12/07/2023-12-07-IO%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>IO，即<code>Input/Output</code>，指的是程序从外部设备或者网络读取数据到用户态内存&#x2F;从用户态内存写数据到外部设备或者网络的过程。  </p><h2 id="普通的IO过程"><a href="#普通的IO过程" class="headerlink" title="普通的IO过程"></a>普通的IO过程</h2><p>一般的IO，其流程为，  </p><ol><li>Java进程调用<code>read()</code> <code>write()</code>系统调用函数，进入内核态；  </li><li>内核中的相关程序将数据从设备缓冲区拷贝到内核缓冲区中；  </li><li>把数据从内核缓冲区拷贝到进程的地址空间中去</li></ol><p>这就完成了一次<code>Input</code>，<code>Output</code>反之。  </p><p>以磁盘IO为例，一次普通IO的流程如下：<br><a href="https://imgse.com/i/pigjMLD"><img src="https://z1.ax1x.com/2023/12/08/pigjMLD.jpg" alt="一次普通IO的流程.jpg"></a>   </p><p>这里有两个耗时的操作，一是从设备拷贝数据到内核缓冲区（磁盘准备数据慢，这里的设备缓冲区就是磁盘控制器的缓冲区，内核缓冲区就是<code>PageCache</code>），二是从内核缓冲区拷贝数据到进程的用户态内存空间（涉及到内核态到用户态CPU上下文的切换）。  </p><p>内核缓冲区的作用是解决第二个问题，一次性拷贝一批数据，从而避免频繁且缓慢的磁盘IO或者与其他设备的IO。  </p><p>字节缓冲流诸如<code>BufferedInputStream</code>作用是解决第一个问题，一次性从内核缓冲区拷贝一批数据到进程的缓冲区中，这个缓冲区位于进程的地址空间，之后接着取数据，如果缓冲区中还有数据，就无需系统调用而拿到数据，避免了大量的系统调用开销。  </p><p>这是普通的IO操作，除此之外还有各种方式用于加快IO，譬如DMA、零拷贝技术等。  </p><h2 id="网络IO"><a href="#网络IO" class="headerlink" title="网络IO"></a>网络IO</h2><p>服务端如何实现高并发、海量连接与网络IO的方式有着千丝万缕的联系，与磁盘IO不同的是，网络IO是从网卡拿数据，仅此而已  </p><p>在讨论网络IO的方式之前，我们应该先对阻塞&#x2F;非阻塞、同步&#x2F;异步的概念有一个比较清晰的认识：  </p><h3 id="阻塞IO与非阻塞IO"><a href="#阻塞IO与非阻塞IO" class="headerlink" title="阻塞IO与非阻塞IO"></a>阻塞IO与非阻塞IO</h3><p>如上所述，一次IO过程中数据的流动大体可以分为两步  </p><ol><li>硬件（磁盘、网卡等）到内核缓冲区  </li><li>内核缓冲区到用户态进程空间</li></ol><p>通过进程在输入数据的时候，在第一步（也就是硬件到内核缓冲区）是否发生阻塞等待，可以将网络IO分为阻塞IO和非阻塞IO  </p><p>具体来说，用户态进程发起了读写请求，但是内核态数据还未准备就绪（磁盘、网卡还没准备好数据），</p><ol><li>如果进程需要阻塞等待，直到内核数据准备好，才返回，则为阻塞IO；  </li><li>如果内核立马返回，不会阻塞进程，则为非阻塞IO；</li></ol><h3 id="同步IO与异步IO"><a href="#同步IO与异步IO" class="headerlink" title="同步IO与异步IO"></a>同步IO与异步IO</h3><p>在一次IO中数据传输的两个步骤中，但凡有一处发生了阻塞，就被称为同步IO；如果两个步骤都不阻塞，则被称为异步IO。  </p><p>网络IO的方式可分为三种，分别是<code>BIO</code> <code>NIO</code>与<code>AIO</code>.  </p><h3 id="BIO"><a href="#BIO" class="headerlink" title="BIO"></a>BIO</h3><p><code>BIO</code>是同步阻塞的IO，在<code>BIO</code>的方式下，  </p><ol><li>用户态进程发起读写请求，若内核中的数据未准备好，则进程阻塞等待数据；</li><li>在阻塞等待期间不能处理其他的网络IO请求，故为了可以处理海量连接请求，需要为每个连接（具体表现为一个与套接字关联的对象实例）提供一个线程来处理IO；</li></ol><p>每个连接一个线程来处理的方式消耗大量的系统资源，因为线程会占用大概几MB内存，而我们的内存却是有限的，这样的方式注定无法处理太多的请求，这样就限制住了并发数量。  </p><h3 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h3><p><code>NIO</code>是同步非阻塞IO，在<code>NIO</code>的方式下，相比<code>BIO</code>有如下优势：   </p><ol><li><code>NIO</code>不需要为每个网络连接开一个线程来处理，而是使用一个线程监听多个网络连接，当有连接的数据准备就绪，则进行处理，大大减少了处理并发所需的线程数量；  </li><li><code>NIO</code>中，当进行IO操作时，程序可以立即返回，而不需要等待内核数据就绪，通过轮询或者监听，程序可以知道哪些连接已经准备好了数据或者可以写入数据了。针对就绪的连接执行数据处理操作，而不会阻塞某一个特定的IO上，因此称为非阻塞IO；</li></ol><p><code>NIO</code>是需要内核提供支持的，在创建了连接后，调用<code>fcntl(sockfd, F_SETFL, flags | O_NONBLOCK)</code>将其设置为非阻塞。  </p><p>但是<code>NIO</code>也有较为明显的缺点：因为要轮询确定内核数据有没有就绪，这会产生大量的系统调用（每一次轮询是一次系统调用），这会大量消耗系统资源。  </p><h3 id="AIO"><a href="#AIO" class="headerlink" title="AIO"></a>AIO</h3><p><code>AIO</code>是异步非阻塞IO，当进行读写的时候，进程只需要调用API的<code>read</code>或<code>write</code>方法，当IO结束，调用回调函数通知用户线程直接去取数据就好了，与<code>NIO</code>不同的是，AIO是把数据从内核拷贝到用户态也交给了系统线程去处理，整个IO过程无需用户线程参与。  </p><h2 id="IO多路复用"><a href="#IO多路复用" class="headerlink" title="IO多路复用"></a>IO多路复用</h2><p>为了解决上面提到的<code>NIO</code>会导致大量系统调用的问题，出现了IO多路复用模型。  </p><p>IO多路复用不是简单的一个线程管理多个网络连接，因为在未采用IO多路复用的<code>NIO</code>中，就可以做到一个线程管理多个网络连接（依次轮询它所管理的网络连接），那么IO多路复用的本质应该是什么呢？  </p><p>IO多路复用实际上复用的是系统调用，它可以使用有限的系统调用来管理多个网络连接，具体地说，将一批网络连接丢给内核，让内核告诉我，哪几个连接的数据准备好了，这样一次系统调用就可以检查多个网络连接。  </p><p>在Linux中，IO多路复用的实现主要有<code>select</code> <code>poll</code> <code>epoll</code>，都是采用上述思想设计的，不过它们之间又略有不同。  </p><h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><p><code>select</code>在使用时其实是一个函数，传入我们想要监听的文件描述符，程序在调用<code>select</code>时会阻塞，直到有文件描述符就绪或者超时，函数返回。  </p><p><code>select</code>返回已经就绪的文件描述符并遍历，逐个执行IO操作。  </p><p><code>select</code>的缺点是单个进程可以监视的文件描述符的数量有限，在Linux上的限制是1024。  </p><h3 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h3><p><code>poll</code>可以看做是<code>select</code>的升级版本，它不限制可以监听的文件描述符的最大数量。  </p><h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h3><p><code>select</code>和<code>poll</code>所共有的缺点是，用户需要每次都将海量的的文件描述符集合从用户态传递到内核态，让内核去检测哪些文件描述符就绪了。  </p><p>由于频繁的大量文件描述符拷贝，这里是比较耗时的，于是就有了<code>epoll</code>.  </p><p>在调用<code>epoll_wait()</code>的时候会阻塞，直到有文件描述符就绪被返回，线程遍历就绪的文件描述符，依次进行IO操作。  </p><p>相比于<code>select</code> <code>poll</code>，<code>epoll</code>无须频繁地拷贝大量的文件描述符，因为<code>epoll</code>预先在内核中分配了空间，添加需要监听的文件描述符只需要传递新增的文件描述符即可，大大提高了效率。  </p>]]></content>
      
      
      <categories>
          
          <category> 高并发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RPC协议介绍</title>
      <link href="/2023/12/07/2023-12-10-RPC/"/>
      <url>/2023/12/07/2023-12-10-RPC/</url>
      
        <content type="html"><![CDATA[<p><code>RPC</code>，是<code>Remote Procedure Call</code>的缩写，意为远程过程调用，使得调用远程服务的方法，就像我们调用本地方法一样简单，并且我们不需要关心整个过程底层的细节。  </p><p><code>RPC</code>协议被广泛应用于分布式系统节点间的通信，我所接触的分布式存储<code>Curve</code>就广泛使用了<code>RPC</code>协议.  </p><p>关于<code>RPC</code>协议的实现，有很多RPC框架可以为我们所用，比如<code>gRPC</code> <code>dubbo</code>等，因此我们一般不需要去自己实现<code>RPC</code>。  </p><h2 id="RPC架构"><a href="#RPC架构" class="headerlink" title="RPC架构"></a>RPC架构</h2><p><a href="https://imgse.com/i/piRde7n"><img src="https://z1.ax1x.com/2023/12/10/piRde7n.png" alt="RPC架构.png"></a>  </p><p>整个<code>RPC</code>架构可以看做五个部分：  </p><ol><li>客户端，调用远程方法  </li><li>客户端 <code>stub</code>：把客户端调用的方法以及参数等信息传往服务端  </li><li>网络传输：在客户端<code>stub</code>以及服务端<code>stub</code>之间传递信息，可以是基于TCP也可以是基于UDP   </li><li>服务端<code>stub</code>：接收客户端的方法调用请求，调用方法，向客户端<code>stub</code>返回执行结果  </li><li>服务端：提供远程方法</li></ol><h3 id="一次RPC调用"><a href="#一次RPC调用" class="headerlink" title="一次RPC调用"></a>一次RPC调用</h3><p>一次<code>RPC</code>调用的流程如下：  </p><ol><li>客户端调用方法（就像调用本地方法一样）  </li><li>客户端<code>stub</code>将调用的方法及参数信息打包为<code>RpcRequest</code>并序列化  </li><li>客户端<code>stub</code>得到远程服务地址，将消息发送给服务端  </li><li>服务端<code>stub</code>接收到消息，反序列化得到<code>RpcRequest</code>，根据<code>RpcRequest</code>中的方法和参数调用本地方法，将得到的结果封装为<code>RpcRequest</code>并序列化  </li><li>服务端<code>stub</code>将<code>RpcResponse</code>响应给客户端<code>stub</code>  </li><li>客户端<code>stub</code>反序列化消息得到<code>RpcResponce</code>，得到方法调用结果</li></ol><h2 id="为什么需要RPC协议"><a href="#为什么需要RPC协议" class="headerlink" title="为什么需要RPC协议?"></a>为什么需要RPC协议?</h2><p>相信很多第一次接触<code>RPC</code>协议的人，在看完<code>RPC</code>的介绍之后，不禁心生疑惑：这不就是消息传输吗？我已经有了<code>TCP</code>乃至<code>HTTP</code>，不是也可以达到同样的效果吗？那为什么还会有<code>RPC</code>协议并且应用还这么广泛？  </p><p>我在第一次接触到<code>RPC</code>的时候也有同样的疑惑，并且在很长一段时间里对<code>RPC</code>的理解都比较模糊，那么我们就从<code>TCP</code>说起吧！  </p><p>众所周知，<code>TCP</code>可以实现可靠的、面向连接的、基于字节流的消息收发，由于是基于字节流的传输，<code>TCP</code>的消息是没有边界的，我们接收和发送的消息就是源源不断的字节流，我们不知道哪些字节流是一个完整的消息，我们可能会收到半个消息也可能会收到一个半消息，想要区分消息的边界就需要我们自己去定义规则来处理，比如传递一个消息时加上消息长度或者加上开始和结束标识，这样我们就可以在源源不断的字节流中区分一个一个完整的消息，我前段时间写了一个<code>Go</code>库<a href="https://github.com/lim-yoona/tcpack">tcpack</a>就是用来解决这个问题。  </p><p>可以看到，纯的<code>TCP</code>通信是不可以直接拿来用的，需要我们在应用层面做相应的处理才可以完美地运行，因此就出现了<code>HTTP</code> <code>websocket</code>等应用层协议，它们都是基于<code>TCP</code>的，提供了更好的封装以支持不同的场景。  </p><p>大多数的<code>RPC</code>也是基于<code>TCP</code>的，运行在应用层，其实历史上<code>RPC</code>的出现比<code>HTTP</code>更早，<code>HTTP</code>主要处理超文本的传输，并且它是很标准的，因为要确保任何一个浏览器可以向全世界任何一台服务器发起<code>HTTP</code>请求，其请求头中包含了太多的固定的信息，并且使用<code>JSON</code>去序列化结构体数据，相比之下，<code>RPC</code>协议常常用于公司内部微服务之间的通信，它更加灵活，每个公司都可以定制自己的<code>RPC</code>框架，并且可以使用<code>Protobuf</code>这种性能更好的序列化协议去序列化传输数据。  </p><p>综上所述，<code>RPC</code>性能相比<code>HTTP</code>更好并且实现更灵活，更广泛地应用于微服务以及分布式节点通信场景中。  </p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java IO知识总结</title>
      <link href="/2023/12/06/2023-12-06-JavaIO/"/>
      <url>/2023/12/06/2023-12-06-JavaIO/</url>
      
        <content type="html"><![CDATA[<p>IO也就是<code>Input/Output</code> ，数据拿到计算机内存中的过程即为输入，反之，数据从内存输出到外部存储（可以是远程主机、磁盘、数据库等）的过程即为输出。数据传输过程类似于水流，因此称作IO流。IO流在Java中分为输出流和输入流，根据数据的处理方式又分为字节流和字符流。（这里的输入输出是以程序为中心的，输入指程序接收输入，输出指程序把数据输出到外部存储）  </p><h2 id="Java-IO流"><a href="#Java-IO流" class="headerlink" title="Java IO流"></a>Java IO流</h2><p>Java IO流有四个基类，分别是输入流<code>InputStream</code>（字节输入流），<code>Reader</code>（字符输入流），<code>OutputStream</code>（字节输出流），<code>Writer</code>（字符输出流），其余的IO相关类都是派生于这四个抽象基类。  </p><h3 id="字节流与字符流"><a href="#字节流与字符流" class="headerlink" title="字节流与字符流"></a>字节流与字符流</h3><p>字节流：  </p><ol><li>以字节为单位处理数据，适用于处理二进制数据  </li><li>直接操作字节，不涉及编码转换，可以处理任何类型的数据</li></ol><p>字符流：  </p><ol><li>以字符为单位处理数据，适合处理文本数据  </li><li>自动处理字符编码和解码（将字节传为字符）  </li><li>性能逊于字节流处理，因为还有编解码消耗  </li><li>对于不知道编码类型的数据，使用字节流处理会带来乱码问题，而使用字符流就不会出现这样的问题</li></ol><h2 id="字节流"><a href="#字节流" class="headerlink" title="字节流"></a>字节流</h2><h3 id="InputStream"><a href="#InputStream" class="headerlink" title="InputStream"></a>InputStream</h3><p><code>InputStream</code>用于从源读取字节流到内存中，它是一个抽象类，是所有字节输入流的父类。  </p><h4 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h4><ol><li><code>read()</code>:返回输入流中下一个字节的数据，如果未读取任何字节，返回<code>-1</code>，表示结束  </li><li><code>read(byte b[])</code>:从输入流中读取一些字节放到字节数组<code>b</code>中，如果数组<code>b</code>的长度为0，则不读取，如果没有可以读取的字节，返回<code>-1</code>。最多可以读<code>b.length</code>个字节，返回读取的字节数  </li><li><code>read(byte b[], int off, int len)</code>:<code>off</code>是偏移量，<code>len</code>是指定的要读取的最大字节数，其余与<code>read(byte b[])</code>一致（这里的偏移量<code>off</code>是针对字节数组<code>b</code>的，加入偏移为2，则从<code>b</code>的第3个下标开始填充）  </li><li><code>skip(long n)</code>:忽略输入流中的<code>n</code>个字节，返回实际忽略的字节数  </li><li><code>avaliable()</code>:返回输入流中可以读取的字节数  </li><li><code>close()</code>:关闭输入流并释放资源</li><li><code>readAllBytes()</code>:读取输入流中的所有字节，返回字节数组  </li><li><code>readNBytes(byte[] b, int off, int len)</code>:阻塞直到读取<code>len</code>个字节  </li><li><code>transferTo(OutputStream out)</code>:将所有字节流从一个输入流传递到一个输出流，输出流自动写入</li></ol><p>使用的输入文件为<code>text.txt</code>:  </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hello,world!</span><br><span class="line">sjska</span><br><span class="line">12345678910</span><br><span class="line">qpwoeiruty</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">filePath</span> <span class="operator">=</span> <span class="string">&quot;text.txt&quot;</span>;</span><br><span class="line"><span class="type">FileInputStream</span> <span class="variable">file</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileInputStream</span>(filePath);</span><br><span class="line">System.out.println(file.available());</span><br><span class="line"><span class="comment">// 输出输入流中可以读取的字节数 44</span></span><br><span class="line"></span><br><span class="line"><span class="type">byte</span>[] bytes = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">10</span>];</span><br><span class="line">file.read(bytes);</span><br><span class="line"><span class="keyword">for</span> (<span class="type">byte</span> b : bytes)&#123;</span><br><span class="line">    System.out.println(b);</span><br><span class="line">    System.out.println(Character.toChars(b));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 输出bytes数组的内容，依次输出 104 h 101 e 108 l 108 l 111 o 44 , 119 w 111 o 114 r 108 l</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="variable">read</span> <span class="operator">=</span> file.read();</span><br><span class="line">System.out.println(Character.toChars(read));</span><br><span class="line"><span class="comment">// 读取了一个字节，输出 d</span></span><br><span class="line"></span><br><span class="line"><span class="type">byte</span>[] bytes1 = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">7</span>];</span><br><span class="line">file.read(bytes1, <span class="number">2</span>,<span class="number">5</span>);</span><br><span class="line"><span class="keyword">for</span>(<span class="type">byte</span> b : bytes1)&#123;</span><br><span class="line">    System.out.println(b);</span><br><span class="line">    System.out.println(Character.toChars(b));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 读取5个字节，并且偏移量为2，输出bytes1数组的内容，依次输出</span></span><br><span class="line"><span class="comment">// 0 0 33 ! 13 10 115 s 106 j</span></span><br><span class="line"><span class="comment">// bytes1数组的前两个字节偏移了，为空，13和10分别表示换行符和回车符</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 跳过4个字节</span></span><br><span class="line">file.skip(<span class="number">4</span>);</span><br><span class="line">file.read(bytes);</span><br><span class="line"><span class="keyword">for</span>(<span class="type">byte</span> b : bytes)&#123;</span><br><span class="line">    System.out.println(b);</span><br><span class="line">    System.out.println(Character.toChars(b));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 再读取10个字节存在bytes中，其内容为</span></span><br><span class="line"><span class="comment">// 10 49 1 50 2 51 3 52 4 53 5 54 6 55 7 56 8 57 9</span></span><br><span class="line"><span class="comment">// 第一个10是回车符，它之前的换行符已经被skip跳过了</span></span><br><span class="line"><span class="comment">// 之后的1~9为存储的文本，49~57为其对应的ASCII码</span></span><br><span class="line"></span><br><span class="line"><span class="type">String</span> <span class="variable">outFilePath</span> <span class="operator">=</span> <span class="string">&quot;text1.txt&quot;</span></span><br><span class="line"><span class="type">OutputStream</span> <span class="variable">fileOut</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(<span class="string">&quot;outFilePath&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将输入流file中的字节全部放入输出流fileOut</span></span><br><span class="line">file.transferTo(fileOut);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果没有执行transferTo方法，这里读取输入流中剩余全部字符放在返回的字符数组中</span></span><br><span class="line"><span class="comment">// 但是执行了transferTo，输入流中已经没有字节了，所以什么都没读到</span></span><br><span class="line"><span class="type">byte</span>[] bytes2 = file.readAllBytes();</span><br><span class="line"><span class="keyword">for</span>(<span class="type">byte</span> b : bytes2)&#123;</span><br><span class="line">    System.out.println(b);</span><br><span class="line">    System.out.println(Character.toChars(b));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出文件<code>text1.txt</code>:  </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">10</span><br><span class="line">qpwoeiruty</span><br></pre></td></tr></table></figure><h3 id="OutputStream"><a href="#OutputStream" class="headerlink" title="OutputStream"></a>OutputStream</h3><p>字节输出流，将字节输出到指定地方（文件等地），<code>OutputStream</code>是所有字节输出流的父类。  </p><h4 id="常用方法-1"><a href="#常用方法-1" class="headerlink" title="常用方法"></a>常用方法</h4><ol><li><code>write(int b)</code>:将特定字节写入到输出流  </li><li><code>write(byte b[])</code>:将字节数组<code>b</code>写入到输出流  </li><li><code>write(byte b[], int off, int len)</code>:增加了<code>off</code>偏移量以及<code>len</code>（要写入的最大字节数），与字节输入流相同，这里的<code>off</code>也是对于字节数组<code>b</code>来说  </li><li><code>flush()</code>:刷新此输出流并强制写出所有缓冲的输出字节  </li><li><code>close()</code>:关闭输出流并释放资源</li></ol><p><code>FileOutputStream</code>是使用最多的字节输出流对象，用于将字节写入到文件中，当调用<code>write</code>方法的时候，首先将数据写入到<code>FileOutputStream</code>的内存缓冲区，当缓冲区满、手动调用<code>flush</code>方法、手动调用<code>close</code>方法（其实也是触发了<code>flush</code>方法的调用）、程序退出触发<code>close</code>方法时，才会把数据写入到文件中。  </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">filePath</span> <span class="operator">=</span> <span class="string">&quot;test.txt&quot;</span>;</span><br><span class="line"><span class="type">FileOutputStream</span> <span class="variable">fis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(filePath);</span><br><span class="line"><span class="comment">// 将 Z 写入到输出流</span></span><br><span class="line">fis.write(<span class="number">90</span>);</span><br><span class="line"><span class="comment">// 往输出流写入换行符</span></span><br><span class="line">fis.write(<span class="number">10</span>);</span><br><span class="line"><span class="comment">// 网输出流写入回车</span></span><br><span class="line">fis.write(<span class="number">13</span>);</span><br><span class="line"><span class="comment">// 往输出流写入 hello,world!</span></span><br><span class="line"><span class="type">byte</span>[] bytes = <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;hello,world!&quot;</span>).getBytes();</span><br><span class="line">fis.write(bytes);</span><br><span class="line">fis.write(<span class="number">10</span>);</span><br><span class="line"><span class="comment">// 偏移量为3，网输出流写入字节数组</span></span><br><span class="line">fis.write(bytes,<span class="number">3</span>,<span class="number">9</span>);</span><br></pre></td></tr></table></figure><p>得到的输出文件&#96;test.txt”:  </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Z</span><br><span class="line"></span><br><span class="line">hello,world!</span><br><span class="line">lo,world!</span><br></pre></td></tr></table></figure><h2 id="字符流"><a href="#字符流" class="headerlink" title="字符流"></a>字符流</h2><p>基于字节流的IO若不知道编码方式就容易出现乱码问题，字符流对象方便我们对字符进行流操作，对于音频、视频、图片等媒体文件建议使用字节流进行处理，而对于文本文件建议使用字符流进行处理。  </p><p>字符流默认采用的编码方式是<code>Unicode</code>编码。  </p><h3 id="Reader"><a href="#Reader" class="headerlink" title="Reader"></a>Reader</h3><p><code>Reader</code>用于从文件读取字符流到内存，它是所有字符输入流的父类。  </p><h4 id="常用方法-2"><a href="#常用方法-2" class="headerlink" title="常用方法"></a>常用方法</h4><ol><li><code>read()</code>:从输入流读取一个字符  </li><li><code>read(char[] cbuf)</code>:用于从输入流读取字符到字符数组<code>cbuf</code>中  </li><li><code>read(char[] cbuf, int off, int len)</code>:用于从输入流读取字符到字符数组<code>cbuf</code>中，并增加了偏移量<code>off</code>以及读取的字符数量<code>len</code>  </li><li><code>skip(long n)</code>:忽略输入流中的<code>n</code>个字符，返回实际忽略的字符数量  </li><li><code>close()</code>:关闭输入流并释放资源</li></ol><p><code>FileReader</code>是使用较多的字符输入流。  </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 文件使用上面的 test.txt</span></span><br><span class="line"><span class="type">String</span> <span class="variable">filePath</span> <span class="operator">=</span> <span class="string">&quot;test.txt&quot;</span>;</span><br><span class="line"><span class="type">FileReader</span> <span class="variable">fr</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileReader</span>(filePath);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取一个字符，输出90，也就是Z</span></span><br><span class="line">System.out.println(fr.read());</span><br><span class="line"><span class="type">char</span> [] cBuf = <span class="keyword">new</span> <span class="title class_">char</span>[<span class="number">10</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取一系列字符串到字符数组中</span></span><br><span class="line"><span class="comment">// 依次输出 换行符 回车符 h e l l o , w o</span></span><br><span class="line">fr.read(cBuf);</span><br><span class="line"><span class="keyword">for</span>(<span class="type">char</span> c : cBuf)&#123;</span><br><span class="line">    System.out.println(c);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 跳过一个字符</span></span><br><span class="line">fr.skip(<span class="number">1</span>);</span><br><span class="line"><span class="type">char</span> [] cBuf1 = <span class="keyword">new</span> <span class="title class_">char</span>[<span class="number">6</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取4个字符串到字符数组中，偏移量为2</span></span><br><span class="line"><span class="comment">// 输出 空 空 l d ! 换行符</span></span><br><span class="line">fr.read(cBuf1,<span class="number">2</span>,<span class="number">4</span>);</span><br><span class="line"><span class="keyword">for</span>(<span class="type">char</span> c : cBuf1)&#123;</span><br><span class="line">    System.out.println(c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Writer"><a href="#Writer" class="headerlink" title="Writer"></a>Writer</h3><p><code>Writer</code>用于将字符输出到文件中，它是所有字符输出流的父类。  </p><h4 id="常用方法-3"><a href="#常用方法-3" class="headerlink" title="常用方法"></a>常用方法</h4><ol><li><code>write(int c)</code>:向输出流写入单个字符  </li><li><code>write(char[] cbuf)</code>:向输出流写入字符数组  </li><li><code>write(char[] cbuf, int off, int len)</code>:向输出流写入字符数组，并包含偏移量<code>off</code>以及字符数量<code>len</code>  </li><li><code>write(String str)</code>:向输出流写入字符串</li><li><code>write(String str, int off, int len)</code>:向输出流写入字符串，并且包含偏移量<code>off</code>以及字符数量<code>len</code>  </li><li><code>append(CharSequence csq)</code>:将指定的字符序列<code>csp</code>附加到指定的<code>Writer</code>对象并返回该<code>Writer</code>对象  </li><li><code>append(char c)</code>:将指定的字符附加到指定的<code>Writer</code>对象并返回该<code>Writer</code>对象  </li><li><code>flush()</code>:刷新该输出流，强制输出所有缓冲的输出字符</li><li><code>close()</code>:关闭输出流并释放资源</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">filePath</span> <span class="operator">=</span> <span class="string">&quot;simple.txt&quot;</span>;</span><br><span class="line"><span class="type">FileWriter</span> <span class="variable">fw</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileWriter</span>(filePath);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向输出流写入字母Z</span></span><br><span class="line">fw.write(<span class="number">90</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入换行符</span></span><br><span class="line">fw.write(<span class="number">13</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入字符串 hello,world!</span></span><br><span class="line">fw.write(<span class="string">&quot;hello,world!&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入换行符</span></span><br><span class="line">fw.write(<span class="number">13</span>);</span><br><span class="line"><span class="type">char</span>[] charArray = <span class="string">&quot;the night&quot;</span>.toCharArray();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入字符数组</span></span><br><span class="line">fw.write(charArray);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入换行符</span></span><br><span class="line">fw.write(<span class="number">13</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入字符串，偏移量2，写入5个字符</span></span><br><span class="line"><span class="comment">// 因此写入的是 34567</span></span><br><span class="line">fw.write(<span class="string">&quot;123456789&quot;</span>,<span class="number">2</span>,<span class="number">5</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入换行符</span></span><br><span class="line">fw.write(<span class="number">13</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入字符数组，偏移量4，写入2个字符</span></span><br><span class="line"><span class="comment">// 因此写入的是 ni</span></span><br><span class="line">fw.write(charArray,<span class="number">4</span>,<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入换行符</span></span><br><span class="line">fw.write(<span class="number">13</span>);</span><br><span class="line"><span class="type">CharSequence</span> <span class="variable">cs</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;char sequence&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入换行符</span></span><br><span class="line">fw.write(<span class="number">13</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在输出流后追加字符序列 char sequence</span></span><br><span class="line"><span class="type">Writer</span> <span class="variable">append</span> <span class="operator">=</span> fw.append(cs);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 刷新字符输入流</span></span><br><span class="line">append.flush();</span><br></pre></td></tr></table></figure><p>最终得到的<code>simple.txt</code>内容如下：  </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Z</span><br><span class="line">hello,world!</span><br><span class="line">the night</span><br><span class="line">34567</span><br><span class="line">ni</span><br><span class="line"></span><br><span class="line">char sequence</span><br></pre></td></tr></table></figure><h2 id="缓冲流"><a href="#缓冲流" class="headerlink" title="缓冲流"></a>缓冲流</h2><p>由于IO操作很耗时，所以采用缓冲流，一次写入&#x2F;读出多个字节，从而避免频繁的IO操作，提高流的传输效率。  </p><h3 id="字节缓冲流"><a href="#字节缓冲流" class="headerlink" title="字节缓冲流"></a>字节缓冲流</h3><p>字节缓冲流采用<strong>装饰器模式</strong>来增强<code>InputStream</code>和<code>OutputStream</code>子类对象的功能。</p><p>Java的输入输出流有自带的内部缓冲区，为什么还需要字节缓冲流？  </p><ol><li>内部缓冲区的大小固定且较小，而字节缓冲流可以自定义缓冲区大小，更灵活  </li><li>字节缓冲区性能更高</li></ol><h4 id="BufferedInputStream"><a href="#BufferedInputStream" class="headerlink" title="BufferedInputStream"></a>BufferedInputStream</h4><p><code>BufferedInputStream</code>从源头读取数据到内存的过程不会一个字节一个字节读取，而是会先将读取到的字节存放在缓冲区，并从内部缓冲区中单独读取字节，大大减少IO次数，提高了读取效率。  </p><p><strong>这里的缓冲区减少的是系统调用的次数，而不是磁盘IO的次数，从而提高读取效率。</strong>  </p><p><code>BufferedInputStream</code>维护的缓冲区其实是一个字节数组，并且默认的缓冲区大小为8192字节，但是可以在<code>BufferedInputStream</code>对象构造时传入<code>size</code>作为缓冲区大小。  </p><h5 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h5><p>读取571MB的文件，每次读取一字节：  </p><ol><li><code>FileInputStream</code>耗时<code>833447</code>毫秒  </li><li><code>BufferedInputStream</code>耗时<code>9910</code>毫秒<br>可以看到，其读取效率提升是相当巨大的</li></ol><p>读取571MB的文件，每次读取长度为2000的字节数组：  </p><ol><li><code>FileInputStream</code>耗时<code>571</code>毫秒</li><li><code>BufferedInputStream</code>耗时<code>391</code>毫秒</li></ol><p>经测试，这个用于接收的字节数组越小，两种方式的性能差异越大，当字节数组足够大，<code>FileInputStream</code>的读取效率可能会比<code>BufferedInputStream</code>更高。  </p><p>我认为，造成这一情况的原因如下，当用于接收的字节数组大小等于<code>BufferedInputStream</code>的默认缓冲区大小的时候，两种读取方式所产生的系统调用数量是一样的，这相当于缓冲区形同虚设了；而对于一次只读取一个字节的情况来说，没有缓冲区则每次去内核缓冲区拿数据，有缓冲区则每次去缓冲区拿数据，无需系统调用，大大减少了系统调用的次数，因此<code>BufferedInputStream</code>效率更高。**<code>BufferedInputStream</code>减少的实际上是系统调用的次数**  </p><h4 id="BufferedOutputStream"><a href="#BufferedOutputStream" class="headerlink" title="BufferedOutputStream"></a>BufferedOutputStream</h4><p><code>BufferedOutputStream</code>是字节缓冲输出流，首先将字节写入到缓冲区中，再从缓冲区写入到文件中，大大减少了IO次数。<br><code>BufferedOutputStream</code>缓冲区的默认大小也是8192字节  </p><h3 id="字符缓冲流"><a href="#字符缓冲流" class="headerlink" title="字符缓冲流"></a>字符缓冲流</h3><p>字符缓冲流<code>BufferedReader</code>和<code>BufferedWriter</code>与字节缓冲流类似，只不过它们操作的数据变成了字符。  </p><p>在使用Java处理标准输入流时，使用 <code>Scanner</code> 来处理会很慢，如果受到时间限制，应该采用 <code>BufferedReader</code> 更好。（例如2024-3-9美团春招笔试题第二题，<code>Scanner</code> 只能过一小部分用例，而采用 <code>BufferedReader</code> 则直接AC）  </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">InputStreamReader</span> <span class="variable">isr</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">InputStreamReader</span>(System.in);</span><br><span class="line"><span class="type">BufferedReader</span> <span class="variable">br</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BufferedReader</span>(isr);</span><br><span class="line">String[] strs = br.readLine().split(<span class="string">&quot; &quot;</span>);</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;strs.length;i++)&#123;</span><br><span class="line">    <span class="type">Integer</span> <span class="variable">num</span> <span class="operator">=</span> Integer.parseInt(strs[i]);</span><br><span class="line">    System.out.printf(<span class="string">&quot;%d %s\n&quot;</span>,num,num.getClass());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先批量读入字符串，再使用基本类型包装类的 <code>parseInt</code> 等方法将字符串转为数字。</p><h2 id="随机访问流"><a href="#随机访问流" class="headerlink" title="随机访问流"></a>随机访问流</h2><p><code>RandomAccessFile</code>支持随意跳转到文件的任意位置进行读写，在创建<code>RandomAccessFile</code>对象时可以指定读写模式<code>mode</code>  </p><ol><li><code>r</code>:只读模式  </li><li><code>rw</code>:读写模式  </li><li><code>rws</code>:同步更新对“文件的内容”或“元数据”的修改到外部存储设备</li><li><code>rwd</code>:同步更新对“文件的内容”的修改到外部存储设备</li></ol><h3 id="常用方法-4"><a href="#常用方法-4" class="headerlink" title="常用方法"></a>常用方法</h3><ol><li><code>seek(long pos)</code>:指定写入或者读取字节的位置（偏移量）  </li><li><code>getFilePointer()</code>:得到当前的偏移量</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">filePath</span> <span class="operator">=</span> <span class="string">&quot;test1.txt&quot;</span>;</span><br><span class="line"><span class="type">RandomAccessFile</span> <span class="variable">raf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RandomAccessFile</span>(filePath,<span class="string">&quot;rws&quot;</span>);</span><br><span class="line"><span class="type">byte</span>[] bytes = <span class="string">&quot;hello,worle!ssssssssssssssssssaaaaaaaaaaaaaaaaeeeeeeeeeeee&quot;</span>.getBytes();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向文件写入字符串 hello,worle!ssssssssssssssssssaaaaaaaaaaaaaaaaeeeeeeeeeeee</span></span><br><span class="line">raf.write(bytes);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 此时的指针位置在 58 ，也就是文件末尾</span></span><br><span class="line">System.out.println(raf.getFilePointer());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过 seek 方法把指针移到 0 位置，也就是文件开头</span></span><br><span class="line">raf.seek(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出 0 </span></span><br><span class="line">System.out.println(raf.getFilePointer());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 分别输出 h e l</span></span><br><span class="line">System.out.println(Character.toChars(raf.read()));</span><br><span class="line">System.out.println(Character.toChars(raf.read()));</span><br><span class="line">System.out.println(Character.toChars(raf.read()));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 把指针移至 20 位置</span></span><br><span class="line">raf.seek(<span class="number">20</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出 20</span></span><br><span class="line">System.out.println(raf.getFilePointer());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 分别输出 s s</span></span><br><span class="line">System.out.println(Character.toChars(raf.read()));</span><br><span class="line">System.out.println(Character.toChars(raf.read()));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出 22</span></span><br><span class="line">System.out.println(raf.getFilePointer());</span><br></pre></td></tr></table></figure><p>可以看到，偏移量置0为文件开头  </p><p>如上就是Java中输入输出流的常用类以及常用操作啦，其余的类操作应该也是类似的，可以举一反三！  </p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一致性哈希算法</title>
      <link href="/2023/12/04/2023-12-04-Consistent%20Hashing/"/>
      <url>/2023/12/04/2023-12-04-Consistent%20Hashing/</url>
      
        <content type="html"><![CDATA[<p>一致性哈希是一种哈希算法，主要用于分布式系统中数据的分片和负载均衡，一致性哈希算法解决了传统哈希算法在节点动态增减时可能导致数据迁移量过大的问题，能够提供更好的扩展性和性能。  </p><h2 id="普通的哈希算法"><a href="#普通的哈希算法" class="headerlink" title="普通的哈希算法"></a>普通的哈希算法</h2><p>众所周知，哈希算法用于将字符串映射到固定长度的哈希值上，应用广泛，譬如Java中的<code>HashMap</code>，C++中的<code>unordered_map</code>，都是用到了哈希算法。    </p><p>在分布式缓存中，数据被缓存到了不同的节点上，那么具体到一个数据的缓存或者访问，分布式缓存系统应该如何选择节点呢？<br>这里会遇到一个问题，即：  </p><p>如果随机选择节点，那么比如第一次查询选择将数据缓存在A节点，第二次查询的时候有很大概率会选择其他缓存节点，那么则缓存失效，需要重新进行数据查询，这显然是不合理的！  </p><p>另外，此举还会造成不同的节点缓存相同的数据，带来空间的浪费！  </p><p>我们应该让<strong>相同的数据的缓存和查找落在同一个节点上</strong>，这样才可以充分发挥缓存带来的性能提升。  </p><p>如何使得相同的数据的缓存和访问落在同一个节点上呢？  </p><p>使用哈希算法可以很好地完成这样的工作——  </p><p>现假设拥有5个节点，编号为0~4，可以首先将待查询<code>key</code>的信息映射到一个数字<code>h</code>上，可以有很多种方式完成这样的映射，最简单的，将<code>key</code>每个字符对应的ASCII码相加即可得到<code>key</code>对应的数字<code>h</code>，随后进行取模操作<code>h%5</code>，这样就把一个<code>key</code>映射到了一个固定的节点上，无论何时查询这个<code>key</code>都会访问同样的节点！  </p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>上述方法虽实现了对于相同的<code>key</code>，在查询时稳定映射到同样的缓存节点，但是仍有较大缺陷。  </p><p>在分布式系统中，支持节点动态扩容是很重要的功能，也就是常说的“弹性”。  </p><p>上面的方法不可以很好地支持节点的动态扩容，如果现在需要增加一个节点，那么哈希算法将会变成<code>h%6</code>，这样，几乎所有数据所映射到的节点都发生了改变，而别的节点并没有对应的<code>key</code>的缓存，相当于在一瞬间，所有的缓存都失效了，引发<a href="https://ymiir.top/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/threecacheproblem.html">缓存雪崩</a>，所有的并发访问都涌向了后端数据库，这会给后端数据库带来骤然增大的压力甚至宕机。  </p><p>一致性哈希算法就是用来解决普通哈希算法下分布式缓存系统无法实现动态容量更改的情况。  </p><h2 id="一致性哈希算法"><a href="#一致性哈希算法" class="headerlink" title="一致性哈希算法"></a>一致性哈希算法</h2><h3 id="哈希环"><a href="#哈希环" class="headerlink" title="哈希环"></a>哈希环</h3><p>一致性哈希算法将数据或者节点映射到一个哈希环上，哈希环具有<code>2^32</code>个环空间，示意图如下：  </p><p><a href="https://imgse.com/i/piyquLR"><img src="https://z1.ax1x.com/2023/12/04/piyquLR.png" alt="哈希环.png"></a>  </p><p>一致性哈希算法也是取模算法，不过它是对<code>2^32-1</code>取模，任何一个数据都会被映射在哈希环上的固定位置。  </p><p>现假定已经有了三个节点，它们的信息通过哈希运算被映射在哈希环上：  </p><p><a href="https://imgse.com/i/piyLJA0"><img src="https://z1.ax1x.com/2023/12/04/piyLJA0.png" alt="节点映射哈希环上.png"></a>  </p><p>同时，缓存中的数据也分别会被映射在哈希环上：  </p><p><a href="https://imgse.com/i/piyLDBR"><img src="https://z1.ax1x.com/2023/12/04/piyLDBR.png" alt="节点与数据映射哈希环上.png"></a>  </p><p>对于数据，也就是<code>key</code>，它会在哈希环上顺时针找到下一个节点的哈希作为选择的节点，譬如上图，<code>key2</code> <code>key3</code>都会被映射到节点2，<code>key4</code> <code>key5</code>都会被映射到节点3，而<code>key6</code> <code>key7</code> <code>key1</code>都会被映射到节点1.  </p><p>现假设增加一节点4：  </p><p><a href="https://imgse.com/i/piyL4ud"><img src="https://z1.ax1x.com/2023/12/04/piyL4ud.png" alt="增加节点4的哈希环.png"></a>  </p><p>可以看到，新增节点4后，仅有<code>key6</code> <code>key7</code>两个数据的映射节点发生了改变，而其余数据所对应的节点均未改变，这就很大程度上避免了大面积的缓存失效引发的<code>缓存雪崩</code>。  </p><h3 id="数据倾斜问题"><a href="#数据倾斜问题" class="headerlink" title="数据倾斜问题"></a>数据倾斜问题</h3><p>如果哈希环之上节点数量较少，但是数据较多且在环上的分布较为集中，这样就会出现数据在节点之上分布严重不均匀的情况。   </p><p>并且如果缓存数据非常多的某个节点<code>A</code>退出或者崩溃，那么原本映射在<code>A</code>节点的数据都会落在哈希环上的下一个节点（假定为<code>B</code>），导致映射到<code>B</code>的数据突然增多，如果之后<code>B</code>又退出或者宕机……以此类推，数据分布不均匀可能会导致大批缓存同时失效，从而引发<code>缓存雪崩</code>。  </p><p>解决方法是设置一些虚拟节点，并把虚拟节点同样映射到哈希环上，数据沿着哈希环顺时针寻找时，如果找到的是虚拟节点，最终会映射到真实节点上，虚拟节点数量较多，从而避免了大多数数据都映射到同一个节点的情况，实现了负载均衡。  </p>]]></content>
      
      
      <categories>
          
          <category> 分布式缓存 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>缓存击穿、缓存穿透与缓存雪崩</title>
      <link href="/2023/12/03/2023-12-03-threecacheproblem/"/>
      <url>/2023/12/03/2023-12-03-threecacheproblem/</url>
      
        <content type="html"><![CDATA[<p>缓存是计算机系统中应用非常广泛的技术，最经典的，操作系统中处处是缓存，缓存可以大大提升数据访问速率。    </p><p>在业务中，数据库（<code>MySQL</code>）面对大量的并发请求，会出现两个问题:  </p><ol><li>每次请求都需要查询数据库，速度很慢；  </li><li>数据库无法承受如此大的请求流量，可能引起数据库宕机；</li></ol><p>为解决这两个问题，一般会在内存中设置缓存，通常是使用<code>Redis</code>作为缓存，对于数据库的查询请求首先查询缓存，如果查不到，再去查询数据库。  </p><p>引入缓存之后又会面临三个新的问题，即缓存击穿、缓存穿透以及缓存雪崩。  </p><h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p>当缓存中没有某个数据，但是数据库中有这个数据时，对于数据的访问会直接访问数据库，于是——  </p><p>一个热点<code>key</code>每时每刻都在接受大量的并发访问，当这个热点<code>key</code>的缓存过期时，大量的并发请求同时涌入到数据库中，导致后端数据库的压力陡然增大，引发<code>缓存击穿</code>。</p><p>概括来讲，就是由于缓存<code>key</code>过期，导致大量请求涌入后端数据库而造成数据库压力骤然增大。  </p><h3 id="如何解决缓存击穿？"><a href="#如何解决缓存击穿？" class="headerlink" title="如何解决缓存击穿？"></a>如何解决缓存击穿？</h3><ol><li>既然缓存击穿是由于热点缓存<code>key</code>的过期导致的，那么一种方法是设置热点<code>key</code>永不过期。  </li><li>使用分布式锁，当查询缓存未命中时，首先申请分布式锁，再去访问后端数据库，拿到数据之后缓存到缓存中；别的请求得不到锁，就无法请求后端数据库，待解锁后，直接查询缓存，从而有效地解决了大量请求涌入后端数据库的问题。</li></ol><h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>缓存穿透指查询缓存未命中，同时后端数据库中也没有这个数据，那么Mysql就只能返回一个空对象，表示此次查询失败。如果这样的请求非常多，又或者有攻击者恶意地持续不断发出这样的查询请求，会给后端数据库带来很大的压力甚至崩溃，这就是<code>缓存穿透</code>。  </p><h3 id="如何解决缓存穿透？"><a href="#如何解决缓存穿透？" class="headerlink" title="如何解决缓存穿透？"></a>如何解决缓存穿透？</h3><ol><li>缓存空对象。当返回空对象的请求到达时，缓存一个空对象，这样下一次同样的请求到达，就会查询缓存，而不会访问后端数据库。缺点就是，如果缓存大量空对象，占用了缓存的空间。  </li><li>布隆过滤器。利用布隆过滤器可以判断元素不存在的特性，将一些数据存储在布隆过滤器中，用户访问数据时，首先查询布隆过滤器，如果数据不存在，那么就拒绝查询，从而避免了大量对于空对象的查询。</li></ol><h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p>缓存雪崩是指为一批缓存<code>key</code>设置了相同的过期时间，那么当这个过期时间到达时，这些缓存<code>key</code>同时失效，从而导致大量的访问涌入后端数据库，造成后端数据库压力陡然增大，形成<code>缓存雪崩</code>。  </p><p>有两种情况会造成<code>缓存雪崩</code>：  </p><ol><li>多个缓存<code>key</code>同时过期  </li><li>缓存系统宕机</li></ol><h3 id="如何解决缓存雪崩？"><a href="#如何解决缓存雪崩？" class="headerlink" title="如何解决缓存雪崩？"></a>如何解决缓存雪崩？</h3><p>解决大批<code>key</code>同时过期：  </p><ol><li>设置多级缓存，这样即使缓存失效或者多个缓存<code>key</code>同时过期，也不会造成<code>缓存雪崩</code>.  </li><li>使用锁或者队列，避免大量的并发请求访问后端数据库  </li><li>随机设置缓存失效时间  </li><li>不设置过期时间  </li><li>在分布式负载均衡场景下，可以使用一致性哈希算法来解决由于分布式集群容量动态改变而带来的<code>缓存雪崩</code></li></ol><p>解决缓存系统宕机问题：  </p><ol><li>服务熔断或请求限流机制。服务熔断是指当缓存系统宕机时，暂停业务对于缓存系统的访问，直接返回错误；请求限流机制只允许少部分请求可以访问后端数据库。  </li><li>构建Redis缓存高可用集群。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 分布式缓存 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java反射机制</title>
      <link href="/2023/12/01/2023-12-01-Java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6/"/>
      <url>/2023/12/01/2023-12-01-Java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>在Java中，所有对象都有两种类型，即编译时类型和运行时类型。  </p><p>编译时类型是在程序代码编译解决确定的类型，而运行时类型是在程序运行时根据实际的对象类型确定的。  </p><p>并且由于多态机制，很多时候一个对象的编译时类型和运行时类型并不是一致的。  </p><p>譬如，对于如下代码：  </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Object</span> <span class="variable">i</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;qwe&quot;</span>);</span><br><span class="line">i.getClass();</span><br></pre></td></tr></table></figure><p>对象<code>i</code>的编译时类型为<code>Object</code>，但是当我们使用<code>getClass()</code>获取它的所属类的<code>Class</code>类对象时，得到的结果却是<code>java.lang.String</code>  </p><p>如果想要调用对象运行时类型的方法，那么就需要<strong>反射机制</strong>，因为在编译的时候，并不知道对象的运行时信息。  </p><h2 id="反射概述"><a href="#反射概述" class="headerlink" title="反射概述"></a>反射概述</h2><p>反射机制允许我们在运行时借助<code>Reflection API</code>获取到任何类的内部信息，并可以直接操作任何对象的属性和方法。  </p><p>当类被JVM加载之后，会在方法区产生一个<code>Class</code>类型的对象，这个类包含了完整的类的结构信息。  </p><p>反射机制就是基于每个类的唯一的<code>Class</code>对象实现的。  </p><h2 id="反射第一步——获得Class对象"><a href="#反射第一步——获得Class对象" class="headerlink" title="反射第一步——获得Class对象"></a>反射第一步——获得Class对象</h2><p>在反射操作的第一步，首先是要获得一个<code>Class</code>类对象，之后的反射操作都是基于这个<code>Class</code>实例来完成的，可以说，<code>Class</code>对象是反射的基本。  </p><h3 id="Class"><a href="#Class" class="headerlink" title="Class"></a>Class</h3><p>在<code>Object</code>类中，有一个方法，<code>public final Class getClass()</code>，Java所有的对象都继承了这个方法，通过这个方法可以返回一个<code>Class</code>对象。  </p><p>一个<code>Class</code>对象具有如下特点:</p><ol><li><code>Class</code>对象只能由系统建立  </li><li>一个被加载的类在JVM中只会有一个<code>Class</code>实例  </li><li><code>Class</code>类是<code>Reflection</code>的根源，任何想要动态加载、运行的类，唯有先获得对应的<code>Class</code>对象  </li><li>通过<code>Class</code>对象可以完整地得到一个类中所有被加载的结构</li></ol><h3 id="获取Class实例的方法"><a href="#获取Class实例的方法" class="headerlink" title="获取Class实例的方法"></a>获取Class实例的方法</h3><p>一共有三种获得<code>Class</code>实例的常用方法：    </p><ol><li>获得编译期间已知类型的<code>Class</code>实例<br> 直接通过类的<code>class</code>属性获得，安全可靠且性能高，例如：   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Class</span> <span class="variable">clazz</span> <span class="operator">=</span> String.class;</span><br></pre></td></tr></table></figure></li><li>已知实例，获取其运行时类型<br> 通常通过实例的<code>getClass()</code>方法来获得</li><li>通过类的全类名来获得<br> 使用<code>Class</code>类提供的静态方法<code>forName()</code>获取，例如：   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Class</span> <span class="variable">clazz</span> <span class="operator">=</span> Class.forName(<span class="string">&quot;java.lang.String&quot;</span>);</span><br></pre></td></tr></table></figure></li></ol><p><strong>注意：所有的Java类型都有<code>Class</code>对象，对于数组来说，只要类型和维度相同，就是同一个<code>Class</code>对象。</strong>  </p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>在以下的案例中，都对<code>Person</code>类来进行反射及操作：  </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Person</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> Integer age;</span><br><span class="line">    <span class="keyword">public</span> String email;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Person</span><span class="params">(String name, Integer age)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getEmail</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> email;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Person&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;name=&#x27;&quot;</span> + name + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, age=&quot;</span> + age +</span><br><span class="line">                <span class="string">&quot;, email=&#x27;&quot;</span> + email + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Person</span><span class="params">(String name, Integer age, String email)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">        <span class="built_in">this</span>.email = email;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setEmail</span><span class="params">(String email)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.email = email;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Person</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setName</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Integer <span class="title function_">getAge</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setAge</span><span class="params">(Integer age)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="创建运行时类的对象"><a href="#创建运行时类的对象" class="headerlink" title="创建运行时类的对象"></a>创建运行时类的对象</h3><p>有两种方式构造一个运行时类的对象：  </p><h4 id="使用Class对象的newInstance-方法"><a href="#使用Class对象的newInstance-方法" class="headerlink" title="使用Class对象的newInstance()方法"></a>使用Class对象的newInstance()方法</h4><p>不过，这种方式构造对象有两个条件：  </p><ol><li>类必须有无参构造器  </li><li>构造器的访问权限满足</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Object</span> <span class="variable">p1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;jack&quot;</span>,<span class="number">34</span>);</span><br><span class="line"><span class="comment">// 获得 p1 对象的运行时类型</span></span><br><span class="line"><span class="type">Class</span> <span class="variable">aClass</span> <span class="operator">=</span> p1.getClass();</span><br><span class="line"><span class="comment">// 调用 Class 对象的 newInstance() 方法实例化对象</span></span><br><span class="line"><span class="type">Person</span> <span class="variable">p</span> <span class="operator">=</span> (Person) aClass.newInstance();</span><br><span class="line">p.setName(<span class="string">&quot;mick&quot;</span>);</span><br><span class="line">p.setAge(<span class="number">12</span>);</span><br><span class="line">System.out.println(p.toString());</span><br></pre></td></tr></table></figure><p>这种方式构造对象只可以调用无参构造方法来构造。  </p><h4 id="通过获取构造器对象来实例化对象"><a href="#通过获取构造器对象来实例化对象" class="headerlink" title="通过获取构造器对象来实例化对象"></a>通过获取构造器对象来实例化对象</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Object</span> <span class="variable">p1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;jack&quot;</span>,<span class="number">34</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获得 p1 对象的运行时类型</span></span><br><span class="line"><span class="type">Class</span> <span class="variable">aClass</span> <span class="operator">=</span> p1.getClass();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过 Class 对象的 getDeclaredConstructor() 方法</span></span><br><span class="line"><span class="comment">// 获得对应类的构造器对象，根据传入的类型参数确定返回哪个构造器对象</span></span><br><span class="line"><span class="type">Constructor</span> <span class="variable">declaredConstructor</span> <span class="operator">=</span> aClass.getDeclaredConstructor();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过构造器对象的 newInstance() 方法实例化对象</span></span><br><span class="line"><span class="comment">// 这里获得的是一个无参构造器，则参数为空</span></span><br><span class="line"><span class="type">Person</span> <span class="variable">o</span> <span class="operator">=</span> (Person)declaredConstructor.newInstance(<span class="keyword">new</span> <span class="title class_">Object</span>[]&#123;&#125;);</span><br><span class="line">o.setName(<span class="string">&quot;mick&quot;</span>);</span><br><span class="line">o.setAge(<span class="number">78</span>);</span><br><span class="line">System.out.println(o.toString());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获得有参构造器对象</span></span><br><span class="line"><span class="type">Constructor</span> <span class="variable">declaredConstructor1</span> <span class="operator">=</span> aClass.getDeclaredConstructor(String.class,Integer.class);</span><br><span class="line"><span class="type">Person</span> <span class="variable">o1</span> <span class="operator">=</span> (Person)declaredConstructor1.newInstance(<span class="keyword">new</span> <span class="title class_">Object</span>[]&#123;<span class="string">&quot;jack&quot;</span>, Integer.valueOf(<span class="number">89</span>)&#125;);</span><br><span class="line">System.out.println(o1.toString());</span><br></pre></td></tr></table></figure><h3 id="获得运行时类的完整结构"><a href="#获得运行时类的完整结构" class="headerlink" title="获得运行时类的完整结构"></a>获得运行时类的完整结构</h3><p>常用方法：</p><ol><li><code>public Class&lt;?&gt;[] getInterfaces()</code>获得实现的全部接口  </li><li><code>public Class&lt;? Super T&gt; getSuperclass()</code>获得所继承的父类<br>获得方法<code>Method</code>:  </li><li><code>public Method[] getDeclaredMethods()</code>返回此Class对应的类或接口的全部方法    </li><li><code>public Method[] getMethods()</code>返回此Class对应的类或接口的public方法<br>在<code>Method</code>类中：  </li><li><code>public Class&lt;?&gt; getReturnType()</code>获得方法全部的返回值  </li><li><code>public Class&lt;?&gt;[] getParameterTypes()</code>获得方法全部的参数方法  </li><li><code>public int getModifiers()</code>获得方法的修饰符  </li><li><code>public Class&lt;?&gt;[] getExceptionTypes()</code>获得方法的异常信息<br>获得属性<code>Field</code>:  </li><li><code>public Field[] getFields()</code>获得Class对应的类的属性  </li><li><code>public Field[] getDeclaredFields()</code>获得Class对应的类的全部属性<br>在<code>Filed</code>对象中：  </li><li><code>public int getModifiers()</code>获得属性的修饰符  </li><li><code>public Class&lt;?&gt; getType()</code>获得属性类型  </li><li><code>public String getName()</code>获得属性的名字<br>注解相关：  </li><li><code>getAnnotations()</code>获取运行时类的注解</li></ol><h4 id="Method相关"><a href="#Method相关" class="headerlink" title="Method相关"></a>Method相关</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Object</span> <span class="variable">o</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Person</span>();</span><br><span class="line">Class&lt;?&gt; aClass = o.getClass();</span><br><span class="line">Method[] methods = aClass.getMethods();</span><br><span class="line"><span class="keyword">for</span> (Method m : methods) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;Method&quot;</span>);</span><br><span class="line">    System.out.println(m);</span><br><span class="line">    Class&lt;?&gt;[] parameterTypes = m.getParameterTypes();</span><br><span class="line">    System.out.println(<span class="string">&quot;Parame&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (Class c : parameterTypes) &#123;</span><br><span class="line">        System.out.println(c);</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(<span class="string">&quot;Modifier&quot;</span>);</span><br><span class="line">    <span class="type">int</span> <span class="variable">modifiers</span> <span class="operator">=</span> m.getModifiers();</span><br><span class="line">    System.out.println(modifiers);</span><br><span class="line">    Class&lt;?&gt; returnType = m.getReturnType();</span><br><span class="line">    System.out.println(<span class="string">&quot;Return&quot;</span>);</span><br><span class="line">    System.out.println(returnType);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Field相关"><a href="#Field相关" class="headerlink" title="Field相关"></a>Field相关</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Object</span> <span class="variable">o</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Person</span>();</span><br><span class="line">Class&lt;?&gt; aClass = o.getClass();</span><br><span class="line">Field[] fields = aClass.getFields();</span><br><span class="line"><span class="keyword">for</span> (Field f : fields) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;Field&quot;</span>);</span><br><span class="line">    <span class="type">int</span> <span class="variable">modifiers</span> <span class="operator">=</span> f.getModifiers();</span><br><span class="line">    System.out.println(<span class="string">&quot;Modifier&quot;</span>);</span><br><span class="line">    System.out.println(modifiers);</span><br><span class="line">    Class&lt;?&gt; type = f.getType();</span><br><span class="line">    System.out.println(<span class="string">&quot;Type&quot;</span>);</span><br><span class="line">    System.out.println(type);</span><br><span class="line">    <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> f.getName();</span><br><span class="line">    System.out.println(<span class="string">&quot;Name&quot;</span>);</span><br><span class="line">    System.out.println(name);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="string">&quot;--------------getDeclaredFields---------------------&quot;</span>);</span><br><span class="line">Field[] declaredFields = aClass.getDeclaredFields();</span><br><span class="line"><span class="keyword">for</span> (Field f : declaredFields) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;Field&quot;</span>);</span><br><span class="line">    <span class="type">int</span> <span class="variable">modifiers</span> <span class="operator">=</span> f.getModifiers();</span><br><span class="line">    System.out.println(<span class="string">&quot;Modifier&quot;</span>);</span><br><span class="line">    System.out.println(modifiers);</span><br><span class="line">    Class&lt;?&gt; type = f.getType();</span><br><span class="line">    System.out.println(<span class="string">&quot;Type&quot;</span>);</span><br><span class="line">    System.out.println(type);</span><br><span class="line">    <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> f.getName();</span><br><span class="line">    System.out.println(<span class="string">&quot;Name&quot;</span>);</span><br><span class="line">    System.out.println(name);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>getFields()</code>方法只能拿到<code>public</code>修饰的属性，而<code>getDeclaredFields()</code>方法可以拿到所有的属性  </p><p>未完待续…随时补充！</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第一个Kubernetes应用</title>
      <link href="/2023/09/04/2023-09-04-%E7%AC%AC%E4%B8%80%E4%B8%AAk8s%E5%BA%94%E7%94%A8/"/>
      <url>/2023/09/04/2023-09-04-%E7%AC%AC%E4%B8%80%E4%B8%AAk8s%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>这两天搭建了一个Kubernetes集群，包含三个节点，如图所示:  </p><p><a href="https://imgse.com/i/pPdtmJ1"><img src="https://s1.ax1x.com/2023/08/29/pPdtmJ1.png" alt="pPdtmJ1.png"></a>  </p><p>接下来该学习如何在k8s集群上运行第一个k8s应用了。  </p><h2 id="准备镜像"><a href="#准备镜像" class="headerlink" title="准备镜像"></a>准备镜像</h2><p>首先第一步，我们应该准备我们运行这个应用所需要的容器镜像。  </p><h2 id="编写应用配置文件"><a href="#编写应用配置文件" class="headerlink" title="编写应用配置文件"></a>编写应用配置文件</h2><p>有了容器镜像之后，我们需要编写应用配置文件告诉k8s我们想要如何运行我们的容器。  </p><p>应用配置文件一般是YAML格式的，其中包含容器的定义、参数、配置等等信息，然后只需一条指令(kubectl create -f)就可以通过这个YAML文件把容器运行起来。  </p><p>一个典型的YAML格式应用配置文件示例如下:   </p><p><a href="https://imgse.com/i/pPdUECR"><img src="https://s1.ax1x.com/2023/08/29/pPdUECR.png" alt="pPdUECR.png"></a>  </p><h2 id="运行应用"><a href="#运行应用" class="headerlink" title="运行应用"></a>运行应用</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 执行如下指令即可运行k8s应用</span></span><br><span class="line">kubectl create -f nginx-test.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过如下指令查看应用的运行状态是否与预期一致</span></span><br><span class="line"><span class="comment"># 这个指令从k8s中获取指定的API对象</span></span><br><span class="line">kubectl get pods -l app=nginx</span><br></pre></td></tr></table></figure><p><a href="https://imgse.com/i/pPr8atJ"><img src="https://s1.ax1x.com/2023/09/04/pPr8atJ.png" alt="pPr8atJ.png"></a>  </p><p>可以看到两个nginx镜像已经运行起来了！  </p><p>我们甚至没有手动拉取镜像，因为在使用kubectl create指令时，k8s会自动将所需镜像拉取下来。  </p><p>很简单，不是吗？可以看到运行k8s应用的最重要的部分应该是编写对应的YAML格式文件了。</p><h2 id="YAML格式文件"><a href="#YAML格式文件" class="headerlink" title="YAML格式文件"></a>YAML格式文件</h2><p>YAML格式的文件使用缩进来表示层次关系，但要<strong>注意不可用tab键来进行缩进</strong>，对于相同层级的元素，需要使用相同的空格个数来进行缩进，空格的个数并无指定，我一般使用4个。  </p><p>一个YAML文件对应到k8s中就是一个API对象，k8s会按照YAML文件来创建出这些对象所定义的容器或者其他类型的API资源。  </p><p>以上面的YAML文件为例  </p><p>kind字段这个API对象的类型——Deployment，Deployment是一个定义多副本应用的对象(多个Pod)，他的副本数(spec.replicas)为2，Pod定义发生变化时，Deployment对每个副本进行滚动更新。  </p><p>Pod的定义在何处呢？在Pod模板中(spec.template)。模板中描述了我们想要创建的Pod的细节。这个Pod中包含一个容器，其镜像(image)为nginx:1.7.9,监听80端口，名字为nginx。  </p><blockquote><p>Pod是k8s世界中的”应用运行单元”，一个应用运行单元可以由多个容器组成。  </p></blockquote><p>每个API对象都有一个叫做Metadata的字段，是API对象的”标识”，是我们从k8s中找到这个对象的主要依据。  </p><p>Deployment对象可以通过metadata中的labels字段从k8s中过滤出它所关心的对象，而这个规则的定义在spec.selector.matchLabels中，Deployment识别所有携带app: nginx的Pod，确保它们的数量等于2。  </p><p>一个k8s的API对象的定义，大多可以分为Metadata和Spec两部分，前者存放这个对象的元数据，后者描述这个对象所要表达的功能。  </p><h2 id="查看API对象"><a href="#查看API对象" class="headerlink" title="查看API对象"></a>查看API对象</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用kubectl describe命令查看一个API对象的细节，具体使用方法如下</span></span><br><span class="line">kubectl describe pod nginx-deployment-f7ccf9478-69kkl</span><br></pre></td></tr></table></figure><p><a href="https://imgse.com/i/pPrJdQ1"><img src="https://s1.ax1x.com/2023/09/04/pPrJdQ1.png" alt="pPrJdQ1.png"></a>  </p><p>比如可以看到，这个pod被调度到了node3上，还有它的IP信息等等。  </p><h2 id="如何更新API对象"><a href="#如何更新API对象" class="headerlink" title="如何更新API对象"></a>如何更新API对象</h2><p>如果想要更新API对象，比如修改nginx的版本，一个如何做呢？  </p><p>k8s提供了非常方便的方法，我们只需要修改YAML文件，再通过一条指令更新应用即可。  </p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改YAML文件后的更新指令</span></span><br><span class="line">kubectl apply -f xxx.yaml</span><br><span class="line"><span class="comment"># 这个命令不仅可以用作更新对象，也可以用来创建对象</span></span><br></pre></td></tr></table></figure><p>这就是<strong>声明式API</strong>，我们只要告诉系统我们期望得到什么样的状态(YAML文件中所描述)，至于系统如何去做我们不需要去管。  </p><h2 id="进入及删除容器"><a href="#进入及删除容器" class="headerlink" title="进入及删除容器"></a>进入及删除容器</h2><p>可以通过如下指令进入到Pod当中</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl <span class="built_in">exec</span> -it nginx-deployment-94c47774b-jxsnc -- /bin/bash</span><br></pre></td></tr></table></figure><p>效果如下:<br><a href="https://imgse.com/i/pPrY0pj"><img src="https://s1.ax1x.com/2023/09/04/pPrY0pj.png" alt="pPrY0pj.png"></a>  </p><p>也可以通过一条指令删除这个Deployment</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># xxx.yaml为这个对象对应的YAML文件</span></span><br><span class="line">kubectl delete -f xxx.yaml</span><br></pre></td></tr></table></figure><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 张磊. 深入剖析Kubernetes[M]. 第1版. 人民邮电出版社, 2021.3.  </p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅谈Kubernetes</title>
      <link href="/2023/08/29/2023-08-29-%E6%B5%85%E8%B0%88k8s/"/>
      <url>/2023/08/29/2023-08-29-%E6%B5%85%E8%B0%88k8s/</url>
      
        <content type="html"><![CDATA[<p>Kubernetes，简称k8s，是云原生生态的基石，是CNCF技术栈的核心。  </p><p>注: <a href="https://www.cncf.io/">CNCF</a>即为云原生计算基金会，是一个开源的软件基金会，致力于云原生技术的普及及可持续发展。许多有名的项目都托管在这个社区当中，包括Docker、Kubernetes。  </p><p>Kubernetes脱骨于Google的Borg系统，而Borg承载了Google公司整个基础设施的核心依赖，k8s在Borg体系的指导之下，在众多容器编排工具中脱颖而出。  </p><h2 id="为什么需要容器编排"><a href="#为什么需要容器编排" class="headerlink" title="为什么需要容器编排"></a>为什么需要容器编排</h2><p>一个Docker容器本质上是一个进程，当然处理不了太多的事情，在一个大型项目当中，可能会有成千上万个容器共同工作，如何处理容器之间复杂的关系让它们协同起来，是一个很棘手的问题。  </p><p>于是类似于k8s这样的容器编排工具就应运而生。  </p><h2 id="用户的期望"><a href="#用户的期望" class="headerlink" title="用户的期望"></a>用户的期望</h2><p>作为用户，我们已经有了应用的容器镜像，我们希望k8s这样的工具，给我们: 在一个给定的集群上运行这个应用，并且提供路由网关、水平扩展、监控、备份、灾难恢复等一系列运维能力。  </p><h2 id="Kubernetes架构"><a href="#Kubernetes架构" class="headerlink" title="Kubernetes架构"></a>Kubernetes架构</h2><p><a href="https://imgse.com/i/pPaWY9K"><img src="https://s1.ax1x.com/2023/08/29/pPaWY9K.png" alt="pPaWY9K.png"></a>  </p><p>图源自[1],展现了Kubernetes的全局架构。</p><p>k8s由Master和Node两种节点组成，分别是控制节点和计算节点。Master节点中有三个独立组件，分别是负责API服务的kube-apiserver、负责调度的kube-scheduler，以及负责容器编排的kube-controller-manager。整个集群的持久化数据，由kube-apiserver处理后保存在etcd中。<br>其中etcd是一个分布式的、高可用的、一致的KV存储数据库，基于raft共识算法实现，主要用于共享配置和服务发现。  </p><p>计算节点上最核心的地方，是一个名为kubelet的组件，主要负责同容器运行时交互。这种交互依赖一个称作CRI(container runtime interface)的远程调用接口，这个接口定义了容器运行时的各项核心操作，比如启动一个容器需要的所有参数。  </p><p>而容器运行时则通过OCI这个容器运行时规范同底层Linux系统进行交互，即把CRI请求翻译成对Linux系统的调用。  </p><p>kubelet还通过gRPC协议同一个叫做Device Plugin的插件进行交互，这个插件是管理GPU等宿主机物理设备的主要组件。  </p><p>kubelet还通过CNI(container networking interface)和CSI(container storage interface)接口调用网络插件和存储插件为容器配置网络和持久化存储。  </p><h2 id="Kubernetes核心能力与项目定位"><a href="#Kubernetes核心能力与项目定位" class="headerlink" title="Kubernetes核心能力与项目定位"></a>Kubernetes核心能力与项目定位</h2><blockquote><p>在大规模集群中的各种任务之间运行，实际上存在各种各样的关系。这些关系的处理才是作业编排和管理系统最困难的地方。</p></blockquote><p>这句话道出了Kubernetes核心能力和项目定位，来自于Borg论文中。  </p><p>任务与任务之间的关系，诸如Web应用与数据库之间的访问关系，负载均衡器和后端服务之间的代理关系等等。</p><p>在容器之前，使用虚拟机来处理这种关系，将可能发生通信的任务部署在同一台虚拟机中，是”粗粒度”的，不仅如此，还需要手动维护守护进程。  </p><p>而有了容器技术，可以将服务放在独立的容器中，容器可以被调度到集群中的任何一台机器上，它是”细粒度”的。  </p><p>如何编排 &amp; 调度呢？  </p><p>Kubernetes以统一的方式抽象底层基础设施能力(比如计算、存储、网络)，定义任务编排的各种关系(比如亲密关系、访问关系、代理关系),将这些抽象以声明式API的方式对外暴露，从而允许平台构建者基于这些抽象进一步构建自己的PaaS乃至任何上层平台。  </p><p>Kubernetes对容器间的访问进行了抽象和分类，它总结出了一类常见的紧密交互的关系，即这些任务之间需要非常频繁地交互和访问，或者它们会直接通过本地文件交换信息。  </p><p>在常规环境中，这些应用会被部署在同一台机器上，通过localhost进行通信，通过本地磁盘目录交换文件。  </p><p>而在Kubernetes中，这些容器会被划分为一个Pod，Pod中的容器共享同一个Network Namespace、同一组Volumn，从而实现高效交换信息。Pod是Kubernetes中最基础的一个对象。  </p><p>但是。对于容器来说，它的IP地址是不固定的，一个应用如何找到另一个应用的Pod呢？  </p><p>Kubernetes的做法是给Pod绑定一个Service服务，而Service服务声明的IP地址等信息是固定不变的。Service服务作为Pod的代理入口，代替Pod对外暴露一个固定的网络地址。Service负责相应Pod的IP地址、端口等信息的自动更新、维护。  </p><p>如果我们希望一次启动多个应用的实例，需要使用Deployment这个Pod的多实例管理器。  </p><p>Secret是保存在etcd中的键值对数据，可以将授权信息(比如Web访问数据库时需要用户名和密码)存放在Secret对象中，Kubernetes就会在Web应用的Pod启动时，自动把Secret里的数据以Volumn的方式挂载到容器里。  </p><h2 id="声明式API"><a href="#声明式API" class="headerlink" title="声明式API"></a>声明式API</h2><p>如何使用Kubernetes？  </p><p>首先，通过一个任务编排对象，比如Pod、Job、CronJob等，描述你试图管理的应用；  </p><p>然后，为它定义一些运维能力对象，比如Service、Ingress、Horizontal Pod Autoscaler(自动水平扩展器)等，这些对象会负责具体的运维能力侧功能。  </p><p>这种使用方法就是”声明式API”。这种API对应的编排对象和服务对象，都是Kubernetes项目中的API对象。  </p><p>题外话:<br>命令式API告诉系统它需要做什么，需要怎么做；而声明式API告诉系统我们想要什么，系统如何去完成是系统的事。声明式API及其优势可以查看参考文献[3].  </p><blockquote><p>声明式API是Kubernetes最核心的设计理念，正因为有了它，我们基于Kubernetes构建的上层平台才有了一致的编程范式和交互编程界面，才使得今天整个云原生生态中诞生了如此多的Kubernetes插件能力和扩展。  </p></blockquote><h2 id="Kubernetes的使用"><a href="#Kubernetes的使用" class="headerlink" title="Kubernetes的使用"></a>Kubernetes的使用</h2><p>首先按照格式编写YAML文件，随后执行: </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl create -f xxx.yaml</span><br></pre></td></tr></table></figure><p>这样对应的容器就启动了。  </p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 张磊. 深入剖析Kubernetes[M]. 第1版. 人民邮电出版社, 2021.3.<br>[2] Hu先生的Linux. ETCD介绍—etcd概念及原理方面分析[EB&#x2F;OL]. [2023-08-29]. <a href="https://zhuanlan.zhihu.com/p/405811320">https://zhuanlan.zhihu.com/p/405811320</a>.<br>[3] Docker_. 为什么说声明式API比命令式API更优雅？[EB&#x2F;OL]. [2023-08-29]. <a href="https://blog.csdn.net/M2l0ZgSsVc7r69eFdTj/article/details/122890922">https://blog.csdn.net/M2l0ZgSsVc7r69eFdTj/article/details/122890922</a>.  </p>]]></content>
      
      
      <categories>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统概述</title>
      <link href="/2023/08/28/2023-08-28-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
      <url>/2023/08/28/2023-08-28-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>当只有一台计算机的时候，也就是单机系统，我们不需要考虑通信、容错、一致性等等问题，只需要将应用部署在这台计算机上，它的正确运行是显而易见的——就像我们平时所做的那样，自己编写一个C++程序并运行。  </p><p>但是单机系统的弊端也是很明显的——它的资源很有限。它的硬盘、CPU、内存都是有限的，当我们的应用需要更多的资源时，一台计算机难以支撑它的运行。  </p><p>一个很直观的想法是:增加更多的计算机，这样我们就有更多资源了！  </p><p>这就是分布式系统: 很多台计算机组成一个系统，协作运行大型的应用。  </p><p>但是一个问题随之而来，那就是，在系统中增加了计算机之后，整个系统的性能也是随之增加的吗？可用性不随着系统的扩展而变化吗？未必。因为引入更多台计算机使得系统复杂度提升，就会带来额外的开销，影响整个系统的性能；而系统中的计算机可能会出现故障而导致整个系统不可用。  </p><p>这就引出了分布式系统的目标: 可扩展性(Scalability)。  </p><h2 id="可扩展性-Scalability"><a href="#可扩展性-Scalability" class="headerlink" title="可扩展性(Scalability)"></a>可扩展性(Scalability)</h2><blockquote><p>可扩展性是系统、网络或进程以一种有能力的方式处理不断增长的工作量的能力，或者是其扩大以适应这种增长的能力。</p></blockquote><p>可扩展系统是指随着规模的增加而不断满足用户需求的系统。我们重点关注两个方面: 性能(Performance)和可用性(Availability)。</p><h3 id="性能-Performance"><a href="#性能-Performance" class="headerlink" title="性能(Performance)"></a>性能(Performance)</h3><blockquote><p>性能被刻画为计算机系统完成的有用工作的数量与所使用的时间和资源的比例。</p></blockquote><p>根据具体情况，这可能被刻画为一个或多个目标:  </p><ul><li>短响应时间&#x2F;低延迟  </li><li>高吞吐量  </li><li>计算资源的利用率低</li></ul><h3 id="可用性-Availability"><a href="#可用性-Availability" class="headerlink" title="可用性(Availability)"></a>可用性(Availability)</h3><blockquote><p>可用性:系统处于正常工作状态的时间比例。如果一个用户不能访问系统，就称为不可用。</p></blockquote><p>可用性也就是容错性，这展现出分布式系统相比于单机系统得天独厚的优势，一台计算机是没有容错性的，但是分布式系统可以在一堆不可靠的组件上构建一个可靠的系统。  </p><p>但是发生故障的概率是随着计算机数量的增加而增加的，我们需要设计好的容错算法，使得系统可用性更高。  </p><p>分区(partition)与复制(replicate)技术是完成上述目标的关键技术。</p><h2 id="分区与复制"><a href="#分区与复制" class="headerlink" title="分区与复制"></a>分区与复制</h2><p>分区将数据拆分到不同的节点上，以便进行更多的并行处理；复制将一份数据复制或缓存到不同的节点上，以减小客户端和服务器之间的距离，并提升容错能力。如图所示:<br><a href="https://imgse.com/i/pPapMVI"><img src="https://s1.ax1x.com/2023/08/28/pPapMVI.png" alt="pPapMVI.png"></a></p><p>有许多实现复制和分区的算法，各有优缺点，需要结合具体问题选择。  </p><h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h3><p>分区通过限制要检查的数据量以及将相关的数据放在同一分区来提高<strong>性能</strong>。  </p><p>分区通过允许分区独立故障来提高<strong>可用性</strong>，即一个分区故障不会影响其他的分区，可以容忍多个分区故障。  </p><h3 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h3><p>复制使额外的计算能力和带宽适用于数据的新副本，从而提高了<strong>性能</strong>。  </p><p>复制通过创建数据的额外副本来提高<strong>可用性</strong>，可以允许一定数量的节点故障。  </p><p>复制使我们能够实现可扩展性、性能和容错性。  </p><p>但是复制同样带来很多问题，最重要的，如何保持多个副本之间的数据一致性？  </p><p>要保障系统满足不同程度的一致性，核心过程往往需要通过共识算法来达成。  </p><h2 id="共识问题"><a href="#共识问题" class="headerlink" title="共识问题"></a>共识问题</h2><blockquote><p>如果几台计算机(或节点)在某个值上达成一致，它们就会达成共识。更正式地:  </p><ol><li>Agreement(协定性): 所有正确的进程必须在同一个值上达成一致。  </li><li>Termination(终止性): 所有正确的进程最终都会认定某个值。  </li><li>Integrity(完整性): 每个正确的进程最多决定一个值，如果决定了某个值，那么它一定是某个进程提出来的。  </li><li>Validity(有效性): 如果所有正确进程提出了同样的值，那么所有正确进程决定这个值。</li></ol></blockquote><p>共识问题是许多商业分布式系统的核心问题。</p><p>两个不可能性定理的其中一个是关于共识问题的，即FLP impossibility。  </p><h2 id="FLP-impossibility"><a href="#FLP-impossibility" class="headerlink" title="FLP impossibility"></a>FLP impossibility</h2><p>1985年，Fischer、Lynch 和 Paterson(FLP)证明了: 在一个异步系统中，即使只有一个进程出现了故障，也没有算法能保证达成共识。  </p><p>后世的研究者为了绕开这个定理达成共识，不得不选择(1)将异步系统转换为同步系统 (2)使用随机性算法。  </p><p>另一个不可能性定理为CAP定理，指导我们对于分布式系统性质的取舍。  </p><h2 id="CAP定理"><a href="#CAP定理" class="headerlink" title="CAP定理"></a>CAP定理</h2><blockquote><p>该定理指出，在这三个性质中:  </p><ol><li>一致性(Consistency): 所有节点在同一时间看到相同的数据(强一致性)。  </li><li>可用性(Availability): 节点故障不会阻止幸存者继续操作(任何时候都可用)。  </li><li>分区容忍度(Partition tolerance): 尽管由于网络和&#x2F;或节点故障导致消息丢失，系统仍能继续运行。</li></ol><p>只能同时满足其中的两个。  </p></blockquote><p>于是我们就得到了三种不同的系统类型:  </p><ol><li>CA(Consistency+Availability): 包括full strict quorum protocols，例如2PC.  </li><li>CP(Consistency+Partition tolerance): 包括少数分区不可用的大多数仲裁协议，如Paxos以及Raft。  </li><li>AP(Availability+Partition tolerance): 包括使用冲突解决的协议，例如Dynamo。</li></ol><p>CAP定理中的一致性为强一致性，因此尽管AP系统无法实现强一致性，但是仍然有弱一致性可供实现。CAP的可用性也为强可用性，因此尽管Raft算法是CP算法，但并不意味着没有可用性，而是大多数时间可用。  </p><p>Raft算法是目前最成功的分布式共识算法，是非拜占庭容错的，在分布式系统的下一篇文章，我将会写一下Raft算法。  </p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Jay Kreps. Distributed systems[EB&#x2F;OL]. [2023-8-28]. <a href="https://book.mixu.net/distsys/index.html">https://book.mixu.net/distsys/index.html</a>.<br>[2] 苏小乐. 分布式系统的一致性与共识性[EB&#x2F;OL]. [2023-08-28]. <a href="https://zhuanlan.zhihu.com/p/35596768">https://zhuanlan.zhihu.com/p/35596768</a>.<br>[3] Fischer, M. J., Lynch, N. A. &amp; Paterson, M. S. Impossibility of distributed consensus with one faulty process. J Acm Jacm 32, 374–382 (1985).</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决方法The following signatures couldn&#39;t be verified because the public key is not available</title>
      <link href="/2023/08/27/2023-08-27-The%20following%20signatures/"/>
      <url>/2023/08/27/2023-08-27-The%20following%20signatures/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>今天在Ubuntu20.04上执行sudo apt-get update命令时，遇到以下错误:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Err:2 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial InRelease</span><br><span class="line">  The following signatures couldn&#x27;t be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05</span><br></pre></td></tr></table></figure><p>他说这个签名不能被验证，因为没有可用的公钥，并且表示没有B53DC80D13EDEF05这个密钥</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>我们给他加上这个密钥就可以了，使用命令:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys B53DC80D13EDEF05</span><br></pre></td></tr></table></figure><p>apt-key命令用于管理Debian Linux系统中的软件包密钥,每个发布的Debian软件包都是通过密钥认证的。<br>adv: 告知apt-key工具使用高级模式<br>–keyserver keyserver.ubuntu.com: 指定从哪个GPG密钥服务器获取密钥<br>–recv-keys: 指定要接收的GPG密钥ID  </p><p>这个命令从指定的服务器获取对应ID的密钥并添加到本地，用于软件包的验证。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决方法-The connection to the server localhost:8080 was refused - did you specify the right host or port?</title>
      <link href="/2023/08/27/2023-08-27-kubectl%E9%97%AE%E9%A2%98/"/>
      <url>/2023/08/27/2023-08-27-kubectl%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>k8s集群在节点运行kubectl命令时出现错误:<br>The connection to the server localhost:8080 was refused - did you specify the right host or port?<br>出现这个问题的原因是kubectl命令需要使用kubernetes-admin来运行</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>依次进行下述步骤:  </p><ol><li>首先将主节点中的&#x2F;etc&#x2F;kubernetes&#x2F;admin.conf文件拷贝到从节点相同的目录下</li><li>配置环境变量echo export KUBECONFIG&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;admin.conf &gt;&gt; ~&#x2F;.bash_profile(这句要手打,不要复制粘贴,尤其是&gt;&gt;，否则会出错)</li><li>使环境变量生效source ~&#x2F;.bash_profile</li></ol>]]></content>
      
      
      <categories>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决方法-It seems like the kubelet isn&#39;t running or healthy.</title>
      <link href="/2023/08/27/2023-08-27-It%20seems%20like%20the%20kubelet%20isn&#39;t%20running%20or%20healthy./"/>
      <url>/2023/08/27/2023-08-27-It%20seems%20like%20the%20kubelet%20isn&#39;t%20running%20or%20healthy./</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>如果在使用kubeadm初始化(kubeadm init)或者添加节点到k8s集群(kubeadm join)中时，遇到类似下图的错误:<br><a href="https://imgse.com/i/pPUr9JJ"><img src="https://s1.ax1x.com/2023/08/27/pPUr9JJ.png" alt="pPUr9JJ.png"></a><br>只要出现了<strong>It seems like the kubelet isn’t running or healthy.</strong> 这句提示，都可以尝试使用下面的解决方法来解决。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>依次执行:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo swapoff -a</span><br><span class="line">sudo sed -i &#x27;/ swap / s/^/#/&#x27; /etc/fstab</span><br></pre></td></tr></table></figure><p>即可。</p>]]></content>
      
      
      <categories>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Innovative Technology for CPU Based Attestation and Sealing论文翻译</title>
      <link href="/2023/05/25/2023-05-25-Innovative%20Technology%20for%20CPU%20Based%20Attestation%20and%20Sealing/"/>
      <url>/2023/05/25/2023-05-25-Innovative%20Technology%20for%20CPU%20Based%20Attestation%20and%20Sealing/</url>
      
        <content type="html"><![CDATA[<p><strong>Innovative Technology for CPU Based Attestation and Sealing</strong>是Intel SGX技术的官方论文，本文将翻译这篇文章。<br>SGX技术提供了enclave环境，当今比较火的机密计算技术一般就是基于SGX技术来实现，当然也有其他的可以提供enclave环境的技术，例如TrustZone等，但是SGX应用更多，且相比之下更安全些。<br><img src="https://s1.ax1x.com/2023/05/25/p9Hy7p6.jpg" alt="sgx论文封面"></p><p>本文中形似<strong>（注：···）</strong>的批注是我的批注，而非原文  </p><h1 id="Innovative-Technology-for-CPU-Based-Attestation-and-Sealing-基于CPU的认证与密封新技术"><a href="#Innovative-Technology-for-CPU-Based-Attestation-and-Sealing-基于CPU的认证与密封新技术" class="headerlink" title="Innovative Technology for CPU Based Attestation and Sealing(基于CPU的认证与密封新技术)"></a>Innovative Technology for CPU Based Attestation and Sealing(基于CPU的认证与密封新技术)</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Intel正在开发Intel®Software Guard Extensions(Intel®SGX)技术，这是Intel®架构的扩展，<strong>用于生成受保护的软件容器。容器被称为飞地。在飞地内部，软件的代码、数据和堆栈受到硬件强制访问控制策略的保护，这些策略可以防止对飞地内容的攻击。</strong>在一个软件和服务通过互联网部署的时代<strong>（注：也就是云计算时代）</strong>，关键是能够通过有线或空中<strong>安全地远程提供飞地</strong>，有把握地知道机密受到保护，并能够将机密保存在非易失性存储器中以备将来使用。<br>本文描述了允许向飞地提供机密<strong>（注：应该指用户想要保护的数据）</strong>的技术组件。这些组件包括<strong>用于对在飞地内运行的软件生成一个基于硬件的证明的方法，以及用于飞地软件密封机密并将其导出到飞地之外（例如将其存储在非易失性存储器中）的方法，以便只有相同的飞地软件能够将其解封回其原始形式。</strong>   </p><h2 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1. INTRODUCTION"></a>1. INTRODUCTION</h2><p>在一个软件和服务通过互联网部署的时代，Intel®Software Guard Extensions(Intel®SGX)和Extensions to Intel®Architecture）使服务提供商能够通过有线或无线提供具有敏感内容的应用程序，并确信其机密得到了适当保护。<strong>为了做到这一点，服务提供者必须能够确切地知道远程平台上运行的是什么软件，以及它在哪个环境中执行。</strong>   </p><h2 id="1-1-Software-Lifecycle"><a href="#1-1-Software-Lifecycle" class="headerlink" title="1.1 Software Lifecycle"></a>1.1 Software Lifecycle</h2><p>启用Intel®SGX的软件不附带敏感数据<strong>（注：指用户的软件，但是还未开始使用，软件可以开辟enclave）</strong>。在这个软件被安装后，它向服务提供商通信，以便将数据远程提供给飞地。然后软件对数据进行加密并存储以备将来使用。 图1阐明了软件完成此过程所需的步骤。<br><img src="https://s1.ax1x.com/2023/05/25/p9H6fv8.png" alt="sgx002"></p><ol><li><strong>飞地启动</strong>–<strong>不受信任的应用程序启动飞地环境以保护服务提供商的软件。在构建飞地时，会记录一个安全日志，反映飞地的内容及其加载方式。</strong> 这个安全日志是飞地的“度量”(即<strong>Measurement</strong>)。   </li><li><strong>Attestation</strong>–飞地联系服务提供者，以便将其敏感数据提供给飞地。 该平台生成一个安全断言（<strong>secure assertion</strong>），用于标识硬件环境和飞地。<strong>（注：安全断言被插入到程序中，用于检测安全问题）</strong>  </li><li><strong>Provisioning</strong>–服务提供者评估飞地的可信度。它使用<strong>Attestation</strong>来建立安全通信并向飞地提供敏感数据。使用安全通道，服务提供者将数据发送到飞地。   </li><li><strong>Sealing&#x2F;Unsealing</strong> –飞地使用一个持久的基于硬件的加密密钥来安全地加密和存储其敏感数据，以确保只有在可信环境恢复时才能检索数据。<strong>（注：可信环境未就绪，不解密。）</strong>  </li><li><strong>Software Upgrade</strong> – 服务提供商可能需要飞地软件更新。为了简化数据从旧软件版本到新版本的迁移，软件可以从旧版本请求密封(seal)密钥来解封数据，并请求新版本的密封，这样密封的数据就不会被以前版本的软件使用。</li></ol><p>最后，当平台所有者计划转移平台所有权时，应使其所有权期间可用的秘密不可访问。 Intel®SGX包含一个用户拥有的特殊持久值，当更改该值时，将更改软件可用的所有密钥。   </p><h2 id="1-2-安全模型"><a href="#1-2-安全模型" class="headerlink" title="1.2 安全模型"></a>1.2 安全模型</h2><p>希望向远程平台提供秘密的服务提供者必须事先知道远程平台的保护策略满足要部署的秘密的保护要求。 根据Intel®SGX的安全模型[1]，负责保护机密的可信计算基础(TCB)包括处理器的固件和硬件，仅包括飞地内的软件。<br>一个Enclave Writer可以使用Intel®SGX的专用sealing和attestation组件，这些组件支持以下安全模型断言，以向服务提供商证明机密将根据预期的安全级别受到保护：   </p><ul><li>Intel®SGX为Enclave实例提供了向平台请求Enclave’ identity的安全断言的方法。<br><strong>（注：Enclave’ identity就是Enclace Measurement，Enclave实例可以通过请求安全断言来验证自己的Enclave Measurement是否正确，并确保自己所在的环境是安全和可信任的。）</strong><br>Intel®SGX还允许飞地将飞地瞬时的数据绑定到断言。   </li><li>Intel®SGX为Enclave实例提供了验证来自同一平台上其他Enclave实例的断言的方法。   </li><li>Intel®SGX为远程实体提供了验证来自Enclave实例的断言的方法。   </li><li>Intel®SGX允许Enclave实例获取绑定到平台和Enclave的密钥。<br>Intel®SGX阻止软件访问其他飞地标识的密钥</li></ul><h2 id="1-3-Intel®-SGX-Instructions指令"><a href="#1-3-Intel®-SGX-Instructions指令" class="headerlink" title="1.3 Intel® SGX Instructions指令"></a>1.3 Intel® SGX Instructions指令</h2><p>Intel®SGX体系结构[1]提供了硬件指令EREPORT和EGETKEY，以支持认证attestation和密封sealing。接受SGX安全模式的秘密拥有者可以依靠这些指示向负责秘密的TCB报告。<br>为了创建飞地环境，不受信任的软件使用Intel®SGX指令。这些指令还计算已启动环境的加密Measurement。本文第2节进一步描述了这些过程。<br>为了启用attestation和sealing，硬件提供了两个附加指令EREPORT和EGETKEY。 EREPORT指令提供了一个证据结构，该结构以加密的方式绑定到硬件上，以供认证验证者使用。 EGETKEY为Enclave软件提供了访问认证和密封过程中使用的“Report”和“Seal”密钥的权限。 第3节讨论了如何使用这些指令来提供飞地的证明，第4节讨论了如何保护传递给飞地的秘密。<br>在第5节中，我们简要回顾了在平台中建立远程信任的相关工作。   </p><h2 id="2-MEASUREMENT"><a href="#2-MEASUREMENT" class="headerlink" title="2 MEASUREMENT"></a>2 MEASUREMENT</h2><p>Intel®SGX架构负责建立用于认证和密封的identities。对于每个飞地，它提供两个measurement寄存器，MRENCLAVE和MRSIGNER；MRENCLAVE提供了所构造的飞地代码和数据的identity，MRSIGNER提供了飞地权限的identity。这些值在构建飞地时被记录，并在飞地执行开始前最终确定。只有TCB有权写入这些寄存器，以确保在认证和密封时能够准确反映identities。    </p><h2 id="2-1-MRENCLAVE-Enclave-Identity"><a href="#2-1-MRENCLAVE-Enclave-Identity" class="headerlink" title="2.1 MRENCLAVE - Enclave Identity"></a>2.1 MRENCLAVE - Enclave Identity</h2><p>“Enclave Identity”是MRENCLAVE的值，它是内部日志的SHA-256[2]摘要，记录了在构建Enclave时所做的所有活动[1]。 日志由以下信息组成：   </p><ul><li>页的内容（代码、数据、堆栈、堆）。   </li><li>飞地中页的相对位置。   </li><li>与页关联的任何安全标志。</li></ul><p>一旦通过EINIT指令完成了enclave初始化，就不再对MRENCLAVE进行更新。 最后MRENCLAVE的值是一个SHA-256摘要，它以加密方式标识放置在飞地中的代码、数据和堆栈、飞地页的放置顺序和位置，以及每个页的安全属性。对这些变量的任何更改都将导致MRENCLAVE中的值不同。<br><strong>（注：MRENCLAVE中存的应该就是Enclave Measurement）</strong>  </p><h2 id="2-2-MRSIGNER-Sealing-Identity"><a href="#2-2-MRSIGNER-Sealing-Identity" class="headerlink" title="2.2 MRSIGNER - Sealing Identity"></a>2.2 MRSIGNER - Sealing Identity</h2><p>该飞地有第二个用于数据保护的identity，称为“Sealing Identity”。Sealing Identity包括“Sealing Authority”、产品ID和版本号。 Sealing Authority是在分发前对飞地进行签名的实体，通常是飞地构建者。飞地构建者向硬件提供一个RSA签名的飞地证书（SIGSTRUCT），该证书包含Enclave Identity，MRENCLAVE和密封机构的公钥。 硬件使用证书中包含的公钥检查证书上的签名，然后将测量的MRENCLAVE值与签名版本进行比较。如果这些检查通过，则在MRSIGNER寄存器中存储封签机构的公钥的哈希值。需要注意的是，如果多个飞地由同一封签机构签名，它们都将具有相同的MRSIGNER值。如第4节所示，Sealing Identity的值可用于封存数据，在某种程度上，来自同一封存机构的飞地（例如，同一飞地的不同版本）可以共享和迁移其封存数据。   </p><h2 id="3-ATTESTATION"><a href="#3-ATTESTATION" class="headerlink" title="3 ATTESTATION"></a>3 ATTESTATION</h2><p>证明是证明一个软件已经在平台上被正确实例化的过程。 在Intel®SGX中，这是一种机制，通过这种机制，另一方可以获得信任，即正确的软件安全地运行在启用的平台上的飞地内。 为此，Intel®SGX体系结构生成一个attestation assertion（认证断言）（如图2所示），它传达以下信息：   </p><ul><li>软件环境的identities被证明  </li><li>任何不可测量状态的细节（例如，软件环境可能运行的模式）   </li><li>软件环境希望与自身相关联的数据   </li><li>与平台TCB绑定的密码来制作这个assertion</li></ul><p><img src="https://s1.ax1x.com/2023/05/25/p9HcLod.png" alt="sgx003"></p><p>Intel®SGX体系结构提供了一种机制，用于在运行在同一平台上的两个飞地（本地认证）之间创建authenticated assertion，以及另一种机制，用于扩展本地认证，以向平台外的第三方提供断言（远程认证）。<strong>（注：SGX提供两种机制，本地证明和远程证明）</strong><br>最后，为了在系统中获得最大的可信度，认证密钥应该只被绑定到一个特定的平台TCB上。如果平台TCB发生变化，例如通过微码更新，应替换平台认证密钥，以正确地代表TCB的可信度。  </p><h2 id="3-1-Intra-Platform-Enclave-Attestation"><a href="#3-1-Intra-Platform-Enclave-Attestation" class="headerlink" title="3.1 Intra-Platform Enclave Attestation"></a>3.1 Intra-Platform Enclave Attestation</h2><p>应用程序开发人员可能希望多个飞地相互协作来来执行一些更复杂的功能。为了实现这个，他们需要一种机制来让一个enclave证明另一个。为了这个目的，SGX提供了EREPORT指令。<br>当这个指令被一个飞地调用时，EREPORT产生一个签名的结构，称为REPORT。REPORT结构包括飞地的两个identities，与飞地相关联的属性（属性标识模式和在ECREATE期间建立的其他属性），硬件TCB的可信度，以及飞地开发者希望传递给目标飞地的额外信息，以及一个消息认证码（MAC）标记。目标飞地将验证MAC，允许它确定创建REPORT的飞地是否在同一平台上运行。<br>MAC被一个称作“Report Key”的密钥产生。如表1所示，Report Key只被目标飞地和EREPORT指令知道。目标飞地可以得到他自己的Report Key通过EGETKEY指令，EGETKEY为飞地提供一系列密钥，包括Report Key，可用于对称加密和身份验证。目标飞地使用Report Key通过REPORT结构重新计算MAC，核实这个REPORT是由证明（reporting）飞地产生的。Intel®SGX架构使用AES128-CMAC [3]作为MAC算法。<br><img src="https://s1.ax1x.com/2023/05/25/p9HczSP.png" alt="sgx004"></p><p>每个REPORT结构也包括一个256bit的用户数据字段。这个字段将enclave内的数据绑定到enclave的identity（如REPORT中所述）。该字段可用于使用辅助数据扩展REPORT，通过将其填充为辅助数据的哈希摘要，然后该摘要与REPORT一起提供。使用用户数据字段使飞地能够构建更高层次的协议，在自身和另一个实体之间形成安全通道。<br>例如，通过交换在飞地内使用双方同意的参数随机生成的公共Diffie-Hellman密钥的报告，飞地可以生成一个经过验证的共享秘密，并使用它来保护它们之间的进一步通信。Intel®体系结构支持通过可供飞地软件使用的RDRAND指令[4]生成真正的随机值。<br>下图显示了一个示例流程，说明两个飞地在同一平台上如何相互验证，并验证对方在同一平台上的一个飞地内运行，因此符合Intel®SGX的安全模型。<br><img src="https://s1.ax1x.com/2023/05/25/p9Hgpy8.png" alt="sgx005"></p><ol><li>在飞地A和B之间建立通信路径后，飞地A获得飞地B的MRENCLAVE值。请注意，此步骤中的通信路径不必是安全的。  </li><li>飞地A与飞地B的MRENCLAVE一起调用EREPORT指令来为飞地B创建一个签名的REPORT。飞地A通过不可信的通信路径将其报告传输到飞地B。  </li><li>收到来自A飞地的报告后：<br>飞地B调用EGETKEY来检索它的Report Key，重新在REPORT结构上计算MAC，并将结果与REPORT携带的MAC进行比较。MAC值的匹配肯定了A确实是一个与飞地B运行在同一平台上的飞地，因此A也运行在一个遵循Intel®SGX的安全模式的环境中。<br><strong>（注：飞地B应该是用飞地A的Report Key来重新计算MAC，实际上这块说调用EGETKEY我不太明白，因为EGETKEY按理只能拿到自己的Report Key）</strong><br>一旦验证了TCB的固件和硬件组件，飞地B就可以检查飞地A的报告，以验证TCB的软件组件：</li></ol><ul><li>MRENCLAVE反映了在飞地内运行的软件映像的内容。  </li><li>签名先生反映了密封人的identity<br>飞地B可以回复一个为飞地A创建的REPORT，通过使用刚刚收到的REPORT中的MRENCLAVE。<br>飞地B向飞地A发送其REPORT，然后，飞地A可以以类似于飞地B的方式验证该报告，确认飞地B与飞地A存在于同一平台上。</li></ul><h2 id="3-2-Inter-Platform-Enclave-Attestation"><a href="#3-2-Inter-Platform-Enclave-Attestation" class="headerlink" title="3.2 Inter-Platform Enclave Attestation"></a>3.2 Inter-Platform Enclave Attestation</h2><p>用于平台内飞地认证的验证机制使用对称密钥系统，其中只有验证REPORT结构的飞地和创建REPORT的EREPORT指令才能访问验证密钥。创建一个可以在平台之外进行验证的认证需要使用非对称密码学。英特尔®SGX启用了一个特殊的飞地，称为Quoting Enclave，专门用于远程证明。Quoting Enclave在平台上验证来自其他enclave的REPORTs，使用上面描述的平台内飞地验证方法，然后用使用特定于设备（私有）非对称密钥创建的签名替换这些报告上的MAC。这个过程的输出被称为QUOTE。  </p><h3 id="3-2-1-Intel®-Enhanced-Privacy-ID-EPID"><a href="#3-2-1-Intel®-Enhanced-Privacy-ID-EPID" class="headerlink" title="3.2.1 Intel® Enhanced Privacy ID (EPID)"></a>3.2.1 Intel® Enhanced Privacy ID (EPID)</h3><p>当在平台的整个生命周期中使用少量密钥时，使用标准非对称签名方案的认证引起了隐私问题。为了克服这个问题，英特尔对TPM [5] &amp;[6]使用的直接匿名认证方案引入了一个扩展，称为Intel®增强隐私ID（EPID）[7]，被Quoting Enclave用来签名飞地认证。<br>EPID是一种组签名方案，它允许平台对对象进行签名，而不需要唯一地标识平台或链接不同的签名。相反，每个签名者都属于一个“组”，验证者使用该组的公钥来验证签名。EPID支持两种签名模式。在EPID的完全匿名模式下，验证者无法将给定的签名与组中的特定成员关联起来。在伪名模式下，EPID验证者能够确定它之前是否已经验证了该平台。  </p><h3 id="3-2-2-The-Quoting-Enclave"><a href="#3-2-2-The-Quoting-Enclave" class="headerlink" title="3.2.2 The Quoting Enclave"></a>3.2.2 The Quoting Enclave</h3><p>Quoting Enclave创建了用于签名平台认证的EPID密钥，然后由EPID后端基础设施进行认证。EPID密钥不仅表示平台，还表示底层硬件的可信度。<br>当飞地系统运行时，只有Quoting Enclave可以访问EPID密钥，并且EPID密钥被绑定到处理器的固件版本。因此，可以看成一个QUOTE是由处理器本身发出的。  </p><h3 id="3-2-3-Example-Remote-Attestation-Process"><a href="#3-2-3-Example-Remote-Attestation-Process" class="headerlink" title="3.2.3 Example Remote Attestation Process"></a>3.2.3 Example Remote Attestation Process</h3><p>图4显示了一个示例，说明在用户平台上具有安全处理元素的应用程序如何向具有挑战性的服务提供者提供认证，以便从提供者接收一些增值服务。请注意，许多用法很少使用此过程（例如在注册时）为飞地提供一个通信密钥，然后直接在后续连接中使用。<br><img src="https://s1.ax1x.com/2023/05/25/p9Hg8YR.png" alt="sgx006"></p><ol><li>最初，应用程序需要来自平台外部的服务，并与服务提供系统建立通信。服务提供商向应用程序发出challenge，以证明它确实在一个或多个飞地内运行必要的组件。challenge本身包含一个nonce（一次性数字），用于验证通信的活跃性。<strong>（注：challenge应该就是nonce，一个一次性的数字）</strong>    </li><li>该应用程序提供了Quoting Enclave的Enclave Identity，并将其与提供者的challenge一起传递到该应用程序的飞地。  </li><li>这个飞地产生了一个manifest，包括对challenge的响应和一个临时生成的公钥，由challenger用来将秘密传回这个飞地。然后，它生成manifest的hash摘要，并将其作为EREPORT指令的用户数据包含在内，该指令将生成一个将manifest绑定到飞地的报告，如第3.2节所述。然后，该飞地会将REPORT发送到应用程序。  </li><li>应用程序将REPORT转发给Quoting Enclave进行签名。  </li><li>Quoting Enclave使用EGETKEY检索它的Report Key并且核实REPORT。Quoting Enclave创建QUOTE结构并且使用EPID密钥签名。Quoting Enclave返回QUOTE结构给应用程序。  </li><li>应用程序发送QUOTE结构和一些相关的支持数据manifest给服务challenger。  </li><li>challenger使用EPID公钥证书和撤销信息或者认证验证服务来验证QUOTE上的签名。他之后使用USERDATA来核实manifest的完整性，并且检查manifest是否有对它在步骤1中发送的challenge的响应。</li></ol><h2 id="4-Sealing"><a href="#4-Sealing" class="headerlink" title="4 Sealing"></a>4 Sealing</h2><p>当飞地被实例化时，当其维护在飞地边界内时，硬件为其数据提供保护（机密性和完整性）。然而，当飞地进程退出时，飞地将被摧毁，在飞地内得到安全的任何数据都将丢失。如果这些数据意味着以后会被重用，那么该飞地必须做出特殊安排，在该飞地之外存储这些数据。<br>上面的表1显示，EGETKEY提供了对持久性Sealing Keys的访问，飞地软件可以使用这些密钥来加密和完整性保护数据。Intel®SGX对该飞地使用的加密方案没有任何限制。当与平台提供的其他服务结合时，如单调计数器，对数据也有可能进行Replay保护。  </p><h2 id="4-1-Intel®-SGX-supported-Sealing-Policies"><a href="#4-1-Intel®-SGX-supported-Sealing-Policies" class="headerlink" title="4.1 Intel® SGX supported Sealing Policies"></a>4.1 Intel® SGX supported Sealing Policies</h2><p>当调用EGETKEY时，飞地选择条件或策略，飞地可以访问此sealing key。这些政策有助于控制敏感数据对该飞地未来版本的可访问性。<br>Intel®SGX支持Seal Keys的两种策略：  </p><ul><li>Sealing to the Enclave Identity  </li><li>Sealing to the Sealing Identity</li></ul><p>Sealing to the Enclave Identity产生一个密钥，可用于这个确切的飞地的任何实例.<strong>（注：如果这个seal key是基于Enclave Identity生成的，则该密文可以被部署在相同enclave Identity的任何实例所使用。在SGX中，将数据密封到enclave的身份标识上生成的密钥可以在相同身份标识的不同enclave实例中共享。）</strong>这并不允许未来的软件访问这个飞地的秘密。Sealing to the Sealing Identity产生一个密钥，可被用于一些别的由相同Sealing Authority签名的enclaves。这可用于允许较新的飞地访问以前版本存储的数据。<br>只有飞地的后续实例化，执行具有相同策略规范的EGETKEY，才能检索Sealing Key并解密以前实例化使用该密钥密封的数据。  </p><h3 id="4-1-1-Sealing-to-the-Enclave-Identity"><a href="#4-1-1-Sealing-to-the-Enclave-Identity" class="headerlink" title="4.1.1 Sealing to the Enclave Identity"></a>4.1.1 Sealing to the Enclave Identity</h3><p>当Sealing to the Enclave Identity，EGETKEY操作会基于enclave的MRENCLAVE的值生成密钥。任何影响飞地measurement的变化都将产生不同的密钥。这导致每个飞地都有不同的密钥，提供了飞地之间的完全隔离。使用此策略的一个副产品是，同一飞地的不同版本也将具有不同的密封密钥，从而阻止脱机数据迁移。<br>此策略对于在发现漏洞后不应该使用旧数据的用法非常有用。例如，如果数据是身份验证凭据，则服务提供者可以撤销这些凭据并提供新的凭据。访问旧的凭证可能是有害的。  </p><h3 id="4-1-2-Sealing-to-the-Sealing-Identity"><a href="#4-1-2-Sealing-to-the-Sealing-Identity" class="headerlink" title="4.1.2 Sealing to the Sealing Identity"></a>4.1.2 Sealing to the Sealing Identity</h3><p>当Sealing to the Sealing Identity，EGETKEY操作会基于enclave的MRSIGNER的值和enclave的版本生成密钥。MRSIGNER反映了签署该飞地证书的Sealing Authority的key&#x2F;identity。<br>这种方式相比上一种的优点是，它允许将封闭的数据在飞地版本之间离线迁移。Sealing Authority可以签署多个飞地，并使他们可以检索相同的seal key。这些飞地可以透明地访问被其他飞地封闭的数据。<br>当sealing to a Sealing Authority，不应该允许较旧的软件访问由较新的软件创建的数据。当发布新软件的原因是为了修复安全问题时，这是正确的。为了方便这一点，Sealing Authority可以选择规定一个安全版本号（SVN）作为密封件标识的一部分。EGETKEY允许飞地指定在生成Seal Key时使用哪个SVN。它将只允许飞地为其Sealing Identity或以前的Identity指定SVNs。当飞地密封数据时，它可以选择设置允许访问该Sealing Key的飞地的最小SVN值。这可以保护未来的秘密不受易受攻击的旧软件的访问，但仍然支持无缝升级过渡，即以前的所有秘密都在升级后可用。<br>SVN与产品版本号不同。一个产品可能有多个版本，具有不同的功能，但具有相同的SVN。飞地Writer有责任与他们的客户沟通（如果必要的话），哪些产品版本具有相同的安全等价性。  </p><h2 id="4-2-Removing-Secrets-from-a-Platform"><a href="#4-2-Removing-Secrets-from-a-Platform" class="headerlink" title="4.2 Removing Secrets from a Platform"></a>4.2 Removing Secrets from a Platform</h2><p>该体系结构提出了一种被称为OwnerEpoch的机制，它允许平台所有者通过更改单个值来更改系统中的所有键。由于在通过EGETKEY指令请求密钥时会自动包含OwnerEpoch，使用特定的OwnerEpoch值密封的数据对象，只有在将OwnerEpoch设置为相同的值时才能打开。<br>该机制的主要目的是允许平台所有者在将平台转移给其他人（永久或暂时）之前，以一个简单且可恢复的步骤拒绝对平台上所有密封秘密的访问。在转移平台之前，平台所有者可以通过使用OEM提供的hooks，将OwnerEpoch更改为一个不同的值。如果临时转移（如平台维护），平台返回后，平台所有者可以将OwnerEpoch恢复到原始值，并恢复对密封秘密的访问。  </p><h2 id="5-RELATED-WORK"><a href="#5-RELATED-WORK" class="headerlink" title="5. RELATED WORK"></a>5. RELATED WORK</h2><p>略···  </p><h2 id="6-CONCLUSIONS"><a href="#6-CONCLUSIONS" class="headerlink" title="6. CONCLUSIONS"></a>6. CONCLUSIONS</h2><p>在本文中，提出了一种新的硬件辅助机制，以Intel®架构的新ISA扩展形式，允许在安全环境（称为飞地）中执行的应用软件进行安全attestation和sealing。<br>ISA扩展为飞地软件提供了手段，以向另一方证明它已在平台上正确实例化，并扩展为正确的软件，并在一个已启用的平台上的飞地内安全运行。这种认证不需要验证者理解飞地正在执行的平台软件上下文，并且仅限于信任飞地软件。<br>Intel®SGX体系结构还提供了一种机制来获得持久的唯一密钥，软件可以使用该密钥来密封秘密并稍后打开秘密。密封机制还提供了在一个飞地的软件升级时无缝转换秘密的能力。<br>认证和密封机制以一种可扩展的方式定义，支持多个飞地同时运行，每个飞地处理自己的秘密，并与远程各方进行安全通信，并向他们证明他们符合他们的安全策略。  </p>]]></content>
      
      
      <categories>
          
          <category> 机密计算 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SGX </tag>
            
            <tag> 机密计算 </tag>
            
            <tag> 内存安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Rust安装与入门</title>
      <link href="/2023/04/29/2023-04-29-rust%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/"/>
      <url>/2023/04/29/2023-04-29-rust%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<p><strong>由于站主的研究方向是内存安全，一些涉及到底层的开发会用到Rust，所以浅浅入门一下。</strong>  </p><h2 id="Rust安装"><a href="#Rust安装" class="headerlink" title="Rust安装"></a>Rust安装</h2><p>Linux下Rust的安装只需要执行一条指令即可：  </p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl https://sh.rustup.rs -sSf | sh</span><br></pre></td></tr></table></figure><p>由于网络问题，执行失败的话，多执行几次总会成功。<br>安装选项选Proceed with installation (default)即可。  </p><p>执行如下命令验证Rust安装是否成功：  </p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rustc --version</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果输出了版本，则表明安装成功！</span></span><br></pre></td></tr></table></figure><h2 id="Hello-World！"><a href="#Hello-World！" class="headerlink" title="Hello World！"></a>Hello World！</h2><h3 id="文件命名"><a href="#文件命名" class="headerlink" title="文件命名"></a>文件命名</h3><p><strong>Rust程序的文件后缀名为.rs</strong><br>文件的命名规范为下划线连接的单词，例如hello_world.rs  </p><h3 id="编译与运行"><a href="#编译与运行" class="headerlink" title="编译与运行"></a>编译与运行</h3><ul><li><strong>编译：</strong> rustc main.rs  </li><li><strong>运行：</strong> Linux下：.&#x2F;main</li></ul><figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>()&#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Hello World!&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>注：</strong><br>rustc只适合简单的Rust程序，如果Rust程序文件比较多，应该用Cargo来编译。  </p><h2 id="Cargo"><a href="#Cargo" class="headerlink" title="Cargo"></a>Cargo</h2><p>Cargo是Rust的构建系统和包管理工具。它的作用是构建代码、下载依赖的库、构建这些库… Cargo是在安装Rust的时候一起安装的。  </p><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一个项目</span></span><br><span class="line">cargo new hello_cargo</span><br></pre></td></tr></table></figure><p>使用cargo创建的项目的目录结构为：<br><img src="https://s1.ax1x.com/2023/04/29/p914eht.jpg" alt="程序结构"></p><p><strong>cargo.toml</strong>  </p><ul><li>TOML(Tom’s Obvious, Minimal Language)格式，是Cargo的配置格式  </li><li>[package]，是一个区域标题，表示下方内容是用来配置包（package）的  </li><li>[dependencies]，另一个区域的开始，它会列出项目的依赖项。  </li><li>Rust中，代码的包（或者称库）被称作crate</li></ul><p><strong>程序结构</strong>  </p><ul><li>源代码都应该放在src目录下  </li><li>顶层目录可以放置：Cargo.toml、README、许可信息、配置文件和其他与程序源码无关的文件</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">构建Cargo项目</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建可执行文件，其路径为target/debug/hello_cargo</span></span><br><span class="line">cargo build</span><br></pre></td></tr></table></figure><ul><li>第一次运行cargo build会在顶层目录生成cargo.lock文件<br>该文件负责追踪项目依赖的精确版本，不需要手动修改该文件</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">构建并且运行cargo项目</span></span><br><span class="line">cargo run</span><br></pre></td></tr></table></figure><ul><li>如果之前编译成功过，并且源码没有改变，那么就会直接运行二进制文件</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cargo check命令检查代码，确保能通过编译，但是不产生任何可执行文件</span></span><br><span class="line">cargo check</span><br></pre></td></tr></table></figure><ul><li>cargo check比cargo build快得多，使用cargo check检查代码效率更高</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为发布构建</span></span><br><span class="line">cargo build --release</span><br></pre></td></tr></table></figure><ul><li>编译时会进行优化，代码会运行的更快，但是编译时间更长  </li><li>会在target&#x2F;release而不是target&#x2F;debug生成可执行文件</li></ul>]]></content>
      
      
      <categories>
          
          <category> Rust </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Rust </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis安装(使用Docker)</title>
      <link href="/2023/03/21/2023-03-21-Redis-install/"/>
      <url>/2023/03/21/2023-03-21-Redis-install/</url>
      
        <content type="html"><![CDATA[<h3 id="使用Docker部署Redis"><a href="#使用Docker部署Redis" class="headerlink" title="使用Docker部署Redis"></a>使用Docker部署Redis</h3><h4 id="1-拉取镜像"><a href="#1-拉取镜像" class="headerlink" title="1. 拉取镜像"></a>1. 拉取镜像</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull redis#默认下载最新版本</span><br></pre></td></tr></table></figure><h4 id="2-创建本地目录（用于挂载）"><a href="#2-创建本地目录（用于挂载）" class="headerlink" title="2. 创建本地目录（用于挂载）"></a>2. 创建本地目录（用于挂载）</h4><p>创建本地映射目录用于挂载Redis配置文件和数据文件  </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#递归创建目录</span><br><span class="line">mkdir -p /home/docker/redis/data</span><br><span class="line">mkdir -p /home/docker/redis/conf</span><br><span class="line">#递归修改文件权限为可编辑</span><br><span class="line">chmod -R 777 /home/docker/</span><br></pre></td></tr></table></figure><h4 id="3-下载配置文件"><a href="#3-下载配置文件" class="headerlink" title="3.下载配置文件"></a>3.下载配置文件</h4><p>下载redis.conf,上传到服务器。<br>在<a href="http://www.redis.cn/download.html">官网</a>下整个文件，找到redis.conf,上传到服务器刚刚创建的conf文件夹下。  </p><h4 id="4-修改配置文件"><a href="#4-修改配置文件" class="headerlink" title="4. 修改配置文件"></a>4. 修改配置文件</h4><p>注释掉下面这句，使redis可以外部访问。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bind 127.0.0.1</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#设置密码</span><br><span class="line">requirepass 密码</span><br><span class="line">#改为yes，持久化</span><br><span class="line">appendonly yes</span><br></pre></td></tr></table></figure><h4 id="5-创建docker容器"><a href="#5-创建docker容器" class="headerlink" title="5. 创建docker容器"></a>5. 创建docker容器</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo docker run -p 6380:6379 --name redis -v /home/docker/redis/conf:/etc/redis/redis.conf -v /home/docker/redis/data:/data -d redis redis-server /etc/redis/redis.conf --appendonly yes</span><br><span class="line">-p端口映射，前面主机，后面容器，本机6379端口被占用，所以换了个</span><br><span class="line">--name指定容器的名称</span><br><span class="line">-v挂载文件或目录，前面表示主机目录，后面表示容器部分</span><br><span class="line">-d后台启动redis</span><br></pre></td></tr></table></figure><h4 id="6-通过客户端连接Redis"><a href="#6-通过客户端连接Redis" class="headerlink" title="6. 通过客户端连接Redis"></a>6. 通过客户端连接Redis</h4><p>进入Redis容器</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#我的容器名称是redis1</span><br><span class="line">docker exec -it redis1 /bin/bash</span><br><span class="line">#通过redis-cli连接Redis</span><br><span class="line">redis-cli</span><br></pre></td></tr></table></figure><p>输入ping命令，若输出PONG，表示目前处在一个正常的连通状态。  </p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>堆排序及其实现</title>
      <link href="/2023/03/20/2023-03-20-dpxjqsx/"/>
      <url>/2023/03/20/2023-03-20-dpxjqsx/</url>
      
        <content type="html"><![CDATA[<h3 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h3><p><strong>堆</strong>是一种叫做完全二叉树的数据结构，可以分为<strong>大根堆</strong>和<strong>小根堆</strong>。<br><strong>大根堆</strong>：每个节点的值都大于或者等于它的左右孩子的值<br><strong>小根堆</strong>：每个节点的值都小于或者等于它的左右孩子的值</p><h3 id="完全二叉树在数组中的存储"><a href="#完全二叉树在数组中的存储" class="headerlink" title="完全二叉树在数组中的存储"></a>完全二叉树在数组中的存储</h3><p>当二叉树按层序遍历的顺序保存在数组中时，**如果根节点存放在array[0]，则节点i的左孩子节点为array[i*2+1]，右孩子节点为array[i*2+2]；如果根节点存放在array[1],则其左孩子为array[i*2],其右孩子为array[i*2+1]**。</p><h3 id="建堆过程-大根堆为例"><a href="#建堆过程-大根堆为例" class="headerlink" title="建堆过程(大根堆为例)"></a>建堆过程(大根堆为例)</h3><p>从最后一个父节点array[n&#x2F;2]开始，往前遍历，判断父节点和两个孩子节点大小，如果有孩子比父节点还大的，交换，这个交换会导致子树不符合大根堆的特点，因此要再往下再调整子树，直到调整完所有的，就构建好了大根堆<br>注：其中n是元素的个数。<br>###代码<br>堆排序实现找第k大数，采用大根堆的方法</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int findKthLargest(vector&lt;int&gt;&amp; nums, int k) &#123;</span><br><span class="line">        //建堆</span><br><span class="line">        bigRootHeaps(nums,nums.size());</span><br><span class="line">        //交换k-1个元素去堆底，下一个堆根即为第k大个元素</span><br><span class="line">        for(int i=0;i&lt;k-1;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            //交换</span><br><span class="line">            int temp=nums[0];</span><br><span class="line">            nums[0]=nums[nums.size()-1-i];</span><br><span class="line">            nums[nums.size()-1-i]=temp;</span><br><span class="line">            //调整,只需要调整交换的那个子树即可</span><br><span class="line">            change(nums,0,nums.size()-i-1);</span><br><span class="line">        &#125;</span><br><span class="line">        return nums[0];</span><br><span class="line">    &#125;</span><br><span class="line">    void bigRootHeaps(vector&lt;int&gt;&amp;nums,int len)</span><br><span class="line">    &#123;</span><br><span class="line">        for(int i=len/2;i&gt;=0;i--)</span><br><span class="line">        &#123;</span><br><span class="line">            change(nums,i,len);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    void change(vector&lt;int&gt;&amp;nums,int i,int len)</span><br><span class="line">    &#123;</span><br><span class="line">        int left_child=i*2+1;</span><br><span class="line">        int right_child=i*2+2;</span><br><span class="line">        int largest=i;</span><br><span class="line">        if(left_child&lt;len&amp;&amp;nums[left_child]&gt;nums[i])</span><br><span class="line">        largest=left_child;</span><br><span class="line">        if(right_child&lt;len&amp;&amp;nums[right_child]&gt;nums[largest])</span><br><span class="line">        largest=right_child;</span><br><span class="line">        if(largest!=i)&#123;</span><br><span class="line">            int temp=nums[i];</span><br><span class="line">            nums[i]=nums[largest];</span><br><span class="line">            nums[largest]=temp;</span><br><span class="line">            change(nums,largest,len);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">执行用时：144 ms, 在所有 C++ 提交中击败了14.16%的用户</span><br><span class="line">内存消耗：44.4 MB, 在所有 C++ 提交中击败了65.45%的用户</span><br><span class="line">通过测试用例：39 / 39</span><br></pre></td></tr></table></figure><p>效果跟快排旗鼓相当：<a href="http://8.130.83.240/article/2023/3/19/9.html">http://8.130.83.240/article/2023/3/19/9.html</a></p><h3 id="找最大k个元素的堆排序优化"><a href="#找最大k个元素的堆排序优化" class="headerlink" title="找最大k个元素的堆排序优化"></a>找最大k个元素的堆排序优化</h3><p>可以采用小根堆而不是大根堆的方式来实现，小根堆只维护k个元素，减少了堆调整的次数<br>小根堆存放k个元素，根节点存储这k个元素中的最小值<br>在解决这个问题时:  </p><ol><li>首先把前k个元素读入堆中，然后维护成一个小根堆；  </li><li>由于要求最大的前k个值，之后都进来的元素，如果比小根堆的根节点还小，则直接丢弃，因为它不可能是top K元素了；  </li><li>如果比根节点的元素大，则替换根节点，并调整小根堆，使其符合小根堆的特性；  </li><li>遍历完所有元素后，小根堆的根节点就是我们要找的第k大个元素；</li></ol><h3 id="小根堆解决方法代码实现"><a href="#小根堆解决方法代码实现" class="headerlink" title="小根堆解决方法代码实现"></a>小根堆解决方法代码实现</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int findKthLargest(vector&lt;int&gt;&amp; nums, int k) &#123;</span><br><span class="line">        //存放前k个元素的数组</span><br><span class="line">        vector&lt;int&gt;array;</span><br><span class="line">        //初始化数组，先存k个数进去</span><br><span class="line">        for(int i=0;i&lt;k;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            array.push_back(nums[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        //建堆</span><br><span class="line">        smallRootHeaps(array,k);</span><br><span class="line">        for(int i=k;i&lt;nums.size();i++)</span><br><span class="line">        &#123;</span><br><span class="line">            //如果之后的元素甚至比小根堆根节点还小，直接丢掉</span><br><span class="line">            if(nums[i]&lt;=array[0])</span><br><span class="line">            continue;</span><br><span class="line">            else&#123;</span><br><span class="line">                //否则将这个元素放入小根堆根节点</span><br><span class="line">                array[0]=nums[i];</span><br><span class="line">                //调整使其符合小根堆特性</span><br><span class="line">                change(array,0,k);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return array[0];</span><br><span class="line">    &#125;</span><br><span class="line">    void smallRootHeaps(vector&lt;int&gt;&amp;nums,int len)</span><br><span class="line">    &#123;</span><br><span class="line">        for(int i=len/2;i&gt;=0;i--)</span><br><span class="line">        &#123;</span><br><span class="line">            change(nums,i,len);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    void change(vector&lt;int&gt;&amp;nums,int i,int len)</span><br><span class="line">    &#123;</span><br><span class="line">        int left_child=i*2+1;</span><br><span class="line">        int right_child=i*2+2;</span><br><span class="line">        int min=i;</span><br><span class="line">        if(left_child&lt;len&amp;&amp;nums[left_child]&lt;nums[min])</span><br><span class="line">        min=left_child;</span><br><span class="line">        if(right_child&lt;len&amp;&amp;nums[right_child]&lt;nums[min])</span><br><span class="line">        min=right_child;</span><br><span class="line">        if(min!=i)&#123;</span><br><span class="line">            int temp=nums[i];</span><br><span class="line">            nums[i]=nums[min];</span><br><span class="line">            nums[min]=temp;</span><br><span class="line">            change(nums,min,len);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">执行用时：96 ms, 在所有 C++ 提交中击败了50.23%的用户</span><br><span class="line">内存消耗：46.1 MB, 在所有 C++ 提交中击败了19.67%的用户</span><br><span class="line">通过测试用例：39 / 39</span><br></pre></td></tr></table></figure><p>对比使用大根堆，效率提升了一大截，因为除去调整小根堆和建堆的时间，效率接近O(n),但是由于使用了辅助数组，内存占用多了一点，也可以不用辅助数组而直接在nums的前k个位置建小根堆，比较简单，就不实现了。</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统概述</title>
      <link href="/2023/03/09/2023-03-09-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"/>
      <url>/2023/03/09/2023-03-09-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>操作系统是控制管理整个计算机系统的软件与硬件资源，合理地组织和调度计算机的工作和资源的分配，进而为用户和应用程序提供方便接口与环境的程序集合，是一种最基本的系统软件。目前常用的计算机操作系统有windows，linux等，本文将从宏观的角度总结操作系统的工作流程，将分散的知识链接在一起，有助于理解操作系统。</strong>  </p><p><strong>如果哪里有错误，请留言提醒我。</strong>  </p><p>要让一个操作系统在计算机上运行起来，首先需要一个安装操作系统的硬盘。  </p><h2 id="硬盘"><a href="#硬盘" class="headerlink" title="硬盘"></a>硬盘</h2><p>每块硬盘在厂家生产出来出厂之前，会经历一次物理格式化，物理格式化是将硬盘划分出柱面和磁道，再将磁道划分为一个一个扇区（也就是盘块），因此在出厂时，硬盘的每一块已经划分好，相应每一块有一个物理地址。  </p><p>在使用硬盘之前先将硬盘分区，分区的目的是方便管理和使用文件，同时分区后簇变小，由于一个簇只能被一个文件占有，若文件很小会造成空间浪费，因此分区有利于减小内部碎片，提高存储利用率。分区之后要进行逻辑格式化，不同于物理格式化，逻辑格式化的目的是給磁盘的分区装入文件系统，以管理磁盘中的文件，常见的文件系统有FAT32、NTFS、exFAT、EXT4等，每个分区的文件系统可以不同。  </p><h2 id="计算机开机过程简述"><a href="#计算机开机过程简述" class="headerlink" title="计算机开机过程简述"></a>计算机开机过程简述</h2><p>按下电源键后，启动CPU，CPU会运行BIOS内部程序，（BIOS是“Basic Input Output System”的缩写，即基本输入输出系统，它是一组固化到计算机内主板上一个ROM芯片上的程序，是个人电脑启动时加载的第一个软件，它保存着计算机最重要的基本输入输出的程序、开机后自检程序和系统自启动程序，它可从CMOS中读写系统设置的具体信息。 其主要功能是为计算机提供最底层的、最直接的硬件设置和控制。引自百度百科）首先运行BIOS里的boot block（引导程序），检查code block（普通程序）代码无误后，转去执行code block。将磁盘的第一个盘块读入内存，并且将FAT表及在FAT表之后的根目录读入内存（FAT表是文件分配表，是在逻辑格式化时选择FAT32文件系统所生成，FAT表的每一项对应于磁盘中的一个盘块），第一个盘块里存放引导程序，执行引导程序，在根目录下的某个目录下找到操作系统的内核程序，载入内存，计算机由操作系统开始掌管。  </p><h2 id="目录和文件的创建"><a href="#目录和文件的创建" class="headerlink" title="目录和文件的创建"></a>目录和文件的创建</h2><p><img src="https://s1.ax1x.com/2023/05/09/p905AzT.jpg" alt="001">  </p><p>注：假定最开始的磁盘是这样的  </p><p>假定最开始的磁盘如上图所示，方框上面一行是块号（虽然1号块画的比其他块都要大，但那是为了说明问题，实际上所有的块同样大），第0块存放引导块，第1块存放FAT表（假定FAT表只占一块），第二、三块存放根目录的文件目录···FAT表项假定-1表示某文件最后一个盘块，-2表示该盘块空闲。根目录的文件目录下已存有logo.png、windows目录等文件的FCB，FCB包含若干信息，为简化起见，只保存文件名，文件类型和文件存放的物理块号。  </p><p>现在在根目录下创建一个新的目录A，首先创建目录项FCB，并在FAT表中寻找一个空闲的盘块（比如4号块）分配给目录A用来存放A对应的目录文件。如下图：<br><img src="https://s1.ax1x.com/2023/05/09/p905VQU.jpg" alt="002">   </p><p>注：在根目录下创建A并且在A目录下创建B目录之后  </p><p>如上图所示，根目录下创建了A目录并且A目录下创建了B目录，并且B目录下又存了一些文件，随着文件的添加删除，盘块被系统的分配回收，7号盘块被占用，10号盘块被占用，而中间的6、8、9是空闲的。  </p><h2 id="安装应用程序"><a href="#安装应用程序" class="headerlink" title="安装应用程序"></a>安装应用程序</h2><p>现假定要在A目录下装一个WPS并且假定WPS占地4个盘块，首先创建文件的FCB，并寻找4个空闲盘块（假定为6、8、9、11块）分配给WPS，WPS安装程序将WPS的代码数据写入分配给他的4个盘块，系统修改相应的FAT项，如图所示：<br>安装WPS之后:<br><img src="https://s1.ax1x.com/2023/05/09/p905ZyF.jpg" alt="003"><br><img src="https://s1.ax1x.com/2023/05/09/p905FJ0.jpg" alt="005"></p><h2 id="启动应用程序"><a href="#启动应用程序" class="headerlink" title="启动应用程序"></a>启动应用程序</h2><p>安装WPS之后就可以运行WPS了，想象你双击WPS在桌面的快捷方式，快捷方式类似于一种软链接，操作系统根据快捷方式提供的路径开始查找文件，先从根目录找到目录A的FCB，得到目录A的目录文件所在的磁盘块号，从磁盘将目录A的目录文件调入内存，在其中寻找WPS.exe的FCB，由此得到WPS程序存放的磁盘块号，将WPS逻辑上的第0块（即物理上的磁盘第6块）调入内存。  </p><h2 id="运行应用程序"><a href="#运行应用程序" class="headerlink" title="运行应用程序"></a>运行应用程序</h2><p>在磁盘第6块调入内存的同时，操作系统创建进程，也就是创建进程的PCB（<strong>PCB是进程存在的唯一标志！</strong>），在创建PCB时，也创建了进程对应的页表，并初始化页表，页表存放在进程的PCB中。PCB创建成功后，经系统调度，进程开始获得处理机运行。<br><img src="https://s1.ax1x.com/2023/05/09/p905kWV.jpg" alt="006"><br>注：调入6号块之后的内存和页表  </p><p>如图所示，6号块调入内存时，系统会在内存中该进程的驻留集中寻找一个空闲的页框，以便盘块内容调入页框中，假定选定211号页框。同时系统初始化进程页表，填写页号、页框号、有效位、修改位、磁盘块号等，其中磁盘块号随着进程的第0块调入内存，所有的磁盘块号都会通过查阅FAT表填入页表。  </p><p>当前系统中可能有多个进程，因此在内存的系统区，存在多个PCB，多个进程涉及到进程的并发执行，从而有进程调度以及进程的状态切换，同时对于临界区的访问，还涉及到死锁、同步和互斥。  </p><p>在请求式分页管理方式中，不必调入全部的页面进程便开始运行。假定调入进程的第0块后，WPS开始运行，如果在运行时需要用到第1块的数据或者代码，查阅页表后页面不在内存中且得知缺失的页面存放在磁盘第8块，此时产生缺页中断，请求操作系统调入第1块（磁盘块号第8块）（假定页框为985），与此同时进程阻塞，页面调入后进程重新回到原来中断的代码执行。如果驻留集已满，要调入新的磁盘块，此时需要利用页面置换算法，换出一个页面，将所需页面调入内存。  </p><p><img src="https://s1.ax1x.com/2023/05/09/p905eL4.jpg" alt="007"><br>注：调入8号块之后的内存和页表  </p><h2 id="保存文件"><a href="#保存文件" class="headerlink" title="保存文件"></a>保存文件</h2><p>用WPS撰写的文档，在点击保存或者另存为前会保存在内存新页中。当需要保存文档时，通过系统调用，在默认路径或者指定路径下的目录文件中创建FCB（xx.doc）（创建FCB的过程如前所述）。保存时，进程首先打开 （open系统调用） xx.doc（刚刚创建的那个），然后将内存中的文档内容写入（write系统调用）xx.doc，完成文档的保存。  </p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>以上就是操作系统概述，是根据<strong>咸鱼学长</strong>的讲解总结的<strong>操作系统从启动到应用程序运行的大致工作流程</strong>，将整个操作系统知识串了起来，对于宏观上掌握408考研操作系统大有裨益，受益匪浅。</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
